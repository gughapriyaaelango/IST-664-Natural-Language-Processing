{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34nwFy4M5w-0"
      },
      "source": [
        "**IST664 Lab for Week 4: Extracting Semantics**\n",
        "\n",
        "If the end goal of a project is natural language understanding, at some point we must figure out how to associate words, phrases, sentences, and larger structures with the meaning that they convey. Figuring out the meaning of utterances is the goal of semantics. In fact the leading definition of the word semantics is, \"the study of the meaning of words.\" In this lab, we are going to conisder three different approaches to extracting semantics from text.\n",
        "\n",
        "One of the earliest and most comprehensive efforts to explore semantics on a large scale arose from the work of George Miller at Princeton in the mid-1980s. The database arising from Miller's work, known as WordNet, was an award-winning effort to create a network of interconnected meanings of words. You used WordNet briefly in last week's lab. The WordNet project is alive and well in the present day, in fact there is an international organization  known as the Global WordNet Association that continues research and development of WordNet. Check it out here:\n",
        "\n",
        "http://globalwordnet.org\n",
        "\n",
        "GWA has an annual conference and offers some databases and documentation to the world community for free. These databases, now covering more than 200 languages, represent a massive amount of collective human effort, which is both amazing and illustrative of the core challenge with such resources: The maintenance of manually developed language resources requires lots of manual labor.\n",
        "\n",
        "Possibly, some of the value of what WordNet provides has been or will eventually be superceded by approaches based on deep learning. We see inklings of this with GloVe word embedding and more sophisticated embedding approaches such as BERT that are initially trained (in an unsupervised mode) on masses of unlabeled natural language text. Even so, WordNet works (and works fast!) without needing to provide any training data, so there are many applications where it is still an appropriate choice. In this first part of the week 4 lab, we explore some of the WordNet capabilities afforded by NLTK."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUKzxUVv31MY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "685d6399-1a44-4aa7-b81b-bfc723424fea"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet') # Colab does not have it installed by default\n",
        "nltk.download('omw-1.4') # Colab does not have it installed by default\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "type(wn.synsets) # A key function call (method) that we will use"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "method"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQXUKYTC4G1R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56459ca5-81cc-4534-e764-452596dc8b37"
      },
      "source": [
        "# Let's start by getting data on the word cat. A \"synset\" is a very basic\n",
        "# data structure supported by NLTK that can be used to look up synonyms \n",
        "# and related information for any word that the WordNet folks have included\n",
        "# in the giant database.\n",
        "syn = wn.synsets('cat')\n",
        "type(syn), len(syn)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(list, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z36vNxJP4hXT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f74214c9-01ae-44a6-c41d-8c090f647a3a"
      },
      "source": [
        "# The output above shows that the return data structure has 10 elements in a \n",
        "# list. What are these different list elements?\n",
        "[type(s) for s in syn]"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[nltk.corpus.reader.wordnet.Synset,\n",
              " nltk.corpus.reader.wordnet.Synset,\n",
              " nltk.corpus.reader.wordnet.Synset,\n",
              " nltk.corpus.reader.wordnet.Synset,\n",
              " nltk.corpus.reader.wordnet.Synset,\n",
              " nltk.corpus.reader.wordnet.Synset,\n",
              " nltk.corpus.reader.wordnet.Synset,\n",
              " nltk.corpus.reader.wordnet.Synset,\n",
              " nltk.corpus.reader.wordnet.Synset,\n",
              " nltk.corpus.reader.wordnet.Synset]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeJqwuhC3xGB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f468cd5d-4ebe-4ab7-dda7-f0eeb69b265f"
      },
      "source": [
        "# Each element in the list is a synset object. We have more than one whenever\n",
        "# there is more than one sense of the word.\n",
        "\n",
        "cat0 = syn[0] # Let's look at some of the details for the first synset\n",
        "\n",
        "print (\"Synset name :  \", cat0.name())\n",
        "  \n",
        "# Defining the word\n",
        "print (\"\\nSynset meaning : \", cat0.definition())\n",
        "  \n",
        "# list of phrases that use the word in context; not all words have these\n",
        "print (\"\\nSynset example : \", cat0.examples())"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset name :   cat.n.01\n",
            "\n",
            "Synset meaning :  feline mammal usually having thick soft fur and no ability to roar: domestic cats; wildcats\n",
            "\n",
            "Synset example :  []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOBBRu-27z54"
      },
      "source": [
        "Note that the synset name has interesting information in it: Of course the word itself comes first, but then the letter after the dot indicates the part of speech. The number after the second dot reveals the variant. So cat.n.01 would be read as \"the first noun sense of cat.\" The fact that cat.n.01 appears as the first synset in the list indicates that linguists believed it to be the most commonly used sense of the word.\n",
        "\n",
        "WordNet is organized as a tree structure, where we can find more specific and more general terms related to a particular word by tracing up or down the branches and twigs of the tree. A \"hypernym\" - which you can think of as \"higher level name\" - is a more general term that encompasses the word we are focusing on. In the other direction, a \"hyponym\" is an example of a word that is more specific than the word we are focusing on. As a mnemonic, remember that \"hyper\" means \"excess\" or \"above\" as in \"hyperactive.\" On the other hand, \"hypo\" means below, as in \"hypothermia.\" "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7s6PD_K86Q9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "681f60fd-a503-4dd0-a700-e32664a9b87f"
      },
      "source": [
        "print (\"Synset name :  \", cat0.name()) # Let's show the name again\n",
        "\n",
        "# Here is the \"root\" word - the highest level hypernym  \n",
        "print (\"\\nSynset root hypernym:  \", cat0.root_hypernyms())\n",
        "\n",
        "# These are the more general terms  \n",
        "print (\"\\nSynset hypernyms:  \", cat0.hypernyms())\n",
        "\n",
        "# These are the more specific terms  \n",
        "print (\"\\nSynset hyponyms:  \", cat0.hyponyms())\n",
        "\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset name :   cat.n.01\n",
            "\n",
            "Synset root hypernym:   [Synset('entity.n.01')]\n",
            "\n",
            "Synset hypernyms:   [Synset('feline.n.01')]\n",
            "\n",
            "Synset hyponyms:   [Synset('domestic_cat.n.01'), Synset('wildcat.n.03')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyWNgAoDmgDw"
      },
      "source": [
        "The second and subsequent elements in the synset list (if any) are alternative word senses. If you're a music fan, you might be able to think of another use of the word \"cat.\" In the first line of code below, we extract the second element of the synset list. Use it to show the name, definition, example, root hypernym, hypernyms, and hyponyms for this first synonym of cat."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48e3WIGn97lq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a8427e9-aed0-4946-842e-1b40c8d142a4"
      },
      "source": [
        "# Exercises: Explore the second synset for \"cat.\"\n",
        "# Create a new block of code for each of the following exercises.\n",
        "\n",
        "cat1 = syn[1] # Let's look at some of the details for the second element\n",
        "\n",
        "# 4.1: Print the name of cat1: What part of speech is it?\n",
        "print(\"Synset name :  \", cat1.name()) #guy.n.01\n",
        "\n",
        "# 4.2: Print the definition of cat1\n",
        "print(\"\\nSynset meaning : \", cat1.definition()) #an informal term for a youth or man\n",
        "\n",
        "# 4.3: Print the examples of use of cat1 in context\n",
        "print(\"\\nSynset example : \", cat1.examples()) #'a nice guy', \"the guy's only doing it for some doll\"\n",
        "\n",
        "# 4.4: Print the root hypernym of cat1\n",
        "print(\"\\nSynset root hypernym:  \", cat1.root_hypernyms())\n",
        "# 4.5: Print a list of hypernyms of cat1\n",
        "print(\"\\nSynset hypernyms:  \", cat1.hypernyms())\n",
        "# 4.6: Print a list of hyponyms of cat1\n",
        "print(\"\\nSynset hyponyms:  \", cat1.hyponyms())"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset name :   guy.n.01\n",
            "\n",
            "Synset meaning :  an informal term for a youth or man\n",
            "\n",
            "Synset example :  ['a nice guy', \"the guy's only doing it for some doll\"]\n",
            "\n",
            "Synset root hypernym:   [Synset('entity.n.01')]\n",
            "\n",
            "Synset hypernyms:   [Synset('man.n.01')]\n",
            "\n",
            "Synset hyponyms:   [Synset('sod.n.04')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwNfii4hAD-Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cbe8d66-d630-4435-94cc-9ded940f2aa1"
      },
      "source": [
        "# Given what you saw above, does it make sense now why the root hypernym\n",
        "# of cat is \"entity\" rather than something more specific like \"animal?\"\n",
        "\n",
        "# Cat is such a common word in English that it has been reused to refer\n",
        "# to many different kinds of things. Let's go back to the complete list\n",
        "# to show all of the definitions:\n",
        "\n",
        "[s.definition() for s in syn]"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['feline mammal usually having thick soft fur and no ability to roar: domestic cats; wildcats',\n",
              " 'an informal term for a youth or man',\n",
              " 'a spiteful woman gossip',\n",
              " 'the leaves of the shrub Catha edulis which are chewed like tobacco or used to make tea; has the effect of a euphoric stimulant',\n",
              " 'a whip with nine knotted cords',\n",
              " 'a large tracked vehicle that is propelled by two endless metal belts; frequently used for moving earth in construction and farm work',\n",
              " 'any of several large cats typically able to roar and living in the wild',\n",
              " 'a method of examining body organs by scanning them with X rays and using a computer to construct a series of cross-sectional scans along a single axis',\n",
              " \"beat with a cat-o'-nine-tails\",\n",
              " 'eject the contents of the stomach through the mouth']"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jlp3992_BA4g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6354318b-941c-47a7-e576-cba4656fb5c5"
      },
      "source": [
        "# That's an amazing variety. Let's also glue the corresponding synset name\n",
        "# to the definition so that we can see the parts of speech and numbering.\n",
        "[ (s.name(), s.definition())  for s in syn]"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('cat.n.01',\n",
              "  'feline mammal usually having thick soft fur and no ability to roar: domestic cats; wildcats'),\n",
              " ('guy.n.01', 'an informal term for a youth or man'),\n",
              " ('cat.n.03', 'a spiteful woman gossip'),\n",
              " ('kat.n.01',\n",
              "  'the leaves of the shrub Catha edulis which are chewed like tobacco or used to make tea; has the effect of a euphoric stimulant'),\n",
              " (\"cat-o'-nine-tails.n.01\", 'a whip with nine knotted cords'),\n",
              " ('caterpillar.n.02',\n",
              "  'a large tracked vehicle that is propelled by two endless metal belts; frequently used for moving earth in construction and farm work'),\n",
              " ('big_cat.n.01',\n",
              "  'any of several large cats typically able to roar and living in the wild'),\n",
              " ('computerized_tomography.n.01',\n",
              "  'a method of examining body organs by scanning them with X rays and using a computer to construct a series of cross-sectional scans along a single axis'),\n",
              " ('cat.v.01', \"beat with a cat-o'-nine-tails\"),\n",
              " ('vomit.v.01', 'eject the contents of the stomach through the mouth')]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNFyf-zrC3WN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b43a00f3-0f3d-44af-cc64-7f6efe73f40c"
      },
      "source": [
        "# That last one is British slang, probably arising from the propensity of\n",
        "# domestic cats to retch hairballs. Anyway. . . We can also get lemmas for\n",
        "# each synonym entry in our list of 10:\n",
        "[ (s.name(), s.lemma_names())  for s in syn]"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('cat.n.01', ['cat', 'true_cat']),\n",
              " ('guy.n.01', ['guy', 'cat', 'hombre', 'bozo']),\n",
              " ('cat.n.03', ['cat']),\n",
              " ('kat.n.01',\n",
              "  ['kat', 'khat', 'qat', 'quat', 'cat', 'Arabian_tea', 'African_tea']),\n",
              " (\"cat-o'-nine-tails.n.01\", [\"cat-o'-nine-tails\", 'cat']),\n",
              " ('caterpillar.n.02', ['Caterpillar', 'cat']),\n",
              " ('big_cat.n.01', ['big_cat', 'cat']),\n",
              " ('computerized_tomography.n.01',\n",
              "  ['computerized_tomography',\n",
              "   'computed_tomography',\n",
              "   'CT',\n",
              "   'computerized_axial_tomography',\n",
              "   'computed_axial_tomography',\n",
              "   'CAT']),\n",
              " ('cat.v.01', ['cat']),\n",
              " ('vomit.v.01',\n",
              "  ['vomit',\n",
              "   'vomit_up',\n",
              "   'purge',\n",
              "   'cast',\n",
              "   'sick',\n",
              "   'cat',\n",
              "   'be_sick',\n",
              "   'disgorge',\n",
              "   'regorge',\n",
              "   'retch',\n",
              "   'puke',\n",
              "   'barf',\n",
              "   'spew',\n",
              "   'spue',\n",
              "   'chuck',\n",
              "   'upchuck',\n",
              "   'honk',\n",
              "   'regurgitate',\n",
              "   'throw_up'])]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you examined the output above carefully, you will see a lemma_name for guy.n.01, which is \"bozo.\" In the late 1920s, this was a slang word which had the connotation of a big, muscular person of sub-normal intelligence. Gradually over the next century, this evolved into meaning a goofy or incompetent person. The use of this sense of the word peaked in 2012 and has been declining since. This anecdote illustrates the difficulty of maintaining an information resource like wordnet: Language usage changes over time, sometimes quite rapidly, and keeping up with those changes is time-consuming, expensive work."
      ],
      "metadata": {
        "id": "vvzdcNEJmvEW"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWkVa6JbDWgh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d7c22b9-966c-4d40-b483-a8909f564e81"
      },
      "source": [
        "# The elements of each of list shown above (as the second part of the tuple)\n",
        "# are plain words - the lemma names - representing the synonym set. \n",
        "# This could come in handy later, so let's make sure we know how to \n",
        "# extract each synonym.\n",
        "\n",
        "[s.lemma_names()[0] for s in syn]"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cat',\n",
              " 'guy',\n",
              " 'cat',\n",
              " 'kat',\n",
              " \"cat-o'-nine-tails\",\n",
              " 'Caterpillar',\n",
              " 'big_cat',\n",
              " 'computerized_tomography',\n",
              " 'cat',\n",
              " 'vomit']"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4K8rcg7FMFK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3e372ae-9c47-4f2a-b9c7-a3d7704adb4c"
      },
      "source": [
        "# Now repeat the process by finding the synset for an adjectival word, like\n",
        "# good, bad, great, horrid. etc. Show the list of lemma_names for that word. \n",
        "# As a related task, reduce that list of lemma names to its unique set\n",
        "# in order to eliminate duplicates. As a bonus challenge, can you figure out \n",
        "# how to do all that with just one line of code?\n",
        "\n",
        "# 4.7: Generate a unique set of lemmas for an adjective of your choice.\n",
        "\n",
        "adjec = wn.synsets('good')\n",
        "set([s.lemma_names()[0] for s in adjec])"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'adept',\n",
              " 'beneficial',\n",
              " 'commodity',\n",
              " 'dear',\n",
              " 'dependable',\n",
              " 'effective',\n",
              " 'estimable',\n",
              " 'full',\n",
              " 'good',\n",
              " 'thoroughly',\n",
              " 'well'}"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2GB7qH1KN9D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdd17625-81ec-47bb-ce8f-54cbcec3ed4a"
      },
      "source": [
        "# There are a couple more useful things we can do with a synset. First, we can\n",
        "# ask WordNet for the part of speech for each entry:\n",
        "from tabulate import tabulate # To make a neat table\n",
        "\n",
        "takesyn = wn.synsets('take') # The word \"take\" has many senses - noun and verb\n",
        "\n",
        "poslist = [(s.lemma_names()[0], s.pos(), s.definition()) for s in takesyn]\n",
        "\n",
        "print(tabulate(poslist,  headers=[\"Word\", \"POS\", \"Definition\"]))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word         POS    Definition\n",
            "-----------  -----  ----------------------------------------------------------------------------------------------\n",
            "return       n      the income or profit arising from such transactions as the sale of land or other property\n",
            "take         n      the act of photographing a scene or part of a scene without interruption\n",
            "take         v      carry out\n",
            "take         v      require (time or space)\n",
            "lead         v      take somebody somewhere\n",
            "take         v      get into one's hands, take physically\n",
            "assume       v      take on a certain form, attribute, or aspect\n",
            "take         v      interpret something in a certain way; convey a particular meaning or impression\n",
            "bring        v      take something or somebody with oneself somewhere\n",
            "take         v      take into one's possession\n",
            "take         v      travel or go by means of a certain kind of transportation, or a certain route\n",
            "choose       v      pick out, select, or choose from a number of alternatives\n",
            "accept       v      receive willingly something given or offered\n",
            "fill         v      assume, as of positions or roles\n",
            "consider     v      take into consideration for exemplifying purposes\n",
            "necessitate  v      require as useful, just, or proper\n",
            "take         v      experience or feel or submit to\n",
            "film         v      make a film or photograph of something\n",
            "remove       v      remove something concrete, as by lifting, pushing, or taking off, or remove something abstract\n",
            "consume      v      serve oneself to, or consume regularly\n",
            "take         v      accept or undergo, often unwillingly\n",
            "take         v      make use of or accept for some purpose\n",
            "take         v      take by force\n",
            "assume       v      occupy or take on\n",
            "accept       v      admit into a group or community\n",
            "take         v      ascertain or determine by measuring, computing or take a reading from a dial\n",
            "learn        v      be a student of a certain subject\n",
            "claim        v      take as an undesirable consequence of some event or state of affairs\n",
            "take         v      head into a specified direction\n",
            "aim          v      point or cause to go (blows, weapons, or objects such as photographic equipment) towards\n",
            "take         v      be seized or affected in a specified way\n",
            "carry        v      have with oneself; have on one's person\n",
            "lease        v      engage for service under a term of contract\n",
            "subscribe    v      receive or obtain regularly\n",
            "take         v      buy, select\n",
            "take         v      to get into a position of having, e.g., safety, comfort\n",
            "take         v      have sex with; archaic use\n",
            "claim        v      lay claim to; as of an idea\n",
            "accept       v      be designed to hold or take\n",
            "contain      v      be capable of holding or containing\n",
            "take         v      develop a habit\n",
            "drive        v      proceed along in a vehicle\n",
            "take         v      obtain by winning\n",
            "contract     v      be stricken by an illness, fall victim to an illness\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4c4Xnf27-4O0"
      },
      "source": [
        "Having all of the most common words in a language organized based on their hypernyms and hyponyms supports some interesting operations. For example, the noun senses of \"dog\" and \"cat\" that refer to pets both have mammal as a \"container\" word. So we can traverse our way upward from \"cat\" to find the common ancestor word and then traverse back down to \"dog.\" If we started with \"cat\" and we wanted to get to \"doctor\" it would probably take a lot more steps, because the common ancestor word would be much more general.    \n",
        "\n",
        "This leads to an interesting possibility: We can calculate the similarity between any pair of words by measuring the length of the \"path\" along the twigs and branches that connects two words. Here's an example to illustrate:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2M0wbIHrUjq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4db1be3c-3e85-456a-abdc-6ea9a334fe40"
      },
      "source": [
        "# Pay close attention: the \"synset\" method looks up ONE synset if it\n",
        "# exists. We have to specify exactly which synset we are talking about,\n",
        "# so that's why we use something like bird.n.01 to refer to the first\n",
        "# noun sense of bird. Earlier in this lab we used the \"synsets\" method\n",
        "# which will look up all of the available synsets for a word. So \"synset\"\n",
        "# and \"synsets\" do slightly different jobs.\n",
        "birdsyn = wn.synset('bird.n.01') \n",
        "goatsyn = wn.synset('goat.n.01')\n",
        "sheepsyn = wn.synset('sheep.n.01')\n",
        "\n",
        "birdsyn.path_similarity(goatsyn) # Bird to goat\n",
        "# These distances are normalized to be on a scale of 0 to 1 where 0\n",
        "# is least similar and 1 is most similar.\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1111111111111111"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdlWtyc9tFAx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "196dc01b-12c9-4e08-abf7-7b69d3ca9a3d"
      },
      "source": [
        "# Does this value make sense?\n",
        "birdsyn.path_similarity(sheepsyn) # Bird to sheep"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1111111111111111"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpSb4pNOtoYB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1eece513-9bd4-4a5d-add1-a363d24a9ffc"
      },
      "source": [
        "# How about goat to sheep?\n",
        "goatsyn.path_similarity(sheepsyn)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3333333333333333"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Discuss With Your Partner\n",
        "\n",
        "Just above, you have three measures of word similarity. The scores have been normalized to a scale of 0 to 1 and they represent the \"path length\" between the two words in the synset hierarchy. Discuss these scores with your partner and make sure you agree on why two of them are identical and the other one is higher. The idea of \"path length\" means that there must be a traversal path between every pair of words in the database, yes? What would that look like for a noun and a verb?"
      ],
      "metadata": {
        "id": "B_qyIrOj6e2n"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTddgazJwb-P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8acc2477-4c26-4476-d33c-ce996636fd94"
      },
      "source": [
        "# As with many things related to language, there is often an alternative way\n",
        "# to do something. Leacock-Chodorow similarity also uses the path lengths, \n",
        "# but also considers how deep the least common ancestor is in the hierarchy. \n",
        "# Resnik similarity also considers the relative frequency of a word in a \n",
        "# corpus you provide. We show the earlier value of path similarity here just\n",
        "# for the sake of comparison. \n",
        "nltk.download('wordnet_ic')\n",
        "from nltk.corpus import wordnet_ic\n",
        "brown_ic = wordnet_ic.ic('ic-brown.dat')\n",
        "\n",
        "birdsyn.path_similarity(goatsyn), birdsyn.lch_similarity(goatsyn), birdsyn.res_similarity(goatsyn, brown_ic)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet_ic.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.1111111111111111, 1.4403615823901665, 5.2175784741185165)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1VsAeR6xmTN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6df02c23-87a6-4b71-fc37-47b225cf902d"
      },
      "source": [
        "# Obviously, these other similarity measures are calibrated on different\n",
        "# scales from path similarity. Add code to produce the Leacock-Chodorow \n",
        "# and the Resnick similarity for sheepsyn to goatsyn\n",
        "\n",
        "# 4.8: Compute L-C and Res similarity for sheepsyn to goatsyn\n",
        "sheepsyn.path_similarity(goatsyn),sheepsyn.lch_similarity(goatsyn),sheepsyn.res_similarity(goatsyn,brown_ic)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.3333333333333333, 2.538973871058276, 8.005695458684853)"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIsWfofPyiui",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "802cab70-efb0-4866-cac9-6af3b7863be6"
      },
      "source": [
        "# OK, one last WordNet operation: Antonyms. If we want to find a word with\n",
        "# the opposite meaning, WordNet can provide us with choices:\n",
        "syn = wn.synsets('good') # Grab all of the synonyms for good\n",
        "[(s.name(), s.definition()) for s in syn] # Display them"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('good.n.01', 'benefit'),\n",
              " ('good.n.02', 'moral excellence or admirableness'),\n",
              " ('good.n.03', 'that which is pleasing or valuable or useful'),\n",
              " ('commodity.n.01', 'articles of commerce'),\n",
              " ('good.a.01',\n",
              "  'having desirable or positive qualities especially those suitable for a thing specified'),\n",
              " ('full.s.06', 'having the normally expected amount'),\n",
              " ('good.a.03', 'morally admirable'),\n",
              " ('estimable.s.02', 'deserving of esteem and respect'),\n",
              " ('beneficial.s.01', 'promoting or enhancing well-being'),\n",
              " ('good.s.06', 'agreeable or pleasing'),\n",
              " ('good.s.07', 'of moral excellence'),\n",
              " ('adept.s.01', 'having or showing knowledge and skill and aptitude'),\n",
              " ('good.s.09', 'thorough'),\n",
              " ('dear.s.02', 'with or in a close or intimate relationship'),\n",
              " ('dependable.s.04', 'financially sound'),\n",
              " ('good.s.12', 'most suitable or right for a particular purpose'),\n",
              " ('good.s.13', 'resulting favorably'),\n",
              " ('effective.s.04', 'exerting force or influence'),\n",
              " ('good.s.15', 'capable of pleasing'),\n",
              " ('good.s.16', 'appealing to the mind'),\n",
              " ('good.s.17', 'in excellent physical condition'),\n",
              " ('good.s.18', 'tending to promote physical well-being; beneficial to health'),\n",
              " ('good.s.19', 'not forged'),\n",
              " ('good.s.20', 'not left to spoil'),\n",
              " ('good.s.21', 'generally admired'),\n",
              " ('well.r.01',\n",
              "  \"(often used as a combining form) in a good or proper or satisfactory manner or to a high standard (`good' is a nonstandard dialectal variant for `well')\"),\n",
              " ('thoroughly.r.02',\n",
              "  \"completely and absolutely (`good' is sometimes used informally for `thoroughly')\")]"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24ghhlidz7cH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "139323ab-c211-4f02-df78-2a7f69cc8804"
      },
      "source": [
        "# We'll choose the first adjectival form for finding antonyms:\n",
        "goodsyn = wn.synset('good.a.01')\n",
        "\n",
        "# Now get the antonym from the lemma\n",
        "[l.antonyms() for l in goodsyn.lemmas()]"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[Lemma('bad.a.01.bad')]]"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U88lc1L024RT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5b21ca1-cc0d-406f-b44d-f265e89918d1"
      },
      "source": [
        "# Now look up the antonym(s) for the adjectival sense of bad.\n",
        "\n",
        "# 4.9: Look up the antonym for bad\n",
        "badsyn = wn.synset('bad.a.01')\n",
        "[l.antonyms() for l in badsyn.lemmas()]"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[Lemma('good.a.01.good')]]"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DGWWImT3QdW"
      },
      "source": [
        "**Part 2 - Word Sentiment**\n",
        "\n",
        "Using WordNet, a truly massive effort to build a tree of semantics for words in various languages, we've looked up synonyms, antonyms, definitions, and examples for a variety of words. We've also gotten our first indication of quantitative relations between words, i.e., the similarity measures between pairs of words. The tree structure of WordNet was intentionally designed so that similar words were close to each other and semantically different words further away.\n",
        "\n",
        "But what can we do with this kind of information? One of the first practical analytical methods for using semantics arises from efforts to measure sentiment in fragments of natural language - basically whether a phrase, sentence, paragraph or other structure is trying to say something positive or negative. Positive versus negative is perhaps the simplest form of sentiment, but naturally there are other forms as well: good vs. bad, happy vs. sad, useful vs. useless, etc. Maybe there is some way that we could use the structure of WordNet to get at these forms of sentiment. Let's start simple and then work our way to some more complex options."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8wADjvN5uN7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bddac1f8-8244-477d-fadc-2efdf7348f55"
      },
      "source": [
        "# First, we need a dataset to work on. Anything with some comments and\n",
        "# a sentiment indicator will do. This URL refers to a project on Github\n",
        "# that Dennis Pan posted. If the URL is unavailable, find another CSV file\n",
        "# with text comments and a sentiment score.\n",
        "import pandas as pd\n",
        "data = pd.read_csv(\"https://raw.githubusercontent.com/dennisypan/Quick-N-Dirty-Sentiment-Analysis/master/sentiment_on_business.csv\")\n",
        "print(list(data)) # Show column names"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Unnamed: 0', 'Business', 'Comments', 'Rating', 'Sentiment Label', 'Sentiment Score', 'URL']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dppMX25BBG85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05ff4528-15a2-42ab-86c8-894fab6feefb"
      },
      "source": [
        "# So we will be examining the Comments for hints about sentiment along with\n",
        "# Sentiment Label and Sentiment Score, which were set up by the creator of the\n",
        "# dataset to help with machine learning tasks.\n",
        "\n",
        "# Show the number of rows and columns in this data set\n",
        "data.shape"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHuGS_YN-XZE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40cbe698-c412-4b4e-e1b3-9a007ae50fc1"
      },
      "source": [
        "# A very small dataset, but fine for what we are doing here.\n",
        "\n",
        "# View a few comments. Note that the name of this data field ('Comments') is \n",
        "# peculiar to the Dennis Pan Yelp/Sushi data. If you change the dataset, you may\n",
        "# need to change the name of the field where the comments are found.\n",
        "data['Comments'][0:5]"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    Boyfriend and I ordered togo sushi and picked ...\n",
              "1    I am pleased to recommend this restaurant in S...\n",
              "2    great food been going to japan town since i wa...\n",
              "3    Small sushi boat restaurant located in SJ Japa...\n",
              "4    Sushi Maru is one of the many gems of SJ's Jap...\n",
              "Name: Comments, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# For the super bonus challenge at the end, you might need to use a regular\n",
        "# expression to remove punctuation and digits from the text. You could put \n",
        "# that code here. This regex matches anything that is not an alpha character\n",
        "# or whitespace: [^a-zA-Z\\s]\n",
        "# Don't worry about this for now, though. We want to first see the results\n",
        "# with punctuation and other stuff left in the text.\n",
        "#\n",
        "import re\n",
        "for s in data['Comments']:\n",
        "  patt=re.sub('[^a-zA-Z\\s]','',s)\n",
        "  print(patt)"
      ],
      "metadata": {
        "id": "CkogV-eNyWYF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "973cb222-3f43-411f-b5ca-94509d979105"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Boyfriend and I ordered togo sushi and picked up a couple bottles of sake next door to have dinner at home Our friends told us they werent fans of Sushi Maru but we decided to give it a shot anyway We hadHAMACHI ROLL I love yellowtail and thought this was great They added green onion which complimented it well Bf isnt too keen on yellowtail so I ate it all SAKE ROLL You cant go wrong with salmon The pieces are a decent size TEKKA ROLL Im not too big on tuna so bf had this He liked it RAINBOW ROLL We were both impressed The crab meat had great flavor Super delicious and we will order again We got all of that and only spent about  Dinner was perfect and we both liked it very much Next time well dine in and take advantage of their conveyor belt sushi bar\n",
            "I am pleased to recommend this restaurant in San Joses Japantownright next door to Union Bank The restaurant is quite popular and fills up at lunchtime  The service is fast and friendly   There is a sushiboat bar for those who are so inclined as it is definitely wellliked  The booths are spacious and comfortable  The  luncheon menu  is somewhat limited Their tempura appetizer is really remarkable both in taste and price ample and affordable  I was slightly disappointed in their salad dressing  Its usually so good in Japanese restaurants The restaurant is clean as is the ladies room Parking is not a problem There is both street metered and lot parking\n",
            "great food been going to japan town since i was a young tadpole love all the different restaurants and stores in area will be going to this restaurant again\n",
            "Small sushi boat restaurant located in SJ Japantown Sushi Maru looks a bit outdated but their food is pretty decent I ordered a bowl of agedashi tofu and my mom ordered their chicken terriyaki lunch The agedashi tofu was decent definitely could be slightly crispier but the flavors were alright We also grabbed a few plates off the sushi belt and they were decent but they were a tad pricey for okay quality  Overall this place is alright Its not high on my list to revisit but if im in the area ill probably try it out again\n",
            "Sushi Maru is one of the many gems of SJs Japan town They have a rotating sushi belt but also a solid menu of entrees as well as individual nigiri and hand roll options My friend and I both ordered the Chefs sushi special and some hot sake the toro and salmon belly with skin were to DIE for It was a great way to get a taste of everything I definitely want to come back and try some of the other entrees or for some more yummy nigiri but ultimatelythis is a very very sushi place but not the best Ive tried Id give  stars if I could  However Id still come back if Im looking for a good spot in Japan town\n",
            "ve enjoyed lunch here numerous times and have loved each visit They have a daily special which is always out of the ordinary bento box but we come here for the sushi Its always so fresh and beautifully prepared There is a sushi conveyor belt that circulates the freshly made eats for the perusal of those sitting at the bar We typically order ama ebi sweet shrimp and torched salmon nigiri Each dish comes with  pieces and is not cheap pair but its so worth it The shrimp is always tender and sweet They fry the heads so you can enjoy their crunchy briney glory The torched salmon is phenomenal You must try it Its called nanoku Each sushi dish from the bar is color coded and corresponds to a price The dishes are on the wall so you can tally up as you eat if you so choose We love it here  cant wait to return Oiishi\n",
            "Sushi Maru is a conveyor belt sushi restaurant and a popular lunch spot during the week Unlike the Sushi Maru in Milpitas this location has GOOD food Ive never really tried the sushi here and usually end up ordering from their lunch menuspecials For about  you can get an entree or two depending on if you opt for the combo plus salad and soup The options are decent and the food is filling If you come here often you probably already know about their stamp card I think you need to spend  in six months in order to save  on your next bill  This place opens at am during the week so come early because this place fills up quickly\n",
            "There were a few gems hidden here seared salmon some of the items on the wall such as the mackeral but most of the sushi I got here was rather average Tried the Tempura Soba as well which had the same problem of being unremarkable\n",
            "Pretty inconsistent but I cant resist that seared salmon My friend Lily is the BEST at ordering and Im so spoiled that when I come on my own I sometimes forget what to order  I always go for the seared salmon towards the bottom on the paper menu and white tuna tataki appetizer The last two times Ive gone weve ordered the  piece appetizer and only gotten  pieces We cleared it up today but I wonder if we were previously overcharged For todays visit alone the first piece I had was really firmcooked on the bottom whereas the nd round of tataki that came out was really soft and tender Our order of  pieces of seared salmon also came out COLD pretty disappointing Despite the minor ups and downs Im sure Ill be backespecially with those occasional discount cards they hand out\n",
            "Food Sushi bento udon donburiall consistent and good flavors If you are seated at the sushi bar you can order as needed as well as take from the conveyor belt The rolls are good size and there is board of what fresh fish are available The wasabi and ginger are in community containers so you just be cautious and you could ask for a fresh batch from behind the counter if you need to Overall the dishes are consistent with what Japanese cuisine is and you will always have decent meal Service Sit at the booth closest to the sushi bar if you dont want to wait for you rolls as you can grab from the belt and order from the menu Seats at the bar allow to order from the menu but the space is limited for bigger plates When it gets busy you may wait a little longer for your orders Ambiance Clean simple and good for smaller groups and easy to have conversations\n",
            "I struggle with this joint  To me its a tweener meaning its sometimes justok while others its Notok  Lets go with a true  Stars here Ive had good service and some notsogood service here which is annoying   The food isnt bad but the quality of the sushi is borderline and its debatable on how long theyve been riding the sushigoround  Oh and the price for sushi is in the realm of that wasnt worth it and stick to nonsushi dishes\n",
            "Delicious food and great service but a little expensive  Im a big fan of their pumpkin croquette and the nanook seared salmon nigiri Their dinner boxes and other sushi are pretty good too Total cost for dinner for two around  Not sure if this quite makes up for the price but they do have a frequent diners stamp card However there is a time frame that you have to earn the stamps within  Sitting at the conveyor belt sushi bar was cho natsukashii nostalgic\n",
            "Ive come here once before and the first time was good This time no The food on the rotating bar was NOT fresh The bento box was ok but as I was sitting there eating the sushi chef started picking his nose and then picked up his phone and checked his POF account Yeah never coming here again\n",
            "Came here because someone recommended it I heard it was the best sushi boat restaurant But I was sorely disappointed First the sushis on the conveyor belt werent really sushis they were rolls with excessive amounts of rice Less than  of the items on the belt were what I would call sushi or quality Japanese appetizers  A bit turned off by the fishiness teehee on the conveyor belt my buddy and I mozzied over to a regular table and each ordered a bento box which was decent at best   Look if you are doing Japanese food then go all topnotch quality OR go simple wno frills Dont feign topnotch but offer the other Next time I will try another Japanese restaurant in town\n",
            "Came here with the boyfriend on a Saturday night at pm There is a sign posted at the front that you can only sit in a booth if you have a party of  or more so we sat at the sushi bar with the revolving belt Upon sitting there is a box of ginger winning for me for you to eat as you please and they will also provide you a tub of wasabi win for the boyfriend You can either order off the menu or pick off the belt There are  types of plates with different pricing from  Dont see anything you like on the belt No problem just ask the sushi chefs to make it for your and there you have it There are a variety of half rolls nigiri and desserts on the belt Boyfriend and I ate a total of  plates together a pitcher of beer side salad and a miso soup the bill came out to about  pretty pricey in my opinion considering their portions There is also a stamp card if dining here based on how many plates you pick off the sushi bar   stars because I am not convinced that the fish was all that fresh since I woke up a few time to run to the bathroom in the middle of the night  However the service is great the sushi chefs and the servers are very friendly You will also have to find metered street parking if dining here Tip Last call for the kitchen is  minutes before closing if you are on a budget and adventurous definitely come during this time They will combine two plates into one on the belt of whatever is left and you will totally get bang for your buck \n",
            "This place is amazing The staff was so friendly and we were seated quickly it was also  min from closing so this could be different for earlier in the day My partner and I decided to try a little bit of everything so he got a plate that came with two entres salad rice and  CA rolls I got a bowl of chicken udon noodles We both shared the Nanook rolls and Jackson rolls They were all so delicious This place also has that cool conveyor belt for their sushi and you have the option of just eating those Pricing for sushi is based on the kind of plate you get lowest being  and highest being  Very good food will be visiting again\n",
            "This is my favorite sushi place in San Jose Super good super high quality too Great people that work there My family and I have been going to this restaurant for so long and it gets better and better Really recommend going\n",
            "Stopped by for a quick lunch on the way back from Santa Cruz Although it was memorials day I was surprised that the restaurant was only half full We had a big group of  but were seated pretty quickly Its a standard Japanese restaurant with bento boxes sushi and bowls  They also have daily specials which change everyday I got the sushi lunch  which comes with nigiri baked fish california role oranges and some small side dishes It also comes with a salad and miso soup which came out first The sushi was pretty standard I like how they didnt put a lot of rice with the sushi The baked fish was pretty fatty but it wasnt too salty or under seasoned The seaweed salad on the side was he perfect pallete cleanser  I also liked how the dish came with slices of Orange which was refreshing after the meal You get what you pay for and it was the perfect amount for me Overall a good Japanese restaurant with friendly staff and clean atmosphere   Highly recommend stopping by if you are in San Jose Japan town\n",
            "more like  stars but Ill never go back again maybe the sushiroll are better but the lunch set was terrible miso soup was way salty  dressing on the salad maybe thats why the teriyaki sauce they put on the beef don was like concentrated oyster sauce its so salty that its just not edible ended up leaving the bowl as is couldnt eat it\n",
            "Great location nice atmosphere Sit at the bar and pick from the sushi round about Great assortment including desserts Fast service and Parking is easy Can select from the items presented or order directly\n",
            "The plusses Food is very good service is friendly reasonable price and we didnt have to wait long  Also the sushi at the bar is all covered with plastic covers to keep it sanitary  most restaurants just let it sit out exposed to the elements The minuses crowded feels a bit cramped they dont seem to make the best use of space the way other restaurants do in Japantown and we had to sit at the sushi bar because theyre arent enough tables Overall this was a very good restaurant but if I ever go back Ill choose a time when it isnt rush hour\n",
            "Very welcoming very accommodating staff when you first walk in They will do their best to seat you together no matter the size of your group Its not a large restaurant Half of it is a Ushaped sushi bar with boats circling around with a variety of sushi desserts and even drinks The other half are small tables and six or so booths that hold up to four diners The food is always fresh and there is a varied menu from which to choose There always seems to be a wait for tea and water refills though  many times we have to ask\n",
            "You need to chose the guy in the bar to make Nanook but not the women She made it in heavy soil sauce flavor which cover all the salmon taste  The bad thing is after I talked to the waiter she asked me rudely so what do you want me to do Update  after a year visit again Taste still good Eggplant and kalbi recommend Just dont argue the food with them you will be fine\n",
            "So yummy here we where here on Christmas Eve And we wanted sushi thank good it was open that day Service was great food was excellent and the employees where up to beat I cant wait to eat here again The bento  box was enough food for us to share we also got some sushi and oysters at the bar to keep us full Hot tea is always a bonus\n",
            "This is my favorite sushi place The staff and chefs are friendly and always working hard The location is located conveniently in downtown Just a couple blocks away from Coleman and Taylor This is my go to place Whenever I have a craving for sushi I always end up choosing their teriyaki salmon over the sushi on the conveyor belt Its not that the I dont like their sushi its just that their salmon is REALLY good Its never dry and its never too saucy Also they have THE best baked mussels out there Its always made fresh to order so it always comes out hot Its very flavorful Its sweet chewy and a little bit spicy Other places cant compare  Some drawback is that it is quite small inside It can get pretty crowded and you while youre seated you may have to wait a little while until more sushi plates are placed on the belt They also dont have those special sushi rolls like the Dragon roll or SpiderMan roll But its okay youre in Japantown This aint no Asian fusion place With all that I dont mind the wait Its amazing to watch and see how the chefs move so quickly I always end up having a good time and I leave with my belly full Cant complain about that\n",
            "Probably my fav sushi place in South Bay  The key things to have here are the tai do not dip they pre season seated salmon  also same and their homemade soba\n",
            "Came here for lunch on a Friday and the line was out the door It moved quickly though We both had the salmon teriyaki bento box and it was DELICIOUS We also had some rolls from the sushi boats that were equally as delicious Loved it and will most definitely be back\n",
            "Food is delicious portion is just right and price is reasonable I had lunch here every time I visit Downtown San Jose during the weekend and stopped by at Nikita maker next block for grocery shopping after lunch\n",
            "A quick and convenient place for dinner Especially if you eat in a booth by the sushi conveyor belt\n",
            "Best bento place ever We eat here like every month We get the Chicken Teriyaki and Katsu Combo  Lion King Roll The best they never disappoint Plus very affordable and great customer service Im speechless Theyre that good\n",
            "Sushi Maru San Jose is truly a Hidden Gem the place is always clean and neat all of the staff make you feel welcome and the food is truly consistent every time we havent eaten there The dinners are about  each with drinks and hors doeuvres about  per person for dinner and you truly walk away full and very satisfied\n",
            "I came here for lunch today with my friend and his Mom and was surprised when I saw that it was a sushi boat place I had never come to a sushi boat place before because my Dad is a sushi snob I was surprised by how much space the conveyer belt took up  The sushi conveyer belt was an efficient way to add things to your order but over time as more people took sushi from the conveyer belt there werent many things to grab  Therefore we needed to ask the sushi chef to make the sushi for us which defeated the purpose of the conveyer belt My friend recommended getting the nanook which was seared salmon with a sweet sauce When I first bit into the salmon a bunch of fat poured out from the searing The searing also made the salmon much softer and brought out a lot of the natural salmon flavor Most of the fish was decent quality except for the tuna which didnt have much flavor and was a little hard Overall this is a pretty good meal and if you take advantage of the conveyer belt you can really fill yourself up here\n",
            "I go because its close to my home I know what to order right in Japanese Price is a lot higher than sushi in Japan But among all other sushi restaurants in San Jose Japantown area this is the best one\n",
            "I had the Chicken teriyaki and Salmon along with the Eel and Octopus Sushi and it was very good The service here was very fast and friendly Prices for what you get are reasonable I would definitely come back again\n",
            "The sushi is here is just as I would expect from a sushi bar The fish is fresh and can be made to order They do have a rotating belt as well There is a meal menu for those that like Japanese food but not sushi The food is excellent and reasonably priced It was a stop I make when visiting San Jose even though I live in Japan and regularly eat sushi\n",
            "Our families favorite sushi spot here in Japantown Love the options and the chefs really make sure you are full and happy Sushi boat has good options and more you can choose from on the far wall More of a traditional style sushi not many fancy specialty rolls Bento Boxes seem to be filling as well Overall have great experience here and we continue to go back when we are walking down Japantown for sushi\n",
            "this review is not about their food not about their service im giving this place a  star this time around simply because we were denied a sushi bar booth their rule i guess is in order to sit in a booth you have to have  people in your party we had three not only that the host sat a party of three people in a booth and we got there first are you kidding me we settled for a table in front of us are  parties of  sitting in the sushi bar booth wow\n",
            "Where do I start So my mom and I came on a busy day Valentines Day for dinner So to wait for a bar seat we had to wait a bit but tables were open here and there My mom insisted we wait for a bar seat haha It took a while but thats okay It took a while for the waiter to come take our drink orders which is quite understandable since it was such a busy night The options they had going around the sushi bar werent crazy but nonetheless was it  fresh Holy hell the fish was delicious The chefs and waitress were nice even though they were busy and not as attentive They took forever to give us our bill and wouldnt grab it even though they clearly saw us ready to pay I had to walk up front to make them swipe the card lol We came here because my mothers former boss used to rave about this being the freshest sushi in town and the guy is Japanese from Japan So we had to come here and boy was he right Will definitely be coming back again on a slower night\n",
            "Ordered the beef tongue and chefs special sushi The presentation was fine but man was this an off day for them I took one bite of the uni and I was disgusted It was not only foul tasting it was clear that the uni was not fresh at all I immediately spat out most of it and just lost my appetite I couldnt even stomach more than a bite of the beef tongue before I paid the bill and left It is about half an hour from when I had the meal and I feel super queasy  This was my first experience at sushi maru and I wont be back They clearly are not keeping their less popular items fresh Worst  dollars spent Please for your own safety do not order the uni sea urchin\n",
            "Best sushi at a reasonable price The nangook and uni and California roll topped w uni are some of my favorites\n",
            "my husband and I come here at least once a week food their food and reasonable price I always order their lunch combo its a great deal sometimes its hard to find parking here though\n",
            " The people So nice attentive and quick If you sit at the bar you can see how talented the chefs are and how fast The waitresses arent really waitresses they just all help each other out and are really nice   Also its pretty small and I wish it was more roomy its cozy and youre at least not completely elbow to elbow with the person next to you   The food YUMMMMMMM The spicy calamari is the best calamari Ive had in a LONGGGGG while Ask for it and theyll make it nice and warm We get a sushi with salmon and lemon on top of a California roll with some Siracha on top and its Delish  All in all I love this place Not my first time here and wont be the last They greet us so friendly when we come in and I love it\n",
            "The menu is slightly limited not many rolls no special rolls rolls come in  pieces at  per order  Lunch bento box is  The quality of food is good the raw fish tasted fresh and everything just tastes light as it should  Miso soup is top notch  Rolls are tasty They have a conveyer belt and if you have a group of  or more you can sit at an actual table next to the belt\n",
            "I seriously think about this place A LOT My go to things to order here halibut fin red snapper and nanookamazing  The service can be slow at times but theyre busy but if youre okay with my loud little nephew youre amazing to me  Plus the food I cant get enough ofremember to get their stamp card You now know where to spot me\n",
            "Food was pretty good with decent price The place has both sushi belt and tables so you can order with the server or may pick up  order to the sushiman The server doesnt come often to take your order so if youre not ordering hot food better off order to the sushi bar directly if youre eating at the booth or the bar\n",
            "It was my first time coming here for lunch with my dad We came around pm and decided to sit by the bar  For their food I just stuck with nigiri I ordered ebi and a tempura nigiri Their ebi tasted really fresh One of the freshest sushi Ive tasted I feel Their sushi rice is also good with its light sweetness and perfect texture The tempura nigiri was also delicious because they dipped the rice in some kind of sauce but it tasted delicious and it went well with the tempura My dad ordered the fried oysters for appetizers and he enjoyed them as well  Since we came close to closing time they would put two different kinds of sushi on one plate so you get more on one plate So awesome Itd be a shame wasting all that sushi anyways I would definitely come back for lunch\n",
            "My kids love this place They can each eat their own bowl of udon couple plates of sushi and edamame And theyll sit through the meal without asking for my phone so I can actually enjoy my kastsu donburi\n",
            "A great sushi boat type restaurant with delicious fresh fish My boyfriend and I sat at the conveyor belt and had two different rolls from it I also got the katsu don and he got the chefs special sushi My katsu don was delicious It was sweet and savory and the onions were delicious My boyfriend said he loved the fish selectiob and that the uni sea cucumber was absolutely amazing like butter Were definitely coming back to try more of the sushi boat rolls in the near future\n",
            "Sat at the bar and the service was terrible  Fish was presliced and the portion of fish for nigiri was very thin  Variety was Not very good most of the standard rolls included crab salad which i dont like  Not a very good value  Will not go back\n",
            "Fresh sushi and sashimi Check out the daily lunch special sometimes its pretty unique not regular items on the menu Atmosphere is friendly there could be a short line during lunch hours Finding a parking space nearby occasionally can be a challenge\n",
            "Ive been here at least  times over the last  years and its still consistent This place is always poppin which keeps everything on the conveyer belt fresh  I love their salmon teriyaki chicken teriyaki tempura katsu donburi nanook flame torched salmon belly nigiri unagi nigiri and chirashi  Fresh fish average prices Yum \n",
            "First time here and the people were very nice and the food was good Enjoyed the beef tariyaki and some of the sushis my friend was having me tryout\n",
            "Great place Cheap fresh quality food and prompt friendly service Waited a little to be seated but every single restaurant em Japatown has a waiting list  Baked mussle shooter are delicious here\n",
            "My go to sushi bar in San Jose  I have come here for many years and when I read yelp reviews for sushi restaurants I quickly appreciate that people dont know what good sushi tastes like  High quality authentic Japanese sushi and the prices havent gone up in years plus they give you a stamp card to come back\n",
            "Fresh and yummy\n",
            "My sister in law and brother in law took me here for the first tine  I must say I LOVE it  My favorite ones are the nanook and taiso ooooo good  Will definitely come back\n",
            "This location is definitely on the decline We stopped by yesterday for lunch My husband and I ordered the bento box and we both picked salmon and tuna sashimi The fish tasted old but the worst part was we got food poisoning from it Will never visit again\n",
            "Get nigiri here for the quality you get the price is unbelievable Make sure to get a stamp card for some savings here and there  Unagi nanook and saba are some of my favorites Their unagi nigiri is the best Ive had and only thing in the world I have to eat with my eyes closed every single time  My sister really enjoys their Toro too Their ginger is nice if you like to clean your palate without harassing your sinuses Green tea is delicious and comes piping hot Its a minus star because even though staff are very friendly they seem to get overwhelmed if theres a party of more than  in the restaurant The last time we went there was a birthday party of maybe  and we kept having to remind our server of some requests  The entree items also came out way slower than usual even though the restaurant wasnt filed \n",
            "I was on a shopping trip to SJ and fell into Sushi Maru We were headed to Gombei Japanese Restaurant when we arrived at Gombei we found out that they only took cash We walked to the bank to get cash and  the atm was broken Next to the bank with the broken atm was Sushi Maru Bam Divine intervention We had a wonderful dinner The service was very fast and friendly We both had the dinner combo the bento box and we both enjoyed it Dinner for two was under  A happy accident that I would be happy to repeat\n",
            "Not much of a wait during  lunch time It is somewhat busy Theres a sushi boat conveyor belt at the bar or you can sit at a regular table Service was fast too Sashimi was very fresh good quality and delicious Not to mention its not too expensive   I love white fish so I ordered mostly white fish sashimi Hamachi Albacore Toro Halibut Saba and two other ones I forgot the name Love the california rolls too Real crabmeat and huge The sushi rice was good too\n",
            "Showed up and there was no table my kid could get a high chair for without obstructing the walk ways The hostess who also busses tables and serves kindly asked if a table of  dudes drinking wouldnt mind moving to another table They agreed and we were seated Super accommodating The food was pretty dang good I walked out feeling  satisfied and thankful I live walking distance Only thing I have to say is TURN YOUR HEATER OFF It was so freakin hot in there  star none the less\n",
            "This cute little place opened in the early  and its delightful that it has remained among many other Jtown legends The conveyor belt sushi is fun and seems very fresh The cooked dishes are delicious as well It can take a while to be seated and to get your bill at the end\n",
            "We have been to many Sushi restaurants and this one truly is among  the best There pricing is lower than most and the qualiy at the top Friendly clean fast and tasty\n",
            "Went there for lunch today Sat at the conveyor because I like to eat quickly Was decent but plates are much more than the place in McCarthy ranch\n",
            "It is a nice authentic place My first time eating at conveyor belt sushi bar in the US  In Japan it is called Kaitenzushi and very popular but I had not known that it existed in the US   My friend and I ate  plates which means  pieces of sushi  I am crazy for salmon  I ate two kinds of salmon here raw and with tare Both great The Japanese chef in the bar was really nice and professional It is better to arrive by  pm otherwise a long line can be formed\n",
            "Walking around sj japantown in the carmeet and me and my sibs decide to eat some Japanese food This place is pretty busy but we got seated right away However we waited about  mins to have our order taken The food was decent It wasnt the best japanese food but it was okay I love how the waiters speak japanese though Overall experience was good and the food was decent\n",
            "I used to absolutely love this place and had recommended it to many many friends however the service has gone steadily downhill they hired a bunch of new servers that have dont have a clue what theyre doing It makes me sad because this was my goto Japanese place But with the service quality and you can tell her theres no one in the restaurant on Friday and Saturday night anymore its not the same owner has gotten cheap on service It breaks my heart as I will no longer be coming here\n",
            "got the beef teriyaki lunch not bad the sushi boat needs some work\n",
            "Great friendly service The tori kawa ponzu is my guilty pleasure fried chicken skin in ponzu sauce Sushi is great friendly chefs great waitresses No matter how busy they are always welcoming This is my new normal spot now that I have moved to San Jose I hope it always stays like this\n",
            "Sushi Maru in Jtown is top notch value I would say arguably the best value sushi in San Jose Now dont get me wrong when I say value the fish here is actually quite fresh and good Their daily lunch specials are always a really good deal usually coming with some kind of dashi based soup a mini chirashi bowl or tunadon and some other meat entree Their sushi and sashimi specials are also really quite good for how cheap they are and beautiful presentation too They dont take reservations here but if youre a regular you can get a discount card where they give you a  gift card every few visits Its a really solid place to have as your goto sushi place in SJ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLV5ZKQD-p4N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85a7d9e6-6dd0-4b7b-ada7-92c17da865e3"
      },
      "source": [
        "# We know that the word \"good\" has many senses, but they are generally\n",
        "# all positive as we saw in the WordNet work above. What if we just find\n",
        "# all the comments where a good-related word appears in the text?\n",
        "# Would that tell us anything about sentiment?\n",
        "\n",
        "# First, let's see if we can just match one word\n",
        "for g in data['Comments']:\n",
        "  if 'good' in g.lower():\n",
        "    print(g)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I am pleased to recommend this restaurant in San Jose's \"Japantown\"right next door to Union Bank. The restaurant is quite popular and fills up at lunchtime.  The service is fast and friendly.   There is a sushi-boat bar for those who are so inclined as it is definitely well-liked.  The booths are spacious and comfortable.  The  luncheon menu  is somewhat limited. Their tempura appetizer is really remarkable, both in taste and price, ample and affordable.  I was slightly disappointed in their salad dressing.  It's usually so good in Japanese restaurants. The restaurant is clean as is the ladies' room. Parking is not a problem. There is both street (metered) and lot parking.\n",
            "Sushi Maru is one of the many gems of SJ's Japan town. They have a rotating sushi belt, but also a solid menu of entrees as well as individual nigiri and hand roll options. My friend and I both ordered the Chef's sushi special and some hot sake- the toro and salmon belly with skin were to DIE for. It was a great way to get a taste of everything. I definitely want to come back and try some of the other entrees or for some more yummy nigiri, but ultimately...this is a very, very sushi place but not the best I've tried. I'd give 3.75 stars if I could  However, I'd still come back if I'm looking for a good spot in Japan town.\n",
            "Sushi Maru is a conveyor belt sushi restaurant and a popular lunch spot during the week. Unlike the Sushi Maru in Milpitas, this location has GOOD food. I've never really tried the sushi here and usually end up ordering from their lunch menu/specials. For about $10.99-12.99, you can get an entree (or two depending on if you opt for the combo) plus salad and soup. The options are decent and the food is filling. If you come here often, you probably already know about their stamp card. I think you need to spend $200 in six months in order to save $15 on your next bill.  This place opens at 11:30am during the week so come early because this place fills up quickly!\n",
            "Food: Sushi, bento, udon, donburi.....all consistent and good flavors. If you are seated at the sushi bar, you can order as needed as well as take from the conveyor belt. The rolls are good size and there is board of what fresh fish are available. The wasabi and ginger are in community containers, so you just be cautious, and you could ask for a fresh batch from behind the counter if you need to. Overall the dishes are consistent with what Japanese cuisine is and you will always have decent meal. Service: Sit at the booth closest to the sushi bar if you don't want to wait for you rolls as you can grab from the belt and order from the menu. Seats at the bar allow to order from the menu but the space is limited for bigger plates. When it gets busy you may wait a little longer for your orders. Ambiance: Clean, simple and good for smaller groups and easy to have conversations.\n",
            "I struggle with this joint.  To me it's a \"tweener\" meaning it's sometimes \"just-ok\" while others it's \"Not-ok.\"  Let's go with a true 2.5 Stars here. I've had good service and some not-so-good service here which is annoying.   The food isn't bad but the quality of the sushi is borderline and it's debatable on how long they've been riding the \"sushi-go-round.\"  Oh, and the price for sushi is in the realm of \"that wasn't worth it\" and \"stick to non-sushi dishes.\"\n",
            "Delicious food and great service, but a little expensive...  I'm a big fan of their pumpkin croquette and the nanook (seared salmon nigiri). Their dinner boxes and other sushi are pretty good too. Total cost for dinner for two: around $75. Not sure if this quite makes up for the price, but they do have a frequent diner's stamp card. However, there is a time frame that you have to earn the stamps within.  Sitting at the conveyor belt sushi bar was cho natsukashii (nostalgic).\n",
            "I've come here once before and the first time was good. This time... no. The food on the rotating bar was NOT fresh. The bento box was ok but as I was sitting there eating, the sushi chef started picking his nose and then picked up his phone and checked his POF account. Yeah, never coming here again.\n",
            "This place is amazing! The staff was so friendly and we were seated quickly (it was also 30 min from closing, so this could be different for earlier in the day). My partner and I decided to try a little bit of everything, so he got a plate that came with two entrées, salad, rice, and 3 CA rolls. I got a bowl of chicken udon noodles. We both shared the Nanook rolls and Jackson rolls. They were all so delicious! This place also has that cool conveyor belt for their sushi and you have the option of just eating those. Pricing for sushi is based on the kind of plate you get, lowest being $3.99 and highest being $6.49. Very good food, will be visiting again.\n",
            "This is my favorite sushi place in San Jose! Super good, super high quality too. Great people that work there. My family and I have been going to this restaurant for so long and it gets better and better! Really recommend going.\n",
            "Stopped by for a quick lunch on the way back from Santa Cruz. Although it was memorials day, I was surprised that the restaurant was only half full. We had a big group of 15, but were seated pretty quickly. It's a standard Japanese restaurant with bento boxes, sushi, and bowls.  They also have daily specials, which change everyday. I got the sushi lunch ($15.99) which comes with nigiri, baked fish, california role, oranges, and some small side dishes. It also comes with a salad and miso soup, which came out first. The sushi was pretty standard, I like how they didn't put a lot of rice with the sushi. The baked fish was pretty fatty, but it wasn't too salty or under seasoned. The seaweed salad on the side was he perfect pallete cleanser.  I also liked how the dish came with slices of Orange, which was refreshing after the meal. You get what you pay for and it was the perfect amount for me. Overall, a good Japanese restaurant with friendly staff and clean atmosphere.   Highly recommend stopping by if you are in San Jose Japan town.\n",
            "The plusses: Food is very good, service is friendly, reasonable price, and we didn't have to wait long.  Also, the sushi at the bar is all covered with plastic covers to keep it sanitary -- most restaurants just let it sit out exposed to the elements. The minuses: crowded, feels a bit cramped (they don't seem to make the best use of space the way other restaurants do in Japantown), and we had to sit at the sushi bar because they're aren't enough tables. Overall this was a very good restaurant, but if I ever go back I'll choose a time when it isn't rush hour.\n",
            "You need to chose the guy in the bar to make Nanook but not the women. She made it in heavy soil sauce flavor which cover all the salmon taste.  The bad thing is after I talked to the waiter, she asked me rudely 'so what do you want me to do?' Update 5/25/17 after a year visit again. Taste still good. Eggplant and kalbi recommend. Just don't argue the food with them you will be fine.\n",
            "So yummy here, we where here on Christmas Eve. And we wanted sushi, thank good it was open that day. Service was great, food was excellent and the employees where up to beat. I can't wait to eat here again. The bento  box was enough food for us to share.. we also got some sushi and oysters at the bar to keep us full. Hot tea is always a bonus..\n",
            "This is my favorite sushi place. The staff and chefs are friendly and always working hard. The location is located conveniently in downtown. Just a couple blocks away from Coleman and Taylor. This is my go to place. Whenever I have a craving for sushi, I always end up choosing their teriyaki salmon over the sushi on the conveyor belt. It's not that the I don't like their sushi, it's just that their salmon is REALLY good. It's never dry and it's never too saucy. Also, they have THE best baked mussels out there. Its always made fresh to order, so it always comes out hot. Its very flavorful: Its sweet, chewy, and a little bit spicy. Other places can't compare.  Some drawback is that it is quite small inside. It can get pretty crowded and you while you're seated, you may have to wait a little while until more sushi plates are placed on the belt. They also don't have those special sushi rolls like the \"Dragon roll\" or \"Spider-Man roll.\" But it's okay, you're in Japantown. This ain't no Asian fusion place. With all that, I don't mind the wait. It's amazing to watch and see how the chefs move so quickly. I always end up having a good time and I leave with my belly full! Can't complain about that\n",
            "Best bento place ever! We eat here like every month. We get the Chicken Teriyaki and Katsu Combo & Lion King Roll. The best, they never disappoint. Plus, very affordable and great customer service. I'm speechless. They're that good!\n",
            "I came here for lunch today with my friend and his Mom, and was surprised when I saw that it was a sushi boat place. I had never come to a sushi boat place before because my Dad is a sushi snob. I was surprised by how much space the conveyer belt took up.  The sushi conveyer belt was an efficient way to add things to your order, but over time, as more people took sushi from the conveyer belt, there weren't many things to grab.  Therefore we needed to ask the sushi chef to make the sushi for us, which defeated the purpose of the conveyer belt. My friend recommended getting the nanook, which was seared salmon with a sweet sauce. When I first bit into the salmon, a bunch of fat poured out from the searing. The searing also made the salmon much softer, and brought out a lot of the natural salmon flavor. Most of the fish was decent quality, except for the tuna, which didn't have much flavor and was a little hard. Overall, this is a pretty good meal, and if you take advantage of the conveyer belt, you can really fill yourself up here.\n",
            "I had the Chicken teriyaki and Salmon along with the Eel and Octopus Sushi and it was very good. The service here was very fast and friendly. Prices for what you get are reasonable. I would definitely come back again.\n",
            "Our families favorite sushi spot here in Japantown. Love the options and the chefs really make sure you are full and happy. Sushi boat has good options and more you can choose from on the far wall. More of a traditional style sushi, not many fancy specialty rolls. Bento Boxes seem to be filling as well. Overall, have great experience here and we continue to go back when we are walking down Japantown for sushi.\n",
            "The menu is slightly limited, not many rolls (no special rolls, rolls come in 2-6 pieces at 2.99-5.99 per order).  Lunch bento box is $11. The quality of food is good (the raw fish tasted fresh) and everything just tastes light, as it should.  Miso soup is top notch.  Rolls are tasty. They have a conveyer belt, and if you have a group of 3 or more you can sit at an actual table next to the belt.\n",
            "Food was pretty good with decent price. The place has both sushi belt and tables so you can order with the server or may pick up & order to the sushiman. The server doesn't come often to take your order so if you're not ordering hot food, better off order to the sushi bar directly if you're eating at the booth or the bar.\n",
            "It was my first time coming here for lunch with my dad! We came around 1pm and decided to sit by the bar.  For their food, I just stuck with nigiri. I ordered ebi and a tempura nigiri. Their ebi tasted really fresh. One of the freshest sushi I've tasted I feel. Their sushi rice is also good with its light sweetness and perfect texture. The tempura nigiri was also delicious because they dipped the rice in some kind of sauce, but it tasted delicious and it went well with the tempura. My dad ordered the fried oysters for appetizers and he enjoyed them as well.  Since we came close to closing time, they would put two different kinds of sushi on one plate so you get more on one plate! So awesome. It'd be a shame wasting all that sushi anyways. I would definitely come back for lunch!\n",
            "Sat at the bar and the service was terrible.  Fish was presliced and the portion of fish for nigiri was very thin.  Variety was Not very good, most of the standard rolls included crab salad, which i dont like.  Not a very good value.  Will not go back.\n",
            "First time here and the people were very nice and the food was good. Enjoyed the beef tariyaki and some of the sushi's my friend was having me tryout.\n",
            "My go to sushi bar in San Jose.  I have come here for many years and when I read yelp reviews for sushi restaurants I quickly appreciate that people don't know what good sushi tastes like.  High quality, authentic Japanese sushi, and the prices haven't gone up in years plus they give you a stamp card to come back.\n",
            "My sister in law and brother in law took me here for the first tine.  I must say, I LOVE it!  My favorite ones are the nanook and tai....so ooooo good!  Will definitely come back!\n",
            "Not much of a wait during 12:30 lunch time. It is somewhat busy. There's a sushi boat conveyor belt at the bar or you can sit at a regular table. Service was fast too. Sashimi was very fresh, good quality, and delicious! Not to mention, its not too expensive.   I love white fish so I ordered mostly white fish sashimi. Hamachi, Albacore, Toro, Halibut, Saba and two other ones I forgot the name. Love the california rolls too! Real crabmeat and huge. The sushi rice was good too.\n",
            "Showed up and there was no table my kid could get a high chair for without obstructing the walk ways. The hostess, who also busses tables and serves, kindly asked if a table of 3 dudes drinking wouldn't mind moving to another table. They agreed and we were seated. Super accommodating. The food was pretty dang good. I walked out feeling %100 satisfied and thankful I live walking distance. Only thing I have to say is TURN YOUR HEATER OFF!!! It was so freakin hot in there. 5 star none the less.\n",
            "Walking around sj japantown in the carmeet and me and my sibs decide to eat some Japanese food. This place is pretty busy but we got seated right away. However, we waited about 20 mins to have our order taken. The food was decent. It wasnt the best japanese food but it was okay. I love how the waiters speak japanese though. Overall experience was good and the food was decent.\n",
            "Sushi Maru in Jtown is top notch value. I would say arguably the best value sushi in San Jose. Now, don't get me wrong when I say value, the fish here is actually quite fresh and good. Their daily lunch specials are always a really good deal, usually coming with some kind of dashi based soup, a mini chirashi bowl or tuna-don, and some other meat entree. Their sushi and sashimi specials are also really quite good for how cheap they are (and beautiful presentation too!). They don't take reservations here, but if you're a regular, you can get a discount card where they give you a $15 gift card every few visits. It's a really solid place to have as your \"go-to\" sushi place in SJ.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGT9sL2y_8Td",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e78c482b-00a5-439d-aa9b-75cfdbbb0069"
      },
      "source": [
        "# Before moving on, make sure to take a careful look at the list of comments\n",
        "# above. Each should contain the word \"good.\" What do you observe?\n",
        "\n",
        "# Now look for good AND all of its synonyms. Notice the use of set().\n",
        "lemmas = set([s.lemma_names()[0] for s in wn.synsets('good')])\n",
        "\n",
        "# This is going to be a longer list, so let's just count the matches for now\n",
        "# rather than printing them all.\n",
        "matches = 0\n",
        "\n",
        "for g in data['Comments']:\n",
        "  for l in lemmas:\n",
        "    if l in g.lower():\n",
        "      matches += 1\n",
        "\n",
        "\n",
        "print(matches)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBnFhZesBBgA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2120ee7e-46b6-486f-c446-907bddbd9100"
      },
      "source": [
        "# That's useful: We got a lot of mentions of all good-related words\n",
        "# in the 70 comments stored in this dataset. This time we will count \n",
        "# how many matches we get per comment.\n",
        "\n",
        "lemmas = set([s.lemma_names()[0] for s in wn.synsets('good')])\n",
        "\n",
        "# Here we will assign matches into a list containing 70 elements\n",
        "matches = [0] * data.shape[0] # Fill a list with 70 zeroes\n",
        "\n",
        "# This loop uses an enumerator, which is a cool Python solution to a \n",
        "# common programming problem. The \"i\" that the enumerator produces is the\n",
        "# index of the corresponding g. In this case the \"g\"s are the comments\n",
        "# extracted from each successive row. \n",
        "for i, g in enumerate(data['Comments']): # Loop over all comments\n",
        "  for l in lemmas:  # Loop over all lemmas of good\n",
        "    if l in g.lower(): # If we get a match, increment the count\n",
        "      matches[i] += 1\n",
        "\n",
        "len(matches) # We should have 70 entries"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "70"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSgqQwI1DYPu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "ca93923a-ac90-4334-8f40-34b4af476076"
      },
      "source": [
        "# What's the distribution of counts \n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(matches)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([35.,  0.,  0., 27.,  0.,  0.,  7.,  0.,  0.,  1.]),\n",
              " array([0. , 0.3, 0.6, 0.9, 1.2, 1.5, 1.8, 2.1, 2.4, 2.7, 3. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Discuss With Your Partner\n",
        "\n",
        "Interpret the histogram above. What does the leftmost bar signify? It looks like there are 35 of something? What? \n",
        "\n",
        "Also, what's the maximum number of matches found in a comment?"
      ],
      "metadata": {
        "id": "J9M6Ovk48bq_"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZOQ0b7CEoaz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d07d8b9-a6a7-4c3a-8e4f-627ee0a7790c"
      },
      "source": [
        "# Let's use pandas to calculate the simple Pearson's correlation between\n",
        "# the sentiment score in the data set and the count of good-related words.\n",
        "x = pd.Series(data['Sentiment Score'])\n",
        "y = pd.Series(matches)\n",
        "x.corr(y)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.12068240259212179"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaL7cRS-FSJ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "535c5fc8-eeff-48ae-eb92-4fe9fc342013"
      },
      "source": [
        "# Well, that's not a very strong result, but what if we used the word\n",
        "# bad instead of the word good. Would that make any difference?\n",
        "# (Use a separate code block for each task.)\n",
        "\n",
        "# 4.11: Copy the loop from four blocks above and change from good to bad\n",
        "lemmas = set([s.lemma_names()[0] for s in wn.synsets('bad')])\n",
        "\n",
        "# Here we will assign matches into a list containing 70 elements\n",
        "matches2 = [0] * data.shape[0] # Fill a list with 70 zeroes\n",
        "\n",
        "# This loop uses an enumerator, which is a cool Python solution to a \n",
        "# common programming problem. The \"i\" that the enumerator produces is the\n",
        "# index of the corresponding g. In this case the \"g\"s are the comments\n",
        "# extracted from each successive row. \n",
        "for i, g in enumerate(data['Comments']): # Loop over all comments\n",
        "  for l in lemmas:  # Loop over all lemmas of good\n",
        "    if l in g.lower(): # If we get a match, increment the count\n",
        "      matches2[i] += 1\n",
        "\n",
        "len(matches2) \n"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "70"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.12: Create a histogram of matches\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(matches)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "Pl7whI2T01Q2",
        "outputId": "3cd2172f-3735-4288-ffc2-ac53929ed04c"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([67.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  3.]),\n",
              " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 126
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.13: Write a comment interpreting the histogram\n",
        "\n",
        "#'Bad' word also occurs 70 times. However, the words that match its meaning is only two. \n",
        "#Hence the historgram is distributed between 0 and 1\n",
        "#We have only two synonyms for 'bad'\n",
        "#First one occurs 65 times and second one occurs 5 times"
      ],
      "metadata": {
        "id": "Tffx5VMt04Bh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.14: Calculate the correlation between Sentiment Score and matches\n",
        "x = pd.Series(data['Sentiment Score'])\n",
        "y = pd.Series(matches2)\n",
        "x.corr(y)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-KRbVs-05qI",
        "outputId": "bef2c0bb-3e2d-43db-c920-a3385eb8d083"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.1877341356444923"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOunXc1JO-0o"
      },
      "source": [
        "The approach we took above depends on the a priori assumption that the positive and negative meanings of words as determined by WordNet are the most appropriate way to score these comments. But what if we turned the puzzle around and let the comments \"tell\" us which words are the best? We can use a simple geometric technique called Linear Discriminant Analysis to accomplish this for us. Don't worry about the math for this: Just keep in mind that we are going to divide the dataset into two groups - a positive group and a negative group - and then find out to what degree each word functions differently in those two groups.\n",
        "\n",
        "As we demonstrated in lab 3, we are going to use a vectorizer to represent what each word does in each document. As a reminder, TF-IDF stands for \"term frequency, inverse document frequency\" which is an alternative to the raw count of each word in a document that gives more weight to rare words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bfT4lvbj3a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed6a3188-1a37-4975-c346-73d6e109df35"
      },
      "source": [
        "# To perform the LDA calculation, we need a TF-IDF matrix, just like in Lab 3\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.tokenize.casual import casual_tokenize\n",
        "\n",
        "# We're keeping it simple for now, no special preprocessing. For example,\n",
        "# we're leaving in stop words.\n",
        "tfidfingest = TfidfVectorizer(tokenizer=casual_tokenize)\n",
        "type(tfidfingest) # We've created an instance of our vectorizer"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sklearn.feature_extraction.text.TfidfVectorizer"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RopuuGmldTw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f5ba053-8770-4f60-e65b-ea7a192a00b4"
      },
      "source": [
        "# Now we have the tool we need to create the TF-IDF matrix: tfidfingest can\n",
        "# be used to \"eat up\" the text data from our dataset.\n",
        "tfidfmatrix = tfidfingest.fit_transform(raw_documents=data['Comments']).toarray()\n",
        "\n",
        "tfidfmatrix.shape, type(tfidfmatrix)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((70, 1254), numpy.ndarray)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLlKcuznmfu1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50efa4bf-18b0-4861-9fc8-2eeaf62b6fe1"
      },
      "source": [
        "# The 1254 columns is saying that we have 1254 unique terms in our vectorized\n",
        "# dataset. Usually we would want to work a lot harder to get this number down.\n",
        "\n",
        "# Remember that an array in numpy is a matrix-like object containing\n",
        "# values all of the same type.\n",
        "\n",
        "# What's in our array?\n",
        "tfidfmatrix[:10,:5] # Just the first ten rows and five columns"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.11255423, 0.        , 0.053985  , 0.        , 0.        ],\n",
              "       [0.        , 0.15665963, 0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.22535615, 0.        , 0.0540444 , 0.        , 0.07541902],\n",
              "       [0.0478254 , 0.        , 0.20644883, 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.15721287, 0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkLSbvDDos0I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e64f8b4-0c31-425f-e645-38512d48647c"
      },
      "source": [
        "# Typical sparse array: Mostly zeroes. The non-zero values are fractional,\n",
        "# showing that this is TF-IDF and not an array of simple counts.\n",
        "\n",
        "# Now let's subdivide our original dataset based on whether each row was classed\n",
        "# as a positive or negative comment. \n",
        "\n",
        "# Here we are creating what Python programmers sometimes call a \"mask.\"\n",
        "# The first mask will let us select the positive cases. The second mask will\n",
        "# let us select the negative cases.\n",
        "\n",
        "classlist = [(c==\"Positive\" or c==\"Neutral\") for c in data['Sentiment Label']] # Positive mask\n",
        "notclasslist = [not c for c in classlist] # Negative mask\n",
        "\n",
        "print(classlist[:8]) # Compare the first 8 results from the two masks\n",
        "print(notclasslist[:8]) # Entries in these two lists should be boolean inverses"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[True, True, True, False, True, True, True, False]\n",
            "[False, False, False, True, False, False, False, True]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFlH9wztplQm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60c81136-705d-424b-c22d-50fcfd56deaf"
      },
      "source": [
        "# We can use the masks to select the cases we want and the mean method\n",
        "# to summarize our tfidf for each subset of the data\n",
        "\n",
        "# Centroid means \"a point in space that is in the middle of a bunch of other points\"\n",
        "poscentroid = tfidfmatrix[classlist].mean(axis=0)\n",
        "negcentroid = tfidfmatrix[notclasslist].mean(axis=0)\n",
        "\n",
        "separator = poscentroid - negcentroid # The difference in means for each word\n",
        "\n",
        "separator"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.05894595, -0.11399296,  0.01746025, ...,  0.00252529,\n",
              "        0.00154828,  0.01642816])"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENY7F-KtEZo2"
      },
      "source": [
        "We just did quite a bit of math in a couple easy steps. When we computed each of the two centroids by taking the mean down the column, we summarized the \"activity\" of each word across all of the comments in each of the two subsets of the data. So for example, if \"good\" is important in positive reviews, the mean of its TF-IDF values across all the positive reviews should be high.\n",
        "\n",
        "The final step in the previous code block is really interesting. By subtracting the two centroids, we get a representation of whether a word does something *different* in the two datasets. We call it \"separator\" because it represents a kind of dividing structure between the positive and negative data subsets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHcE2rk6wBTI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55b6ab03-575d-4824-b0f5-00ce7c21c6f4"
      },
      "source": [
        "# Now let's take our separator and put it together in a little\n",
        "# dataset with the list of tokens, so we can see what's going on.\n",
        "wordsent = pd.DataFrame({\n",
        "    \"Token\":list(tfidfingest.get_feature_names_out()),\n",
        "    \"Sentiment\":list(separator)\n",
        "})\n",
        "\n",
        "# Here we sort the cases from lowest to highest, based on the \n",
        "# value that we took from separator.\n",
        "wordsent.sort_values(by=['Sentiment'], inplace=True)\n",
        "\n",
        "wordsent.shape, list(wordsent) # Summarize our data frame"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1254, 2), ['Token', 'Sentiment'])"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oolTGPU08xo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "outputId": "ba46f5a5-48c1-4b5d-9036-ffd9704f7977"
      },
      "source": [
        "# After sorting, the \"most negative\" words are at the beginning of\n",
        "# the data frame and the \"most positive\" words are at the end. Let's\n",
        "# Take a look:\n",
        "\n",
        "wordsent.head(15) # Give us 15 words that are most negative"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Token  Sentiment\n",
              "1            \"  -0.113993\n",
              "1076       the  -0.050822\n",
              "1214     which  -0.048907\n",
              "200        but  -0.047988\n",
              "948        she  -0.044887\n",
              "436       fish  -0.044311\n",
              "78    agedashi  -0.043009\n",
              "1104      tofu  -0.043009\n",
              "87     alright  -0.043009\n",
              "425        few  -0.042864\n",
              "762    ordered  -0.042253\n",
              "1168     visit  -0.038870\n",
              "684       most  -0.038832\n",
              "1206      were  -0.036540\n",
              "1219      will  -0.036013"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c7607035-65ef-4db1-b99b-5238a44e6e8a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Token</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"</td>\n",
              "      <td>-0.113993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1076</th>\n",
              "      <td>the</td>\n",
              "      <td>-0.050822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1214</th>\n",
              "      <td>which</td>\n",
              "      <td>-0.048907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200</th>\n",
              "      <td>but</td>\n",
              "      <td>-0.047988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>948</th>\n",
              "      <td>she</td>\n",
              "      <td>-0.044887</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>436</th>\n",
              "      <td>fish</td>\n",
              "      <td>-0.044311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>agedashi</td>\n",
              "      <td>-0.043009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1104</th>\n",
              "      <td>tofu</td>\n",
              "      <td>-0.043009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>alright</td>\n",
              "      <td>-0.043009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>425</th>\n",
              "      <td>few</td>\n",
              "      <td>-0.042864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>762</th>\n",
              "      <td>ordered</td>\n",
              "      <td>-0.042253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1168</th>\n",
              "      <td>visit</td>\n",
              "      <td>-0.038870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>684</th>\n",
              "      <td>most</td>\n",
              "      <td>-0.038832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1206</th>\n",
              "      <td>were</td>\n",
              "      <td>-0.036540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1219</th>\n",
              "      <td>will</td>\n",
              "      <td>-0.036013</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c7607035-65ef-4db1-b99b-5238a44e6e8a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c7607035-65ef-4db1-b99b-5238a44e6e8a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c7607035-65ef-4db1-b99b-5238a44e6e8a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MM-7CNaP1VmQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "outputId": "12ad3c82-a64c-4ab2-ffcb-302c008daf39"
      },
      "source": [
        "wordsent.tail(15) # Give us 15 words that are most positive"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Token  Sentiment\n",
              "161        best   0.021562\n",
              "1074       that   0.021747\n",
              "312   delicious   0.021767\n",
              "806       place   0.022676\n",
              "252        come   0.022697\n",
              "209         can   0.024593\n",
              "1101         to   0.024680\n",
              "761       order   0.025505\n",
              "1033      sushi   0.027182\n",
              "491       great   0.027710\n",
              "455       fresh   0.028815\n",
              "510        have   0.030804\n",
              "111         are   0.036204\n",
              "100         and   0.039881\n",
              "0             !   0.058946"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0b381bc7-29d3-4513-b931-986917e91bab\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Token</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>161</th>\n",
              "      <td>best</td>\n",
              "      <td>0.021562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1074</th>\n",
              "      <td>that</td>\n",
              "      <td>0.021747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>312</th>\n",
              "      <td>delicious</td>\n",
              "      <td>0.021767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>806</th>\n",
              "      <td>place</td>\n",
              "      <td>0.022676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>252</th>\n",
              "      <td>come</td>\n",
              "      <td>0.022697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209</th>\n",
              "      <td>can</td>\n",
              "      <td>0.024593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1101</th>\n",
              "      <td>to</td>\n",
              "      <td>0.024680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>761</th>\n",
              "      <td>order</td>\n",
              "      <td>0.025505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1033</th>\n",
              "      <td>sushi</td>\n",
              "      <td>0.027182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>491</th>\n",
              "      <td>great</td>\n",
              "      <td>0.027710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>455</th>\n",
              "      <td>fresh</td>\n",
              "      <td>0.028815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>510</th>\n",
              "      <td>have</td>\n",
              "      <td>0.030804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>are</td>\n",
              "      <td>0.036204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>and</td>\n",
              "      <td>0.039881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>!</td>\n",
              "      <td>0.058946</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0b381bc7-29d3-4513-b931-986917e91bab')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0b381bc7-29d3-4513-b931-986917e91bab button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0b381bc7-29d3-4513-b931-986917e91bab');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8brSoputGKTP"
      },
      "source": [
        "Well, not everything in those lists makes sense, but remember that this is a really small dataset and we did not make the effort to filter out stop words or punctuation. Still, there's some interesting stuff in there, and we've shown how with a few simple steps, we can create a kind of \"empirical\" sentiment value for each word.\n",
        "\n",
        "The next step also uses a cool matrix math trick. By creating *dot products* of the separator vector with the TF-IDF vector for each of our 70 comments, we can summarize the similarity/distance of a given comment from the dividing structure. Maybe the resulting document scores will be useful for something."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y78fidHG5Bk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "329e6519-b343-43e9-f81a-f939c6ef7455"
      },
      "source": [
        "docusent = tfidfmatrix.dot(separator)\n",
        "docusent"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.03190957,  0.00489625,  0.02053524, -0.1131945 ,  0.0068361 ,\n",
              "        0.03714363,  0.05276984, -0.1372704 ,  0.01527414,  0.04051255,\n",
              "       -0.13587406,  0.03995574,  0.00276345, -0.00473419,  0.03760517,\n",
              "        0.02651981,  0.06201844,  0.00034177, -0.01263898,  0.03052205,\n",
              "        0.02293302,  0.0197362 , -0.13294862,  0.02436511,  0.03068126,\n",
              "        0.01019862,  0.00424415,  0.01116213,  0.04171756,  0.03642798,\n",
              "        0.03830759,  0.0108454 ,  0.04254235,  0.00893868,  0.03582491,\n",
              "        0.03351333,  0.03417034,  0.03088434, -0.00089552,  0.04566911,\n",
              "        0.04567206,  0.05179615,  0.03851501,  0.04892801,  0.03642214,\n",
              "        0.02451584,  0.03657144,  0.03245421, -0.12116866,  0.01874153,\n",
              "        0.02458296, -0.00526663,  0.04728941,  0.0562507 ,  0.03587462,\n",
              "        0.04009349, -0.12562397,  0.0534958 ,  0.02060276,  0.02848552,\n",
              "        0.03458464,  0.04533432,  0.04616221,  0.01689287,  0.02849751,\n",
              "        0.0065034 ,  0.02493422, -0.01567791,  0.05086638,  0.02925724])"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwANGGz1HTG7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ee05c8a-fd48-4627-d9d8-e144e3a6f508"
      },
      "source": [
        "x = pd.Series(data['Sentiment Score']) # Here's the sentiment score from the data\n",
        "y = pd.Series(docusent) # Here's our calculated separation of each document from the divider\n",
        "x.corr(y).round(3)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.618"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YL8H49JirFFp"
      },
      "source": [
        "# Checkpoint! Write your name and this correlation value on the whiteboard\n",
        "\n",
        "That's a way better result than what we got by counting WordNet synonyms. We shouldn't get too excited though, because we did not hold out a test set to verify our results, so it is likely that these results are peculiar to this sample of texts. \n",
        "\n",
        "The important thing to note is this: If we have a training criterion (in this case we used Sentiment Label), we can easily process our text in a way that shows us which words are associated with positive sentiment and which words are associated with negative sentiment. Of course sentiment is only one small aspect of semantics as a whole: A word like \"fresh\" can be strongly positive while still containing many other shades of meaning.\n",
        "\n",
        "We used a simple mathematical method to tease out this thin slice of semantics in a somewhat primitive way. As we go further into the course, we are going to learn additional methods for having the data tell us about the meanings of words. Because of the rapid evolution of deep learning techniques and their proven success in so many NLP tasks, many researchers believe that the age of maintaining large, manually-created dictionaries is over.\n",
        "\n",
        "To close this section and get a little practice, let's go back to the vectorization process, take out stop words, and then reproduce the analysis demonstrated above:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Super bonus task! Make sure that you will have time to get the next section\n",
        "# done before doing this task.\n",
        "# \n",
        "# 4.15: Return to the call to TfidfVectorizer above, and add this argument:\n",
        "#\n",
        "# stop_words=\"english\"\n",
        "# \n",
        "# Then rerun all the code up to here. Add a comment saying whether the \n",
        "# correlation value from the last step above changed. If the correlation\n",
        "# got larger, add a comment saying why you think that happened.\n",
        "#"
      ],
      "metadata": {
        "id": "LwTD-0BGrsKM"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxICzoqWxglk"
      },
      "source": [
        "**Part 3: Latent Dirichlet Allocation**\n",
        "\n",
        "What have we done so far? We used WordNet and found that large, expert teams of researchers can create a tree structure for the meanings of words. We can find word similarity, synonyms, antonyms, hypernyms, and hyponyms from this structure. We also found that given a training criterion and a bunch of labeled data, we can tease out some aspects of the meanings of words using data analysis rather than a manual dictionary-building process. Now let's synthesize some of that thinking with a new technique that groups words together and uses those groupings to create compact representations of documents.\n",
        "\n",
        "This new technique is known as Latent Dirichlet Allocation, and its application to NLP was pioneered by David Blei and Andrew Ng. The name sounds complicated, but Latent is the idea that there are unobservable \"topics\" that can be used to represent documents, Dirichlet refers to a family of statistical distributions that are good for representing probabilities, and Allocation just means that we are going to use the statistical distributions to allocate words to topics and topics to documents.\n",
        "\n",
        "We'll start again with a vectorizer, this time just a simple count of words:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGJAKB1X0ipv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c27e4d5-def8-41b5-e770-6f76455f3d41"
      },
      "source": [
        "# Begin by creating a new vectorizer instance\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Create an instance of the count vectorizer. Do some filtering:\n",
        "# A word has to appear in at least two documents\n",
        "# A word can't appear in more than 90% of the documents\n",
        "# Take out stop words\n",
        "counter = CountVectorizer(min_df=2, max_df=0.9, \n",
        "                          tokenizer=casual_tokenize, stop_words='english')\n",
        "\n",
        "# Use the comments from the dataset to generate a sparse matrix of word counts\n",
        "countmatrix = counter.fit_transform(raw_documents=data['Comments']).toarray()\n",
        "\n",
        "countmatrix.shape, type(countmatrix) # Rows? Columns? Type?"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((70, 408), numpy.ndarray)"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cs_WLe8K1OAG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "febdcf9f-3db0-45a6-9fa7-01104eb145d0"
      },
      "source": [
        "# When we want to do calculations or transformations on a sparse matrix, we\n",
        "# usually need to convert it to a data frame first.\n",
        "countdf = pd.DataFrame(countmatrix, columns=counter.get_feature_names_out())\n",
        "\n",
        "countdf.shape, type(countdf) # Rows? Columns? Type?"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((70, 408), pandas.core.frame.DataFrame)"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGteB8nT58oa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "aabc7707-6e7c-4c73-8369-0360af96a714"
      },
      "source": [
        "# Take a look at the first few rows of the data frame using the head() method. \n",
        "# There should be no fractional values, showing that it is a count matrix \n",
        "# rather than tf-idf.\n",
        "\n",
        "#\n",
        "# 4.16 - Show the first few rows of the data frame.\n",
        "#\n",
        "countdf.head()"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   !  \"  $  %  &  '  (  )  ,  -  ...  white  won't  work  worst  worth  \\\n",
              "0  3  0  1  0  0  0  4  4  4  4  ...      0      0     0      0      0   \n",
              "1  0  2  0  0  0  1  1  1  2  0  ...      0      0     0      0      0   \n",
              "2  0  0  0  0  0  0  0  0  0  0  ...      0      0     0      0      0   \n",
              "3  0  0  0  0  0  0  0  0  2  0  ...      0      0     0      0      0   \n",
              "4  0  0  0  0  0  0  0  0  4  1  ...      0      0     0      0      0   \n",
              "\n",
              "   wouldn't  wrong  years  you're  yummy  \n",
              "0         0      1      0       0      0  \n",
              "1         0      0      0       0      0  \n",
              "2         0      0      0       0      0  \n",
              "3         0      0      0       0      0  \n",
              "4         0      0      0       0      1  \n",
              "\n",
              "[5 rows x 408 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e893810f-2a69-4fd8-b909-cac337e7a2e7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>!</th>\n",
              "      <th>\"</th>\n",
              "      <th>$</th>\n",
              "      <th>%</th>\n",
              "      <th>&amp;</th>\n",
              "      <th>'</th>\n",
              "      <th>(</th>\n",
              "      <th>)</th>\n",
              "      <th>,</th>\n",
              "      <th>-</th>\n",
              "      <th>...</th>\n",
              "      <th>white</th>\n",
              "      <th>won't</th>\n",
              "      <th>work</th>\n",
              "      <th>worst</th>\n",
              "      <th>worth</th>\n",
              "      <th>wouldn't</th>\n",
              "      <th>wrong</th>\n",
              "      <th>years</th>\n",
              "      <th>you're</th>\n",
              "      <th>yummy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 408 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e893810f-2a69-4fd8-b909-cac337e7a2e7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e893810f-2a69-4fd8-b909-cac337e7a2e7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e893810f-2a69-4fd8-b909-cac337e7a2e7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eME0JfruCfwc"
      },
      "source": [
        "We've vectorized our documents with word counts, creating a document term matrix. Next, we will use Sci-Kit Learn to fit a Latent Dirichlet Allocation model. This is a stochastic process, because Bayesian estimation methods are used to overcome serious complexities in the math. In order to demonstrate a result that is consistent across runs, we set a random number seed here. \n",
        "\n",
        "We also must set a specific number of topics that we want to model. There are empirical guides for deciding how many topics are needed to model a particular dataset. For now, we will use a relatively small number and just consider it to be an acceptable guess.\n",
        "\n",
        "When we fit our model, we will first obtain a word-topic matrix. This shows the strength of connection between each term in our document-term matrix and each of the topics. In the Sci-Kit Learn implementation, this output is formatted as \"pseudocounts,\" i.e., the number of times that the term could be expected to show up for that topic (in light of the model's prediction). You may encounter other software for doing LDiA that shows term-topic probabilities, in which case all values will show as <= 1.0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NMv4rqb6qPV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "010b1be0-e259-4af5-c203-0e731b13443d"
      },
      "source": [
        "# Sci-Kit learn has a Latent Dirichlet Allocation fitting algorithm that we\n",
        "# can use. \n",
        "from sklearn.decomposition import LatentDirichletAllocation as LDIA\n",
        "from numpy import random as rnd\n",
        "rnd.seed(123)\n",
        "\n",
        "numtopics = 9 # Later on you will change this as an exercise.\n",
        "\n",
        "# Create an instance of the LDIA analyzer\n",
        "ldiamodel = LDIA(n_components=numtopics, learning_method='batch')\n",
        "\n",
        "# Provide the pandas data frame of word counts for it to work on\n",
        "ldiamodel = ldiamodel.fit(countdf)\n",
        "\n",
        "ldiamodel.components_.shape # What is the resulting data frame like?"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9, 408)"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7SdZyuQtAfQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aac82e04-36f8-4bcf-f234-c2dc6d6a455f"
      },
      "source": [
        "# Each row repesents one topic, and each entry in a row\n",
        "# pertains to one of the terms in our count matrix. Let's examine\n",
        "# just the first five entries in each row. Remember that these are\n",
        "# pseudocounts and not probability values. \n",
        "ldiamodel.components_[:numtopics,:5]"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.11107766,  4.11114844,  1.11109594,  0.11111111,  0.11111111],\n",
              "       [ 0.11125124,  0.11111111,  0.97980161,  0.11111111,  1.11112435],\n",
              "       [ 0.11111899,  2.11111287,  2.11111606,  0.11111111,  0.11111111],\n",
              "       [ 9.89858297,  0.11111111,  1.60645729,  0.11111111,  0.87929276],\n",
              "       [ 0.11111112,  0.11111112,  0.11111112,  0.11111112,  0.11111112],\n",
              "       [ 7.64300236, 20.11106664,  7.44997875,  1.11111118,  0.11111111],\n",
              "       [42.79141612,  0.11111648,  2.40814966,  1.11111101,  1.34291621],\n",
              "       [ 3.11128055,  0.11111112,  0.11111112,  0.11111112,  0.11111112],\n",
              "       [ 2.11115898,  0.11111111,  2.11117846,  0.11111112,  0.11111111]])"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x989zdlOqjxN"
      },
      "source": [
        "# Here's a function for showing the top ten words for each topic. This was\n",
        "# adapted from an example in the SciKit Learn documentation.\n",
        "\n",
        "# The model is the fitted model, the vectorizer is the initalized instance\n",
        "# of the count vectorizer, and top_words sets how many of the most\n",
        "# influential words you want to see.\n",
        "def selected_topics(model, vectorizer, top_words=10):\n",
        "    for idx, topic in enumerate(model.components_):\n",
        "        print(\"Topic %d:\" % (idx)) # One of these headers for each topic\n",
        "        \n",
        "        # This uses a list comprehension to iterate over the words\n",
        "        # in each topic, picking out the highest coefficient values.\n",
        "        print([(vectorizer.get_feature_names_out()[i], topic[i])\n",
        "                        for i in topic.argsort()[:-top_words - 1:-1]]) "
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBYH9_9Kq1-v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73deca57-fb02-45c2-86a1-0b12980dde75"
      },
      "source": [
        "# Here we call our function\n",
        "selected_topics(ldiamodel, counter, top_words=10)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 0:\n",
            "[(',', 15.111341076976649), ('sushi', 12.111324065910685), (\"it's\", 6.111247105085878), ('food', 5.111233201946385), ('good', 5.111230365526831), ('place', 4.111215047432107), ('japanese', 4.111196331523579), (\"don't\", 4.111171989763613), ('\"', 4.111148437552365), ('little', 3.111220809173756)]\n",
            "Topic 1:\n",
            "[('sushi', 7.725661982034617), ('order', 6.080713573853641), (',', 4.972983349706635), ('-', 4.111152733351147), ('roll', 3.98315351449739), (')', 3.811938301418745), ('(', 3.8058074356087204), ('dinner', 3.089288756356988), ('belt', 3.0222951938584166), ('bar', 2.9186287763305203)]\n",
            "Topic 2:\n",
            "[('sushi', 9.769405337602432), (',', 6.328024454704488), ('fresh', 5.111216601182591), ('food', 4.291097283459323), ('jose', 4.11122810775634), ('san', 4.1112203220390215), ('just', 4.111085522000185), ('time', 4.1110186353743625), ('delicious', 4.110982472504919), ('lunch', 3.4890927908361813)]\n",
            "Topic 3:\n",
            "[(',', 23.011727108471494), ('sushi', 14.669325698676126), ('!', 9.898582968732633), ('food', 5.710130850278595), ('place', 4.693161253433215), ('maru', 4.4659097523398525), ('lunch', 4.37037947938755), ('ordered', 3.9846298709770553), ('service', 3.834928738248808), ('decent', 3.665639386908288)]\n",
            "Topic 4:\n",
            "[('beef', 0.11111114754318115), ('restaurants', 0.11111113765995871), ('husband', 0.11111113334323532), ('teriyaki', 0.11111113187644751), ('area', 0.11111113146072446), ('reasonable', 0.11111113118890495), ('tai', 0.11111113091150182), ('little', 0.11111113083222687), ('w', 0.11111113053758505), ('eat', 0.11111113038297334)]\n",
            "Topic 5:\n",
            "[(',', 116.21548303789498), ('sushi', 39.511412849086035), ('\"', 20.111066640912146), (')', 19.641678636470726), ('good', 18.79483717970957), ('belt', 17.892976804301412), ('(', 17.518610518019322), ('salmon', 14.111098953973105), (\"it's\", 11.971313019652174), ('fish', 10.574241384421821)]\n",
            "Topic 6:\n",
            "[('!', 42.79141612468878), (',', 42.0269537617839), ('sushi', 25.879497015987596), ('bar', 14.314617991566992), ('great', 11.318136727887454), (\"it's\", 10.250838417437052), ('delicious', 10.110872576408937), ('time', 9.46731653586647), ('nice', 9.111108853950086), ('love', 9.110914571799034)]\n",
            "Topic 7:\n",
            "[('!', 3.111280548726866), ('tai', 1.1112210558920412), ('love', 1.1111970410938607), ('definitely', 1.1111719493282501), ('come', 1.111165848278718), ('nanook', 1.1111613632900368), ('say', 1.1111597109970865), ('good', 1.1111579633696658), ('...', 1.1111508781183606), ('took', 1.111149972332459)]\n",
            "Topic 8:\n",
            "[(',', 7.111408635367724), ('rolls', 3.1112080974970975), ('sushi', 3.1111508071783325), ('got', 2.111256788793555), ('place', 2.111223267320671), ('friendly', 2.11119953249811), ('chicken', 2.11118343025074), ('good', 2.111182912857618), ('$', 2.1111784560980777), ('!', 2.111158976874018)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wATkk-QyHSNs"
      },
      "source": [
        "Take a close look at the output shown above. If two words in a topic both have high values, it means that they co-occur quite frequently in documents where that topic predominates. If you look closely (and ignore the punctuation), you'll see that there are natural semantic connections among words in a topic. For example, even if you did not know that sushi was a kind of food, you can see the sushi-food connection in multiple topics.  \n",
        "\n",
        "If you think about it, our linear discriminant analysis (previous section; using TF-IDF) gave us a very general view of sentiment, simply by comparing the importance of words in two subsets of data. Here we have created a much fuller account of what words occur together in order to build a model that divides words up into semantic groupings. As with other semantic techniques we will encounter, this one relies of the \"distributional hypothesis\" - the idea that words with connected meanings tend to occur together.\n",
        "\n",
        "The connections between terms and topics, as shown in the previous code block, it only half the picture, though. We also need the connections between topics and documents. SciKit learn can produce this for us using the transform method applied to our original sparse matrix (which is organized with one document/comment in each row). We should end up with the same number of rows as we originally had comments and the same number of columns as we have topics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbOnIE72zpVs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a174da18-7bb2-4e5e-8ed1-f0535c0390f7"
      },
      "source": [
        "# Use transform() to get the topic vectors. We should have one\n",
        "# vector for each document in our sushi data.\n",
        "topicvectors = ldiamodel.transform(X=countmatrix)\n",
        "topicvectors.shape, type(topicvectors)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LatentDirichletAllocation was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((70, 9), numpy.ndarray)"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqxXxL6g1WYy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d9084c6-703f-49a2-b603-6dced62d7c27"
      },
      "source": [
        "# Let's see the coefficients for the first 10 rows in our sushi data\n",
        "print(topicvectors[0:10,:].round(4))"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0015 0.8206 0.0015 0.0015 0.0015 0.0015 0.1691 0.0015 0.0015]\n",
            " [0.0022 0.0022 0.0022 0.0022 0.0022 0.6663 0.3185 0.0022 0.0022]\n",
            " [0.0093 0.0093 0.0093 0.0093 0.0093 0.0093 0.9259 0.0093 0.0093]\n",
            " [0.0026 0.0026 0.0026 0.9793 0.0026 0.0026 0.0026 0.0026 0.0026]\n",
            " [0.0021 0.0021 0.0021 0.0021 0.0021 0.9832 0.0021 0.0021 0.0021]\n",
            " [0.0016 0.0016 0.0016 0.0016 0.0016 0.0016 0.9871 0.0016 0.0016]\n",
            " [0.0018 0.0018 0.0018 0.2545 0.0018 0.7327 0.0018 0.0018 0.0018]\n",
            " [0.0058 0.0058 0.0059 0.0059 0.0058 0.9532 0.0059 0.0058 0.0059]\n",
            " [0.0018 0.0018 0.0018 0.0018 0.0018 0.9859 0.0018 0.0018 0.0018]\n",
            " [0.0015 0.0015 0.0015 0.0015 0.0015 0.9878 0.0015 0.0015 0.0015]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure to scan each row in the output above. Generally, each document will load most heavily on just one of the modeled topics. So in each row there should be a lot of very small numbers and one larger number in the range of 0.80 up to 0.99. If you see a row that has two or more \"mid-sized\" numbers, it means that the document in question could not be easily \"assigned\" to just one topic."
      ],
      "metadata": {
        "id": "qok3oExtwDT-"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lp3H_LdrJ781",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71b5b891-f7ea-45e5-a30a-21fb78ba6e93"
      },
      "source": [
        "# Each of those rows is a probability vector and therefore each\n",
        "# row should sum to 1 (within rounding error). As probabilities they\n",
        "# represent the strength of \"attachment\" for each of our topics to each\n",
        "# of our documents. Just as a diagnostic, let's check this assumption.\n",
        "print( [ round(tv.sum(),1) for tv in topicvectors] )"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some of our topic coefficients are likely to be predictive of sentiment. This would indicate that a particular grouping of words (e.g., good, sushi, friendly, place, decent, service) connects strongly with the semantic idea of positivity or negativity. We will use a simple predictive technique, ordinary least squares regression, to probe whether a particular topic vector might be useful in predicting sentiment."
      ],
      "metadata": {
        "id": "DONSzzZ4wyJM"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOmhHyzy2Rhc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91219d88-ffd6-4645-e13d-6fc0716fdee5"
      },
      "source": [
        "# We will use OLS regression from sklearn\n",
        "from sklearn import linear_model # Use regular OLS regression\n",
        "\n",
        "reg = linear_model.LinearRegression() # Create an instance of the class\n",
        "\n",
        "# Train the instance: Note that you can only use n-1 of the topic probabilities.\n",
        "# Because each row sums to one, there is redundant information if you try to\n",
        "# include all of the topic vectors and you will likely end up with a \n",
        "# multicollinear model. This slicer, 0:numtopics, cuts off the last topic. \n",
        "reg.fit(topicvectors[:,0:numtopics], data['Sentiment Score'])\n",
        "\n",
        "# Calculate predicted values based on this regression model so we can get\n",
        "# a zero order correlation as we did above.\n",
        "sentpred = reg.predict(topicvectors[:,0:numtopics])\n",
        "\n",
        "x = pd.Series(data['Sentiment Score'])\n",
        "y = pd.Series(sentpred)\n",
        "x.corr(y)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5683062551922707"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3761pSgLz-V"
      },
      "source": [
        "How does that value, just above, compare with our linear discriminant analysis? Because we have used Latent Dirichlet Allocation as a kind of unsupervised data reduction technique (taking hundreds of columns from our original document term matrix and squashing down to just a few topic vectors), we are much less likely to be overfitting. So if our overall correlation bewteen actual and predicted values is a bit lower than what we obtained from the discriminant analysis, we probably achieved a boost in generalizability insofar as this topic model could be used effectively on novel documents.\n",
        "\n",
        "Let's examine the regression coefficients: Note the largest (absolute value) of these and figure out which topic that coefficient belongs to. For example, counting from 0, if coefficient 4 was equal to 0.437 and that was the largest value, go back a few cells and look at the top words for Topic 4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAqxzVDF33rg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bff3bb1-b119-4bc0-ccd2-d894ada3df8b"
      },
      "source": [
        "reg.coef_"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.08680103, -0.0502043 , -0.03314594,  0.00835262,  0.43663825,\n",
              "       -0.22528869,  0.0213544 ,  0.01771591, -0.08862122])"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topicvectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGCsdf8l5QC5",
        "outputId": "ed41753f-177c-4c59-d4cd-7ad998296674"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00146268, 0.82063706, 0.00146258, 0.00146273, 0.00146199,\n",
              "        0.00146284, 0.16912511, 0.0014623 , 0.00146272],\n",
              "       [0.00217959, 0.00217961, 0.00217947, 0.00218032, 0.00217865,\n",
              "        0.66626825, 0.31847618, 0.00217879, 0.00217914],\n",
              "       [0.00926248, 0.00926753, 0.00926159, 0.00926464, 0.00925926,\n",
              "        0.00926355, 0.92590028, 0.00925988, 0.00926078],\n",
              "       [0.00258597, 0.00258503, 0.00258456, 0.97932069, 0.00258398,\n",
              "        0.00258564, 0.00258528, 0.00258408, 0.00258476],\n",
              "       [0.00209744, 0.00209847, 0.00209795, 0.00209794, 0.00209644,\n",
              "        0.98321943, 0.00209808, 0.00209734, 0.00209693],\n",
              "       [0.00161097, 0.00161107, 0.00161095, 0.00161112, 0.00161031,\n",
              "        0.00161172, 0.98711265, 0.00161047, 0.00161074],\n",
              "       [0.00182298, 0.00182231, 0.0018226 , 0.25450088, 0.00182149,\n",
              "        0.73274356, 0.00182234, 0.00182167, 0.00182217],\n",
              "       [0.00584951, 0.00584901, 0.00585012, 0.0058502 , 0.00584796,\n",
              "        0.95320457, 0.00585037, 0.00584803, 0.00585023],\n",
              "       [0.00176453, 0.00176438, 0.00176398, 0.00176471, 0.00176367,\n",
              "        0.9858852 , 0.00176516, 0.00176424, 0.00176412],\n",
              "       [0.00152299, 0.00152291, 0.00152278, 0.00152287, 0.00152207,\n",
              "        0.9878184 , 0.00152313, 0.00152222, 0.00152263],\n",
              "       [0.00317685, 0.0031755 , 0.00317554, 0.00317554, 0.0031746 ,\n",
              "        0.97459635, 0.00317597, 0.00317465, 0.003175  ],\n",
              "       [0.97931878, 0.00258566, 0.00258537, 0.00258524, 0.00258398,\n",
              "        0.00258582, 0.00258575, 0.00258438, 0.00258502],\n",
              "       [0.00505326, 0.00505308, 0.00505328, 0.00505354, 0.00505051,\n",
              "        0.959577  , 0.00505448, 0.00505191, 0.00505294],\n",
              "       [0.00188412, 0.00188393, 0.00188378, 0.00188417, 0.00188324,\n",
              "        0.9849293 , 0.00188434, 0.00188326, 0.00188386],\n",
              "       [0.00100152, 0.00100143, 0.00100144, 0.00100145, 0.001001  ,\n",
              "        0.37264255, 0.62034789, 0.00100106, 0.00100166],\n",
              "       [0.00195016, 0.00194992, 0.00195003, 0.0019502 , 0.00194932,\n",
              "        0.00195035, 0.00195021, 0.00194957, 0.98440024],\n",
              "       [0.00427568, 0.00427563, 0.0042793 , 0.00427506, 0.00427351,\n",
              "        0.00427577, 0.96579623, 0.00427456, 0.00427426],\n",
              "       [0.0012353 , 0.00123515, 0.00123517, 0.00123504, 0.00123457,\n",
              "        0.99011998, 0.00123514, 0.00123459, 0.00123508],\n",
              "       [0.00271132, 0.0027116 , 0.00271237, 0.00271144, 0.00271003,\n",
              "        0.97831106, 0.00271146, 0.00271006, 0.00271068],\n",
              "       [0.00555736, 0.00555907, 0.00555718, 0.00555719, 0.00555556,\n",
              "        0.00555867, 0.955543  , 0.0055556 , 0.00555636],\n",
              "       [0.00218001, 0.00217993, 0.00217966, 0.00217984, 0.00217865,\n",
              "        0.98256363, 0.00218006, 0.00217871, 0.0021795 ],\n",
              "       [0.00284997, 0.00285014, 0.00285124, 0.00284982, 0.002849  ,\n",
              "        0.97720071, 0.00285067, 0.00284909, 0.00284935],\n",
              "       [0.00396935, 0.00396878, 0.00397013, 0.00396889, 0.00396826,\n",
              "        0.96824668, 0.00397039, 0.00396868, 0.00396885],\n",
              "       [0.0044469 , 0.00444616, 0.00444627, 0.96443068, 0.00444445,\n",
              "        0.00444672, 0.00444744, 0.00444534, 0.00444605],\n",
              "       [0.99063999, 0.00116994, 0.00117002, 0.00117009, 0.00116959,\n",
              "        0.00117023, 0.00117024, 0.00116983, 0.00117007],\n",
              "       [0.00794075, 0.00794001, 0.00793935, 0.00794069, 0.00793651,\n",
              "        0.93647873, 0.0079393 , 0.00794472, 0.00793994],\n",
              "       [0.00529394, 0.00529158, 0.00529387, 0.0052945 , 0.00529101,\n",
              "        0.00529421, 0.95765346, 0.00529173, 0.0052957 ],\n",
              "       [0.0058503 , 0.00584981, 0.95320218, 0.00585021, 0.00584795,\n",
              "        0.00585123, 0.00585043, 0.00584815, 0.00584974],\n",
              "       [0.01235188, 0.90120233, 0.01235243, 0.01235206, 0.01234568,\n",
              "        0.01234982, 0.01235083, 0.01234568, 0.01234929],\n",
              "       [0.00463376, 0.00463418, 0.0046322 , 0.67562363, 0.00462963,\n",
              "        0.00463225, 0.29195279, 0.00463021, 0.00463135],\n",
              "       [0.00411671, 0.00411634, 0.96707158, 0.00411645, 0.00411523,\n",
              "        0.0041164 , 0.00411591, 0.00411523, 0.00411615],\n",
              "       [0.00126327, 0.0012631 , 0.00126306, 0.00126325, 0.00126263,\n",
              "        0.98989556, 0.00126334, 0.00126284, 0.00126294],\n",
              "       [0.00556032, 0.95553819, 0.00555869, 0.00555826, 0.00555556,\n",
              "        0.00555888, 0.0055582 , 0.00555564, 0.00555627],\n",
              "       [0.00855136, 0.00854856, 0.00854899, 0.0085521 , 0.00854701,\n",
              "        0.00855157, 0.00855186, 0.00854936, 0.9315992 ],\n",
              "       [0.00427579, 0.00427599, 0.96579992, 0.00427495, 0.00427351,\n",
              "        0.00427628, 0.00427573, 0.00427357, 0.00427426],\n",
              "       [0.00358709, 0.00358515, 0.0035857 , 0.0035869 , 0.00358423,\n",
              "        0.00358652, 0.97131431, 0.00358493, 0.00358517],\n",
              "       [0.00326887, 0.00326944, 0.00326875, 0.00326889, 0.00326797,\n",
              "        0.00326884, 0.97385043, 0.00326815, 0.00326866],\n",
              "       [0.00152283, 0.00152263, 0.00152255, 0.00152285, 0.00152207,\n",
              "        0.00152271, 0.98781953, 0.00152242, 0.00152242],\n",
              "       [0.00264626, 0.00264635, 0.97883064, 0.00264628, 0.0026455 ,\n",
              "        0.00264696, 0.0026463 , 0.00264575, 0.00264595],\n",
              "       [0.00855094, 0.00855304, 0.00855332, 0.00855022, 0.00854701,\n",
              "        0.00855106, 0.93159719, 0.00854754, 0.00854969],\n",
              "       [0.0058514 , 0.0058509 , 0.00585066, 0.0058526 , 0.00584796,\n",
              "        0.0058513 , 0.95319716, 0.00584872, 0.00584929],\n",
              "       [0.0021804 , 0.00217973, 0.00217983, 0.00217977, 0.00217865,\n",
              "        0.00218002, 0.98256346, 0.00217884, 0.0021793 ],\n",
              "       [0.00246996, 0.0024698 , 0.00246985, 0.00247029, 0.00246914,\n",
              "        0.98024113, 0.00247034, 0.00246929, 0.0024702 ],\n",
              "       [0.00300502, 0.00300459, 0.00300368, 0.97596718, 0.003003  ,\n",
              "        0.00300453, 0.0030042 , 0.00300384, 0.00300396],\n",
              "       [0.0034746 , 0.97221258, 0.00347308, 0.0034737 , 0.00347222,\n",
              "        0.00347401, 0.00347381, 0.0034727 , 0.0034733 ],\n",
              "       [0.00170994, 0.00170976, 0.18165034, 0.8063797 , 0.0017094 ,\n",
              "        0.00171035, 0.00171052, 0.00170973, 0.00171026],\n",
              "       [0.00653786, 0.00653727, 0.00653812, 0.94769797, 0.00653595,\n",
              "        0.00653809, 0.00653948, 0.00653746, 0.00653781],\n",
              "       [0.00217947, 0.00217917, 0.00217985, 0.00217957, 0.00217865,\n",
              "        0.00217981, 0.98256468, 0.0021789 , 0.00217991],\n",
              "       [0.00555735, 0.00555755, 0.00555874, 0.00555699, 0.00555556,\n",
              "        0.95554165, 0.00555898, 0.00555587, 0.00555731],\n",
              "       [0.00505217, 0.00505141, 0.00505284, 0.00505187, 0.00505051,\n",
              "        0.95958501, 0.00505374, 0.00505077, 0.00505168],\n",
              "       [0.00247076, 0.00246951, 0.00246989, 0.00247094, 0.00246914,\n",
              "        0.98023607, 0.00247175, 0.00247063, 0.00247131],\n",
              "       [0.01111762, 0.01111258, 0.01112372, 0.01111891, 0.01111112,\n",
              "        0.01111695, 0.91107322, 0.01111242, 0.01111347],\n",
              "       [0.00585513, 0.00584859, 0.00585185, 0.00585127, 0.00584796,\n",
              "        0.00585079, 0.95319357, 0.00584873, 0.00585211],\n",
              "       [0.97221337, 0.00347342, 0.00347396, 0.00347381, 0.00347222,\n",
              "        0.00347384, 0.0034738 , 0.00347256, 0.00347301],\n",
              "       [0.03704139, 0.03703704, 0.03707202, 0.03704057, 0.03703704,\n",
              "        0.0370516 , 0.03704754, 0.70363576, 0.03703704],\n",
              "       [0.00653886, 0.00653698, 0.00653683, 0.00653973, 0.00653595,\n",
              "        0.0065404 , 0.00653995, 0.94769236, 0.00653894],\n",
              "       [0.00529238, 0.00529238, 0.00529369, 0.00529536, 0.00529101,\n",
              "        0.95765644, 0.00529356, 0.00529202, 0.00529315],\n",
              "       [0.00171023, 0.00171007, 0.00171022, 0.00171022, 0.0017094 ,\n",
              "        0.29157   , 0.69645986, 0.00171004, 0.00170996],\n",
              "       [0.00358562, 0.00358526, 0.00358551, 0.97131801, 0.00358423,\n",
              "        0.00358563, 0.00358565, 0.00358481, 0.00358529],\n",
              "       [0.00222314, 0.00222292, 0.00222304, 0.00222385, 0.00222222,\n",
              "        0.00222396, 0.98221474, 0.00222296, 0.00222318],\n",
              "       [0.00347404, 0.00347297, 0.00347339, 0.00347333, 0.00347222,\n",
              "        0.00347389, 0.97221353, 0.00347361, 0.00347301],\n",
              "       [0.0085548 , 0.00854978, 0.93160009, 0.0085492 , 0.00854701,\n",
              "        0.00855083, 0.00854993, 0.00854728, 0.00855108],\n",
              "       [0.00793935, 0.00793852, 0.00794127, 0.93648503, 0.00793651,\n",
              "        0.00794099, 0.00794   , 0.00793732, 0.00794101],\n",
              "       [0.00926506, 0.009263  , 0.92590176, 0.00926473, 0.00925926,\n",
              "        0.00926227, 0.00926288, 0.00925926, 0.00926176],\n",
              "       [0.00285041, 0.00285056, 0.00284999, 0.00284982, 0.002849  ,\n",
              "        0.00285096, 0.97720019, 0.00284904, 0.00285002],\n",
              "       [0.97131706, 0.00358585, 0.00358554, 0.00358625, 0.00358423,\n",
              "        0.00358545, 0.00358585, 0.00358464, 0.00358513],\n",
              "       [0.0034748 , 0.00347288, 0.00347291, 0.00347347, 0.00347223,\n",
              "        0.00347394, 0.97221482, 0.0034723 , 0.00347264],\n",
              "       [0.01234812, 0.01234678, 0.01235217, 0.90121041, 0.01234568,\n",
              "        0.0123503 , 0.01235008, 0.01234568, 0.01235078],\n",
              "       [0.00411689, 0.00411646, 0.96706658, 0.00411719, 0.00411523,\n",
              "        0.00411743, 0.00411767, 0.00411532, 0.00411724],\n",
              "       [0.00156598, 0.00156576, 0.00156569, 0.00156599, 0.00156495,\n",
              "        0.98747508, 0.00156569, 0.00156534, 0.00156553]])"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRIGWHKJNNHz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1dbab72-88ec-4832-aaeb-dd7dbdd6402e"
      },
      "source": [
        "# Now add some additional diagnostic output. Use an enumerator to find the \n",
        "# documents where Topic 4 represented a probability value larger than 0.90. \n",
        "# Print out the comment corresponding to that document:\n",
        "\n",
        "\n",
        "for idx, tv in enumerate(topicvectors):\n",
        "  # 4.16: Eliminate this print statement\n",
        "  #print(idx)\n",
        "\n",
        "  # 4.17: Include an if statement in this for loop to test the probability\n",
        "  # value for Topic 4 in this particular row\n",
        "  if(tv[3]>0.9):\n",
        "    \n",
        "  # 4.18: Inside the if statement, use idx as the row slicer to get the \n",
        "  # 'Comment' field from the original data set. Print that comment. \n",
        "    print(data.iloc[idx]['Comments'])"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Small sushi boat restaurant located in SJ Japantown. Sushi Maru looks a bit outdated but their food is pretty decent. I ordered a bowl of agedashi tofu and my mom ordered their chicken terriyaki lunch. The agedashi tofu was decent, definitely could be slightly crispier but the flavors were alright. We also grabbed a few plates off the sushi belt and they were decent but they were a tad pricey for okay quality.  Overall this place is alright. It's not high on my list to revisit but if i'm in the area, i'll probably try it out again.\n",
            "So yummy here, we where here on Christmas Eve. And we wanted sushi, thank good it was open that day. Service was great, food was excellent and the employees where up to beat. I can't wait to eat here again. The bento  box was enough food for us to share.. we also got some sushi and oysters at the bar to keep us full. Hot tea is always a bonus..\n",
            "I seriously think about this place A LOT! My go to things to order here: halibut fin, red snapper, and nanook....amazing.  The service can be slow at times, but they're busy, but if you're okay with my loud little nephew, you're amazing to me.  Plus the food, I can't get enough of...remember to get their stamp card. You now know where to spot me!!\n",
            "My kids love this place. They can each eat their own bowl of udon, couple plates of sushi and edamame. And they'll sit through the meal without asking for my phone so I can actually enjoy my kastsu donburi.\n",
            "I was on a shopping trip to SJ and fell into Sushi Maru. We were headed to Gombei Japanese Restaurant, when we arrived at Gombei we found out that they only took cash. We walked to the bank to get cash and  the atm was broken. Next to the bank with the broken atm was Sushi Maru. Bam! Divine intervention. We had a wonderful dinner. The service was very fast and friendly. We both had the dinner combo, the bento box, and we both enjoyed it. Dinner for two was under $40. A happy accident that I would be happy to repeat.\n",
            "We have been to many Sushi restaurants and this one truly is among  the best. There pricing is lower than most and the qualiy at the top. Friendly, clean, fast, and tasty!\n",
            "got the beef teriyaki lunch. not bad. the sushi boat needs some work\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8ri4_w4O6Dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec73061d-8888-4319-caaf-e29c4ed9da3e"
      },
      "source": [
        "# Experimentation with the number of topics.\n",
        "\n",
        "# 4.19: Go back to where numtopics is set and change to the next highest\n",
        "# integer. Rerun the code from there down to here. Interpret the results.\n",
        "# Is this new number of topics a better choice? Why or why not?\n",
        "from sklearn.decomposition import LatentDirichletAllocation as LDIA\n",
        "from numpy import random as rnd\n",
        "rnd.seed(123)\n",
        "\n",
        "numtopics = 400 # Later on you will change this as an exercise.\n",
        "ldiamodel = LDIA(n_components=numtopics, learning_method='batch')\n",
        "ldiamodel = ldiamodel.fit(countdf)\n",
        "ldiamodel.components_.shape # What is the resulting data frame like?\n",
        "ldiamodel.components_[:numtopics,:5]\n",
        "selected_topics(ldiamodel, counter, top_words=10)\n",
        "topicvectors = ldiamodel.transform(X=countmatrix)\n",
        "print(topicvectors.shape)\n"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 0:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 1:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 2:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 3:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 4:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 5:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 6:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 7:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 8:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 9:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 10:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 11:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 12:\n",
            "[(',', 3.0024999999999897), ('sushi', 2.0024999999999884), ('\"', 2.0024999999999884), ('half', 2.0024999999999884), ('-', 2.0024999999999884), ('times', 1.0024999999999844), ('variety', 1.0024999999999844), ('drinks', 1.0024999999999844), ('size', 1.0024999999999844), ('menu', 1.0024999999999844)]\n",
            "Topic 13:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 14:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 15:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 16:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 17:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 18:\n",
            "[('going', 2.0024999999999964), ('great', 1.002499999999995), ('area', 1.002499999999995), ('food', 1.002499999999995), ('japan', 1.002499999999995), ('restaurant', 1.002499999999995), ('restaurants', 1.002499999999995), ('different', 1.002499999999995), ('town', 1.002499999999995), ('love', 1.002499999999995)]\n",
            "Topic 19:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 20:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 21:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 22:\n",
            "[(',', 7.002499999999991), (')', 3.0024999999999875), ('!', 2.0024999999999866), ('fresh', 2.0024999999999866), ('teriyaki', 2.0024999999999866), ('nigiri', 2.0024999999999866), ('salmon', 2.0024999999999866), ('torched', 1.0024999999999822), ('chicken', 1.0024999999999822), ('chirashi', 1.0024999999999822)]\n",
            "Topic 23:\n",
            "[('time', 2.0024999999999937), (',', 2.0024999999999937), ('eating', 1.0024999999999913), ('sitting', 1.0024999999999913), ('bento', 1.0024999999999913), ('fresh', 1.0024999999999913), ('phone', 1.0024999999999913), ('food', 1.0024999999999913), ('bar', 1.0024999999999913), ('box', 1.0024999999999913)]\n",
            "Topic 24:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 25:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 26:\n",
            "[(\"'\", 2.0024999999999915), ('taste', 2.0024999999999915), ('bar', 1.0024999999999886), ('thing', 1.0024999999999886), ('visit', 1.0024999999999886), ('?', 1.0024999999999886), ('nanook', 1.0024999999999886), ('need', 1.0024999999999886), ('guy', 1.0024999999999886), ('asked', 1.0024999999999886)]\n",
            "Topic 27:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 28:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 29:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 30:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 31:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 32:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 33:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 34:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 35:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 36:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 37:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 38:\n",
            "[(',', 7.0024999999999835), ('sushi', 4.002499999999982), ('really', 3.002499999999981), ('good', 3.002499999999981), ('value', 3.002499999999981), (\"don't\", 2.0024999999999795), ('place', 2.0024999999999795), ('\"', 2.0024999999999795), ('card', 2.0024999999999795), ('specials', 2.0024999999999795)]\n",
            "Topic 39:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 40:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 41:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 42:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 43:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 44:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 45:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 46:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 47:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 48:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 49:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 50:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 51:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 52:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 53:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 54:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 55:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 56:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 57:\n",
            "[('beef', 1.002499999999996), ('time', 1.002499999999996), ('having', 1.002499999999996), ('enjoyed', 1.002499999999996), ('good', 1.002499999999996), ('people', 1.002499999999996), ('nice', 1.002499999999996), ('friend', 1.002499999999996), ('food', 1.002499999999996), ('flavors', 0.0025)]\n",
            "Topic 58:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 59:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 60:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 61:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 62:\n",
            "[('sushi', 4.0024999999999915), ('years', 2.0024999999999906), ('come', 2.0024999999999906), (',', 2.0024999999999906), ('know', 1.0024999999999873), ('prices', 1.0024999999999873), ('authentic', 1.0024999999999873), ('high', 1.0024999999999873), ('restaurants', 1.0024999999999873), (\"haven't\", 1.0024999999999873)]\n",
            "Topic 63:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 64:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 65:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 66:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 67:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 68:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 69:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 70:\n",
            "[('sushi', 4.002499999999992), ('japantown', 2.002499999999991), (',', 2.002499999999991), ('options', 2.002499999999991), ('happy', 1.0024999999999875), ('rolls', 1.0024999999999875), ('chefs', 1.0024999999999875), ('great', 1.0024999999999875), ('really', 1.0024999999999875), ('spot', 1.0024999999999875)]\n",
            "Topic 71:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 72:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 73:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 74:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 75:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 76:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 77:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 78:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 79:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 80:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 81:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 82:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 83:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 84:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 85:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 86:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 87:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 88:\n",
            "[(',', 4.002499999999987), ('sushi', 4.002499999999987), ('nigiri', 2.0024999999999844), ('japan', 2.0024999999999844), ('town', 2.0024999999999844), ('come', 2.0024999999999844), ('sake', 1.0024999999999789), ('ordered', 1.0024999999999789), ('options', 1.0024999999999789), ('friend', 1.0024999999999789)]\n",
            "Topic 89:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 90:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 91:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 92:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 93:\n",
            "[('!', 4.002499999999988), (',', 4.002499999999988), ('delicious', 3.0024999999999866), ('sushi', 3.0024999999999866), ('katsu', 2.0024999999999853), ('got', 2.0024999999999853), ('fish', 2.0024999999999853), ('boat', 2.0024999999999853), ('don', 2.0024999999999853), ('rolls', 2.0024999999999853)]\n",
            "Topic 94:\n",
            "[('!', 2.0024999999999937), ('delicious', 2.0024999999999937), ('lunch', 1.0024999999999915), ('salmon', 1.0024999999999915), ('rolls', 1.0024999999999915), ('door', 1.0024999999999915), ('quickly', 1.0024999999999915), ('came', 1.0024999999999915), ('sushi', 1.0024999999999915), ('box', 1.0024999999999915)]\n",
            "Topic 95:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 96:\n",
            "[('!', 3.002499999999995), ('love', 1.002499999999993), ('definitely', 1.002499999999993), ('sister', 1.002499999999993), ('come', 1.002499999999993), ('favorite', 1.002499999999993), ('tai', 1.002499999999993), ('good', 1.002499999999993), ('took', 1.002499999999993), ('ones', 1.002499999999993)]\n",
            "Topic 97:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 98:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 99:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 100:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 101:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 102:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 103:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 104:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 105:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 106:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 107:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 108:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 109:\n",
            "[(',', 2.0024999999999933), ('lunch', 2.0024999999999933), ('daily', 1.002499999999991), ('items', 1.002499999999991), ('sashimi', 1.002499999999991), ('regular', 1.002499999999991), ('space', 1.002499999999991), ('special', 1.002499999999991), ('pretty', 1.002499999999991), ('sushi', 1.002499999999991)]\n",
            "Topic 110:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 111:\n",
            "[('!', 6.002499999999976), (',', 5.002499999999976), ('(', 4.0024999999999755), ('sushi', 4.0024999999999755), (')', 4.0024999999999755), (\"it's\", 3.0024999999999746), ('great', 3.0024999999999737), ('bar', 2.002499999999972), ('sweet', 2.002499999999972), ('dish', 2.002499999999972)]\n",
            "Topic 112:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 113:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 114:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 115:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 116:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 117:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 118:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 119:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 120:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 121:\n",
            "[('!', 2.0024999999999924), ('super', 2.0024999999999924), ('going', 2.0024999999999924), ('better', 2.0024999999999924), ('high', 1.0024999999999895), ('people', 1.0024999999999895), ('favorite', 1.0024999999999895), ('sushi', 1.0024999999999895), ('gets', 1.0024999999999895), ('good', 1.0024999999999895)]\n",
            "Topic 122:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 123:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 124:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 125:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 126:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 127:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 128:\n",
            "[('sushi', 4.002499999999993), ('food', 2.002499999999993), ('like', 1.0024999999999895), ('make', 1.0024999999999895), ('belt', 1.0024999999999895), ('fish', 1.0024999999999895), ('bar', 1.0024999999999895), ('order', 1.0024999999999895), ('excellent', 1.0024999999999895), ('eat', 1.0024999999999895)]\n",
            "Topic 129:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 130:\n",
            "[('!', 2.0024999999999893), ('best', 2.0024999999999893), (',', 2.0024999999999893), ('place', 2.002499999999989), (\"i'm\", 1.0024999999999855), ('great', 1.0024999999999855), ('good', 1.0024999999999855), ('plus', 1.0024999999999855), ('eat', 1.0024999999999855), ('affordable', 1.0024999999999855)]\n",
            "Topic 131:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 132:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 133:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 134:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 135:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 136:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 137:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 138:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 139:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 140:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 141:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 142:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 143:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 144:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 145:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 146:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 147:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 148:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 149:\n",
            "[(',', 9.002499999999982), ('!', 2.0024999999999813), ('time', 2.0024999999999813), ('party', 2.0024999999999813), ('nigiri', 2.0024999999999813), ('unagi', 2.0024999999999813), ('restaurant', 2.0024999999999813), ('stamp', 1.0024999999999742), ('single', 1.0024999999999742), ('saba', 1.0024999999999742)]\n",
            "Topic 150:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 151:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 152:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 153:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 154:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 155:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 156:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 157:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 158:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 159:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 160:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 161:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 162:\n",
            "[('great', 2.002499999999994), ('parking', 1.002499999999992), ('bar', 1.002499999999992), ('easy', 1.002499999999992), ('order', 1.002499999999992), ('fast', 1.002499999999992), ('atmosphere', 1.002499999999992), ('sushi', 1.002499999999992), ('round', 1.002499999999992), ('sit', 1.002499999999992)]\n",
            "Topic 163:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 164:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 165:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 166:\n",
            "[(',', 13.00249999999998), ('sushi', 7.002499999999979), ('conveyer', 5.002499999999979), ('belt', 5.002499999999979), ('salmon', 4.002499999999978), ('surprised', 2.0024999999999746), ('place', 2.0024999999999746), ('flavor', 2.0024999999999746), ('friend', 2.0024999999999746), ('boat', 2.0024999999999746)]\n",
            "Topic 167:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 168:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 169:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 170:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 171:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 172:\n",
            "[(')', 2.5476506392976055), ('(', 2.5476506275373985), ('soba', 2.002499999999982), ('salmon', 2.002499999999982), (',', 1.214279526860649), ('sushi', 1.2004545665827555), ('tai', 1.0024999999999926), ('probably', 1.0024999999999926), ('seated', 1.0024999999999926), ('things', 1.0024999999999926)]\n",
            "Topic 173:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 174:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 175:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 176:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 177:\n",
            "[(',', 7.002499999999987), ('rolls', 3.002499999999985), ('got', 2.0024999999999835), ('sushi', 2.0024999999999835), ('plate', 2.0024999999999835), ('place', 2.0024999999999835), ('!', 2.0024999999999835), ('$', 2.0024999999999835), ('good', 1.0024999999999773), ('day', 1.0024999999999773)]\n",
            "Topic 178:\n",
            "[(',', 3.0024999999999897), ('sushi', 2.0024999999999884), ('nice', 2.0024999999999884), ('salmon', 2.0024999999999884), ('ate', 2.0024999999999884), ('bar', 2.0024999999999884), ('belt', 1.0024999999999844), ('time', 1.0024999999999844), ('eating', 1.0024999999999844), ('really', 1.0024999999999844)]\n",
            "Topic 179:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 180:\n",
            "[(',', 12.002499999999971), ('sushi', 8.00249999999997), (\"it's\", 6.002499999999969), ('\"', 4.0024999999999675), ('place', 3.002499999999966), (\"don't\", 3.002499999999966), ('dinner', 3.002499999999966), ('!', 2.002499999999963), ('little', 2.002499999999963), ('friendly', 2.002499999999963)]\n",
            "Topic 181:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 182:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 183:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 184:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 185:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 186:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 187:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 188:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 189:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 190:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 191:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 192:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 193:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 194:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 195:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 196:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 197:\n",
            "[(',', 7.002499999999989), ('!', 2.0024999999999853), ('sashimi', 2.0024999999999853), ('sushi', 2.0024999999999853), ('fish', 2.0024999999999853), ('love', 2.0024999999999853), ('white', 2.0024999999999853), ('good', 2.0024999999999853), ('california', 1.00249999999998), ('halibut', 1.00249999999998)]\n",
            "Topic 198:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 199:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 200:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 201:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 202:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 203:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 204:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 205:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 206:\n",
            "[('booth', 4.0024999999999915), ('!', 3.002499999999991), ('?', 3.002499999999991), ('sushi', 2.00249999999999), ('people', 2.00249999999999), ('bar', 2.00249999999999), ('party', 2.00249999999999), ('sat', 1.0024999999999864), ('3', 1.0024999999999864), ('got', 1.0024999999999864)]\n",
            "Topic 207:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 208:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 209:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 210:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 211:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 212:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 213:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 214:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 215:\n",
            "[(',', 2.0024999999999946), ('lunch', 2.0024999999999946), ('visit', 1.0024999999999924), ('san', 1.0024999999999924), ('portion', 1.0024999999999924), ('time', 1.0024999999999924), ('price', 1.0024999999999924), ('stopped', 1.0024999999999924), ('reasonable', 1.0024999999999924), ('downtown', 1.0024999999999924)]\n",
            "Topic 216:\n",
            "[(',', 17.790720473139313), ('sushi', 5.722024016766257), ('belt', 5.002499999999967), ('plates', 4.002499999999967), ('(', 3.457349372462561), (')', 3.457349360702354), ('$', 3.002499999999964), ('boyfriend', 3.002499999999964), ('came', 2.0024999999999604), ('bar', 2.0024999999999604)]\n",
            "Topic 217:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 218:\n",
            "[('decent', 3.0024999999999884), ('sushi', 3.0024999999999884), ('ordered', 2.002499999999987), (',', 2.002499999999987), ('list', 1.0024999999999828), ('place', 1.0024999999999828), ('area', 1.0024999999999828), ('okay', 1.0024999999999828), ('overall', 1.0024999999999828), ('food', 1.0024999999999828)]\n",
            "Topic 219:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 220:\n",
            "[('rolls', 4.002499999999988), (',', 4.002499999999988), ('belt', 2.0024999999999866), ('(', 2.0024999999999866), (')', 2.0024999999999866), ('menu', 1.0024999999999822), ('slightly', 1.0024999999999822), ('miso', 1.0024999999999822), ('quality', 1.0024999999999822), ('group', 1.0024999999999822)]\n",
            "Topic 221:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 222:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 223:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 224:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 225:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 226:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 227:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 228:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 229:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 230:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 231:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 232:\n",
            "[(',', 14.002499999999978), ('sushi', 4.002499999999977), ('restaurant', 3.002499999999976), ('pretty', 3.002499999999976), ('perfect', 2.0024999999999737), ('comes', 2.0024999999999737), ('baked', 2.0024999999999737), ('salad', 2.0024999999999737), ('fish', 2.0024999999999737), ('lunch', 2.0024999999999737)]\n",
            "Topic 233:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 234:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 235:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 236:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 237:\n",
            "[(',', 7.002499999999985), ('japanese', 3.0024999999999844), ('belt', 3.0024999999999844), ('\"', 2.002499999999983), ('conveyor', 2.002499999999983), ('restaurant', 2.002499999999983), (')', 2.002499999999983), ('sushi', 2.002499999999983), ('quality', 2.002499999999983), ('(', 2.0024999999999826)]\n",
            "Topic 238:\n",
            "[('service', 3.002499999999992), ('place', 2.0024999999999906), ('friday', 1.002499999999987), ('new', 1.002499999999987), ('night', 1.002499999999987), ('gotten', 1.002499999999987), ('gone', 1.002499999999987), ('go-to', 1.002499999999987), ('friends', 1.002499999999987), (\"they're\", 1.002499999999987)]\n",
            "Topic 239:\n",
            "[('bowl', 1.0024999999999926), ('actually', 1.0024999999999926), ('enjoy', 1.0024999999999926), ('donburi', 1.0024999999999926), ('couple', 1.0024999999999926), ('udon', 1.0024999999999926), ('phone', 1.0024999999999926), ('meal', 1.0024999999999926), (\"they'll\", 0.9335189278838468), ('love', 0.7845828209985344)]\n",
            "Topic 240:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 241:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 242:\n",
            "[('prices', 1.0024999999999946), ('friendly', 1.0024999999999946), ('chicken', 1.0024999999999946), ('sushi', 1.0024999999999946), ('good', 1.0024999999999946), ('fast', 1.0024999999999946), ('come', 1.0024999999999946), ('salmon', 1.0024999999999946), ('reasonable', 1.0024999999999946), ('definitely', 1.0024999999999946)]\n",
            "Topic 243:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 244:\n",
            "[(',', 5.002499999999975), ('nice', 3.0024999999999853), (\"it's\", 3.0024999999999853), ('love', 2.2204171790014433), ('!', 2.002499999999984), ('waitresses', 2.002499999999984), ('really', 2.002499999999984), ('sit', 2.002499999999947), ('sushi', 2.002499999999947), ('place', 1.096221331997217)]\n",
            "Topic 245:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 246:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 247:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 248:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 249:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 250:\n",
            "[('\"', 12.002499999999992), (\"it's\", 4.0024999999999915), ('sushi', 2.0024999999999897), ('service', 2.0024999999999897), ('long', 1.0024999999999862), ('dishes', 1.0024999999999862), (\"i've\", 1.0024999999999862), (\"isn't\", 1.0024999999999862), ('2.5', 1.0024999999999862), ('stars', 1.0024999999999862)]\n",
            "Topic 251:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 252:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 253:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 254:\n",
            "[('sushi', 4.0024999999999835), ('!', 3.002499999999982), ('nigiri', 3.002499999999982), (',', 3.002499999999982), ('tasted', 3.002499999999982), ('tempura', 3.002499999999982), ('time', 2.002499999999981), ('lunch', 2.002499999999981), ('ordered', 2.002499999999981), ('plate', 2.002499999999981)]\n",
            "Topic 255:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 256:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 257:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 258:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 259:\n",
            "[('food', 4.0024999999999915), ('japanese', 3.0024999999999915), ('decent', 2.002499999999991), ('okay', 1.0024999999999875), ('got', 1.0024999999999875), ('good', 1.0024999999999875), ('order', 1.0024999999999875), ('away', 1.0024999999999875), ('overall', 1.0024999999999875), ('best', 1.0024999999999875)]\n",
            "Topic 260:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 261:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 262:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 263:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 264:\n",
            "[('!', 2.002499999999994), ('food', 2.002499999999994), (\"it's\", 2.002499999999994), ('lunch', 1.0024999999999924), ('come', 1.0024999999999924), ('combo', 1.0024999999999924), ('reasonable', 1.0024999999999924), ('price', 1.0024999999999924), ('parking', 1.0024999999999924), ('order', 1.0024999999999924)]\n",
            "Topic 265:\n",
            "[(',', 4.002499999999981), ('roll', 4.002499999999981), ('-', 4.002499999999981), ('(', 4.002499999999981), (')', 4.002499999999981), ('!', 3.00249999999998), ('sushi', 3.00249999999998), ('sake', 2.0024999999999777), ('great', 2.0024999999999777), ('liked', 2.0024999999999777)]\n",
            "Topic 266:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 267:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 268:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 269:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 270:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 271:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 272:\n",
            "[(',', 3.0024999999999884), ('dinner', 2.002499999999987), ('(', 2.002499999999987), (')', 2.002499999999987), ('sushi', 2.002499999999987), ('salmon', 1.0024999999999828), ('seared', 1.0024999999999826), ('sure', 1.0024999999999826), ('great', 1.0024999999999826), ('nigiri', 1.0024999999999826)]\n",
            "Topic 273:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 274:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 275:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 276:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 277:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 278:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 279:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 280:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 281:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 282:\n",
            "[(',', 7.002499999999982), ('bar', 3.0024999999999804), ('good', 3.0024999999999804), (':', 3.0024999999999804), ('order', 3.0024999999999804), ('sushi', 3.0024999999999804), ('menu', 2.0024999999999786), ('consistent', 2.0024999999999786), ('belt', 2.0024999999999786), ('rolls', 2.0024999999999786)]\n",
            "Topic 283:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 284:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 285:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 286:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 287:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 288:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 289:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 290:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 291:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 292:\n",
            "[('order', 4.0024999999999915), ('sushi', 2.0024999999999906), ('food', 2.0024999999999906), (\"you're\", 2.0024999999999906), ('bar', 2.0024999999999906), ('server', 2.0024999999999906), ('ordering', 1.0024999999999873), ('eating', 1.0024999999999873), ('good', 1.0024999999999873), ('price', 1.0024999999999873)]\n",
            "Topic 293:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 294:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 295:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 296:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 297:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 298:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 299:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 300:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 301:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 302:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 303:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 304:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 305:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 306:\n",
            "[('uni', 2.0024999999999964), ('!', 1.0024999999999946), ('roll', 1.0024999999999946), ('best', 1.0024999999999946), ('favorites', 1.0024999999999946), ('price', 1.0024999999999946), ('sushi', 1.0024999999999946), ('california', 1.0024999999999946), ('w', 1.0024999999999946), ('reasonable', 1.0024999999999946)]\n",
            "Topic 307:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 308:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 309:\n",
            "[(',', 3.002499999999993), ('sushi', 2.002499999999992), ('food', 2.002499999999992), ('yummy', 2.00249999999998), ('excellent', 1.0024999999999895), ('tea', 1.0024999999999895), ('eat', 1.0024999999999895), ('great', 1.0024999999999895), ('wait', 1.0024999999999895), ('open', 1.0024999999999895)]\n",
            "Topic 310:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 311:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 312:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 313:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 314:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 315:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 316:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 317:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 318:\n",
            "[('!', 7.002499999999983), ('busy', 3.0024999999999804), ('wait', 3.0024999999999804), ('took', 3.0024999999999804), ('bar', 3.0024999999999804), ('seat', 2.0024999999999786), ('mom', 2.0024999999999786), ('night', 2.0024999999999786), ('came', 2.0024999999999786), ('day', 2.0024999999999786)]\n",
            "Topic 319:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 320:\n",
            "[(',', 7.002499999999987), ('good', 2.0024999999999853), ('sushi', 2.0024999999999853), (':', 2.0024999999999853), ('bar', 2.0024999999999853), ('-', 2.0024999999999853), ('restaurants', 2.0024999999999853), ('sit', 2.0024999999999853), ('make', 1.0024999999999797), (\"don't\", 1.0024999999999797)]\n",
            "Topic 321:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 322:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 323:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 324:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 325:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 326:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 327:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 328:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 329:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 330:\n",
            "[('!', 3.002499999999991), ('table', 3.002499999999991), (',', 2.0024999999999906), ('walk', 1.0024999999999873), ('3', 1.0024999999999873), ('hot', 1.0024999999999873), ('5', 1.0024999999999873), ('high', 1.0024999999999873), ('accommodating', 1.0024999999999873), ('mind', 1.0024999999999873)]\n",
            "Topic 331:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 332:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 333:\n",
            "[('uni', 3.0024999999999884), ('fresh', 3.0024999999999755), (',', 2.002499999999987), ('beef', 2.002499999999987), ('sushi', 2.002499999999987), ('\"', 2.002499999999987), ('order', 1.0024999999999828), ('took', 1.0024999999999828), ('popular', 1.0024999999999828), ('presentation', 1.0024999999999828)]\n",
            "Topic 334:\n",
            "[(',', 2.0024999999999937), ('food', 1.0024999999999913), ('location', 1.0024999999999913), ('bento', 1.0024999999999913), ('visit', 1.0024999999999913), ('got', 1.0024999999999913), ('stopped', 1.0024999999999913), ('ordered', 1.0024999999999913), ('husband', 1.0024999999999913), ('box', 1.0024999999999913)]\n",
            "Topic 335:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 336:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 337:\n",
            "[('eat', 2.00249999999998), ('plates', 2.00249999999998), ('place', 1.2942140703236178), ('like', 1.0024999999999942), ('decent', 1.0024999999999942), ('sat', 1.0024999999999942), ('conveyor', 1.0024999999999942), ('went', 1.0024999999999942), ('quickly', 1.0024999999999942), ('today', 1.0024999999999942)]\n",
            "Topic 338:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 339:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 340:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 341:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 342:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 343:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 344:\n",
            "[('place', 1.0024999999999962), ('dinner', 1.0024999999999962), ('eat', 1.0024999999999962), ('quick', 1.0024999999999962), ('sushi', 1.0024999999999962), ('conveyor', 1.0024999999999962), ('booth', 1.0024999999999962), ('belt', 1.0024999999999962), ('flavors', 0.0025), ('flavor', 0.0025)]\n",
            "Topic 345:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 346:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 347:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 348:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 349:\n",
            "[('truly', 4.00249999999998), ('$', 2.0024999999999915), ('clean', 2.002499999999961), ('sushi', 1.085021416650935), ('food', 1.0024999999999882), ('staff', 1.0024999999999882), ('drinks', 1.0024999999999882), (\"haven't\", 1.0024999999999882), ('hidden', 1.0024999999999882), ('time', 1.0024999999999882)]\n",
            "Topic 350:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 351:\n",
            "[('restaurant', 3.0024999999999866), (',', 2.0024999999999853), ('\"', 2.0024999999999853), ('parking', 2.0024999999999853), ('taste', 1.0024999999999795), ('popular', 1.0024999999999795), ('fast', 1.0024999999999795), ('street', 1.0024999999999795), ('fills', 1.0024999999999795), ('booths', 1.0024999999999795)]\n",
            "Topic 352:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 353:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 354:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 355:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 356:\n",
            "[(',', 9.002499999999985), ('!', 4.002499999999984), ('salmon', 3.002499999999984), ('seared', 3.002499999999984), ('appetizer', 2.0024999999999813), ('pieces', 2.0024999999999813), ('pretty', 2.0024999999999813), ('order', 2.0024999999999813), (\"i'm\", 2.0024999999999813), ('really', 2.0024999999999813)]\n",
            "Topic 357:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 358:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 359:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 360:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 361:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 362:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 363:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 364:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 365:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 366:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 367:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 368:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 369:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 370:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 371:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 372:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 373:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 374:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 375:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 376:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 377:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 378:\n",
            "[('!', 2.002499999999994), ('waited', 1.0024999999999924), ('baked', 1.0024999999999924), ('cheap', 1.0024999999999924), ('delicious', 1.0024999999999924), ('food', 1.0024999999999924), ('fresh', 1.0024999999999924), ('friendly', 1.0024999999999924), ('great', 1.0024999999999924), ('little', 1.0024999999999924)]\n",
            "Topic 379:\n",
            "[(',', 6.00249999999999), (\"it's\", 2.0024999999999884), ('maybe', 2.002499999999988), ('salty', 2.002499999999988), ('like', 2.002499999999988), ('sauce', 2.002499999999988), ('lunch', 1.0024999999999837), ('teriyaki', 1.0024999999999837), ('terrible', 1.0024999999999837), (\"that's\", 1.0024999999999837)]\n",
            "Topic 380:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 381:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 382:\n",
            "[('sushi', 4.0024999999999835), ('$', 3.0024999999999835), (',', 3.0024999999999835), ('come', 2.002499999999982), ('lunch', 2.002499999999982), ('food', 2.002499999999982), ('week', 2.002499999999982), ('place', 2.002499999999982), ('maru', 2.002499999999982), ('options', 1.0024999999999755)]\n",
            "Topic 383:\n",
            "[(',', 6.0024999999999915), ('!', 3.0024999999999897), ('...', 2.0024999999999893), ('amazing', 2.0024999999999893), (\"you're\", 2.0024999999999893), ('lot', 1.0024999999999853), ('card', 1.0024999999999853), ('times', 1.0024999999999853), ('think', 1.0024999999999853), ('things', 1.0024999999999853)]\n",
            "Topic 384:\n",
            "[('sushi', 2.0024999999999937), ('close', 1.002499999999992), ('japanese', 1.002499999999992), ('area', 1.002499999999992), ('restaurants', 1.002499999999992), ('order', 1.002499999999992), ('right', 1.002499999999992), ('home', 1.002499999999992), ('price', 1.002499999999992), (\"it's\", 1.002499999999992)]\n",
            "Topic 385:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 386:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 387:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 388:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 389:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 390:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 391:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 392:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 393:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 394:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 395:\n",
            "[('beef', 1.0024999999999962), ('teriyaki', 1.0024999999999962), ('got', 1.0024999999999962), ('lunch', 1.0024999999999962), ('bad', 1.0024999999999962), ('work', 1.0024999999999962), ('sushi', 1.0024999999999962), ('boat', 1.0024999999999962), ('fast', 0.0025), ('favorites', 0.0025)]\n",
            "Topic 396:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 397:\n",
            "[('good', 2.0024999999999937), ('fish', 2.0024999999999937), (',', 2.0024999999999937), ('like', 1.002499999999992), ('salad', 1.002499999999992), ('value', 1.002499999999992), ('variety', 1.002499999999992), ('standard', 1.002499999999992), ('nigiri', 1.002499999999992), ('rolls', 1.002499999999992)]\n",
            "Topic 398:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "Topic 399:\n",
            "[('yummy', 0.0025), ('feel', 0.0025), ('end', 0.0025), ('enjoy', 0.0025), ('enjoyed', 0.0025), ('entree', 0.0025), ('excellent', 0.0025), ('expensive', 0.0025), ('experience', 0.0025), ('fast', 0.0025)]\n",
            "(70, 400)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LatentDirichletAllocation was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Experimentation with the number of topics, take two.\n",
        "\n",
        "# 4.20: Go back to where numtopics is set and change it to a small value\n",
        "# such as three or five. Rerun the code from there down to here. \n",
        "# Interpret the results.\n",
        "# Is this new number of topics a better choice? Why or why not?"
      ],
      "metadata": {
        "id": "EPRTm7okylHN"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this point, it is probably near the end of the lab session. Make sure to download your ipynb file with all of its output intact and then submit this to Blackboard to get credit for today's lab. In the text comment area of the Blackboard dropbox, make sure you say how far you got in working on today's lab. If the there is still time left in the class period, continue on to the bonus task below."
      ],
      "metadata": {
        "id": "uMpIGdw0y2zw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# 4.21: Extra bonus challenge task\n",
        "#\n",
        "# From the very start of the lab, we did not condition our text data by \n",
        "# removing punctuation or numbers. BTW, when we vectorized, the default \n",
        "# was to lowercase the data so we did do that.\n",
        "#\n",
        "# Speculate on whether numbers and punctuation may play a part in detecting\n",
        "# sentiment. Then go back to the very beginning of the lab and \n",
        "# screen out numbers and punctuation. If you overwrite the existing\n",
        "# text values in the Pandas database, none of the other code should need to\n",
        "# change. Then rerun the whole notebook, taking a look at key metrics. Did\n",
        "# we get better results without punctuation and numbers? Which punctuation\n",
        "# might be associated with a positive or negative review.\n",
        "#"
      ],
      "metadata": {
        "id": "Y4_Gbhjnyz8i"
      },
      "execution_count": 102,
      "outputs": []
    }
  ]
}