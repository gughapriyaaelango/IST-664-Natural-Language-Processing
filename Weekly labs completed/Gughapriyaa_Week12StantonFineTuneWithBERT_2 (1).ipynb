{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cb4espuLKJiA"
      },
      "source": [
        "##### A derivative work based on an original notebook with copyright 2020 by \"The TensorFlow Hub Authors.\"\n",
        "\n",
        "Important: You must set up the runtime to use GPU or the fine-tuning training of the BERT model will take a very long time.\n",
        "\n",
        "This tutorial demonstrates fine-tuning a BERT model to perform sentiment analysis on a dataset of plain-text IMDB movie reviews. In addition to training a model, we will preprocess text into an appropriate format.\n",
        "\n",
        "Here's an overview of the steps:\n",
        "\n",
        "1. Load the IMDB dataset\n",
        "2. Load a BERT model from TensorFlow Hub\n",
        "3. Build a model by combining BERT with a classifier\n",
        "4. Train the model, fine-tuning BERT as part of that\n",
        "5. Save the model and use it to classify sentences\n",
        "\n",
        "Note: This is a derivative work licensed under the Apache License, Version 2.0.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCjmX4zTCkRK"
      },
      "source": [
        "## Setup\n",
        "\n",
        "The \"TensorFlow Model Garden\" is a repository of models made available to the public by the Tensorflow authors. The \"official\" area contains a set of models that are well-vetted and maintained. As these are not part of the Colab image, we must use pip install to load them into the VM. \n",
        "\n",
        "We will use a relatively new suite of text preprocessing tools from tensorflow-text that move many of the routine tasks from regular python code into the tensorflow ecosystem.\n",
        "\n",
        "We will also use the AdamW optimizer from [tensorflow/models](https://github.com/tensorflow/models). AdamW implements a form of normalization on the computation of gradients that improves generalizabaility of resulting models. Using AdamW to train has shown superior results in a variety of classification tasks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-YbjCkzw0yU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7a9b62d-8be6-4e5c-f823-33820e42353e"
      },
      "source": [
        "# A dependency of the preprocessing for BERT inputs\n",
        "!pip install -q -U tensorflow-text"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/6.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m4.8/6.0 MB\u001b[0m \u001b[31m142.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m147.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-P1ZOA0FkVJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7953f83-34dd-4cf7-cf37-b5fbe3532d06"
      },
      "source": [
        "!pip install -q tf-models-official"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.6/240.6 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m591.0/591.0 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m630.1/630.1 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XgTpm9ZxoN9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f847d251-c436-4ab5-b004-f45a50f95861"
      },
      "source": [
        "import os # Operating system utilities\n",
        "import shutil # Shell utilities for high level file operations\n",
        "\n",
        "import tensorflow as tf # Basic tensorflow setup\n",
        "import tensorflow_hub as hub # Here's how we get access to several newer features\n",
        "import tensorflow_text as text # Nice new text preprocessing\n",
        "from official.nlp import optimization  # to create AdamW optimizer\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# This sets the logger to a different level than the default, which is WARNING\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "\n",
        "save_model = True # Flag to control saving to disk"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6MugfEgDRpY"
      },
      "source": [
        "## Sentiment analysis\n",
        "\n",
        "This notebook trains a sentiment analysis model to classify movie reviews as *positive* or *negative*, based on the text of the review.\n",
        "\n",
        "We use the [Large Movie Review Dataset](https://ai.stanford.edu/~amaas/data/sentiment/) containing 50,000 movie reviews from the [Internet Movie Database](https://www.imdb.com/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vnvd4mrtPHHV"
      },
      "source": [
        "### Download the IMDB dataset\n",
        "\n",
        "Let's download and extract the dataset, then explore the directory structure.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOdqCMoQDRJL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e559d99-a064-4ac7-af1e-374efddd6f4e"
      },
      "source": [
        "# This take about half a minute\n",
        "\n",
        "# Here's an online repository that contains the data we need\n",
        "url = 'https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
        "basefile = 'aclImdb_v1.tar.gz'\n",
        "\n",
        "# This utility will also untar/unzip the file for us\n",
        "dataset = tf.keras.utils.get_file(basefile, url, untar=True, cache_dir='.',\n",
        "                                  cache_subdir='')\n",
        "\n",
        "# Concatenate the path name\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')\n",
        "\n",
        "# Concatenate the path name\n",
        "train_dir = os.path.join(dataset_dir, 'train')\n",
        "\n",
        "# remove unused folders to make it easier to load the data\n",
        "remove_dir = os.path.join(train_dir, 'unsup')\n",
        "shutil.rmtree(remove_dir) # Shell utilities / high level file ops"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "84125825/84125825 [==============================] - 9s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssiaQU1Kpw_e"
      },
      "source": [
        "#\n",
        "# Exercise 12.1: Examine the aclImdb folder structure in the Files viewer.\n",
        "# Write a comment describing what you see.\n",
        "#\n",
        "#The folder contains a vocab file of imdb.vocab\n",
        "#Test and train folders are separate\n",
        "#Each test and train file has separate negative and positive reviews"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lN9lWCYfPo7b"
      },
      "source": [
        "Next, use the `text_dataset_from_directory` utility to create a labeled `tf.data.Dataset`.\n",
        "\n",
        "The IMDB dataset has already been divided into train and test, but it lacks a validation set. While the test set helps govern the training process and prevent overfitting, the validation set stands apart and is not used until the model is fully trained. Let's create a validation set using an 80:20 split of the training data by using the `validation_split` argument below.\n",
        "\n",
        "Note:  When using the `validation_split` and `subset` arguments, make sure to either specify a random seed, or to pass `shuffle=False`, so that the validation and training splits have no overlap."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IwI_2bcIeX8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ba34d23-5b67-4f91-d220-851a8dbd7274"
      },
      "source": [
        "# Prefetch elements from the input dataset ahead of the time they are requested\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "batch_size = 32 # Number of instances in a batch\n",
        "seed = 42 # Control randomization. Why 42?\n",
        "\n",
        "print(\"Processing training data. . .\")\n",
        "# This utility eats up the data in the aclImdb/train folder\n",
        "raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "    'aclImdb/train',\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,\n",
        "    subset='training',\n",
        "    seed=seed)\n",
        "\n",
        "class_names = raw_train_ds.class_names\n",
        "train_ds = raw_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "print(\"Processing training data for validation. . .\")\n",
        "# A complete directory of data ingested and organized in one function call\n",
        "val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "    'aclImdb/train',\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,\n",
        "    subset='validation',\n",
        "    seed=seed)\n",
        "\n",
        "# Caching and pre-fetch will speed up the preprocessing of training data\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "print(\"Processing test data. . .\")\n",
        "test_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "    'aclImdb/test',\n",
        "    batch_size=batch_size)\n",
        "\n",
        "# Caching and pre-fetch will also speed up the preprocessing of test data\n",
        "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing training data. . .\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n",
            "Processing training data for validation. . .\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n",
            "Processing test data. . .\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hFvWKbh8CMO"
      },
      "source": [
        "#\n",
        "# Exercise 12.2: Look up what tf.data.AUTOTUNE does and write a comment here.\n",
        "# Hint: Look at the buffer_size argument in the call to prefetch()\n",
        "#\n",
        "#tf.data.AUTOTUNE buffer_size=AUTOTUNE in prefetch:\n",
        "#tf.data.AUTOTUNE can be passed to prefecth or cache methods.\n",
        "#t allows TensorFlow to automatically tune the prefetching buffer size for optimal performance\n",
        "#according to hardware configurations.\n",
        "#It helps improving performance of the tensorflow pipelines"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGm10A5HRGXp"
      },
      "source": [
        "Let's take a look at a few reviews."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuxDkcvVIoev",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91555cdb-230b-4173-bd5f-5b4b937bce8c"
      },
      "source": [
        "# The take() method let's us peel off one set from a batch \n",
        "for text_batch, label_batch in train_ds.take(1):\n",
        "  for i in range(5): # Then we can look at some of the instances\n",
        "    print(f'Review: {text_batch.numpy()[i]}')\n",
        "    label = label_batch.numpy()[i]\n",
        "    print(f'Label : {label} ({class_names[label]})')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review: b'\"Pandemonium\" is a horror movie spoof that comes off more stupid than funny. Believe me when I tell you, I love comedies. Especially comedy spoofs. \"Airplane\", \"The Naked Gun\" trilogy, \"Blazing Saddles\", \"High Anxiety\", and \"Spaceballs\" are some of my favorite comedies that spoof a particular genre. \"Pandemonium\" is not up there with those films. Most of the scenes in this movie had me sitting there in stunned silence because the movie wasn\\'t all that funny. There are a few laughs in the film, but when you watch a comedy, you expect to laugh a lot more than a few times and that\\'s all this film has going for it. Geez, \"Scream\" had more laughs than this film and that was more of a horror film. How bizarre is that?<br /><br />*1/2 (out of four)'\n",
            "Label : 0 (neg)\n",
            "Review: b\"David Mamet is a very interesting and a very un-equal director. His first movie 'House of Games' was the one I liked best, and it set a series of films with characters whose perspective of life changes as they get into complicated situations, and so does the perspective of the viewer.<br /><br />So is 'Homicide' which from the title tries to set the mind of the viewer to the usual crime drama. The principal characters are two cops, one Jewish and one Irish who deal with a racially charged area. The murder of an old Jewish shop owner who proves to be an ancient veteran of the Israeli Independence war triggers the Jewish identity in the mind and heart of the Jewish detective.<br /><br />This is were the flaws of the film are the more obvious. The process of awakening is theatrical and hard to believe, the group of Jewish militants is operatic, and the way the detective eventually walks to the final violent confrontation is pathetic. The end of the film itself is Mamet-like smart, but disappoints from a human emotional perspective.<br /><br />Joe Mantegna and William Macy give strong performances, but the flaws of the story are too evident to be easily compensated.\"\n",
            "Label : 0 (neg)\n",
            "Review: b'Great documentary about the lives of NY firefighters during the worst terrorist attack of all time.. That reason alone is why this should be a must see collectors item.. What shocked me was not only the attacks, but the\"High Fat Diet\" and physical appearance of some of these firefighters. I think a lot of Doctors would agree with me that,in the physical shape they were in, some of these firefighters would NOT of made it to the 79th floor carrying over 60 lbs of gear. Having said that i now have a greater respect for firefighters and i realize becoming a firefighter is a life altering job. The French have a history of making great documentary\\'s and that is what this is, a Great Documentary.....'\n",
            "Label : 1 (pos)\n",
            "Review: b\"It's boggles the mind how this movie was nominated for seven Oscars and won one. Not because it's abysmal or because given the collective credentials of the creative team behind it really ought to deserve them but because in every category it was nominated Prizzi's Honor disappoints. Some would argue that old Hollywood pioneer John Huston had lost it by this point in his career but I don't buy it. Only the previous year he signed the superb UNDER THE VOLCANO, a dark character study set in Mexico, that ranks among the finest he ever did. Prizzi's Honor on the other hand, a film loaded with star power, good intentions and a decent script, proves to be a major letdown.<br /><br />The overall tone and plot of a gangster falling in love with a female hit-man prefigures the quirky crimedies that caught Hollywood by storm in the early 90's but the script is too convoluted for its own sake, the motivations are off and on the whole the story seems unsure of what exactly it's trying to be: a romantic comedy, a crime drama, a gangster saga etc. Jack Nicholson (doing a Brooklyn accent that works perfectly for De Niro but sounds unconvincing coming from Jack) and Kathleen Turner in the leading roles seem to be in paycheck mode, just going through the motions almost sleepwalking their way through some parts. Anjelica Huston on the other hand fares better but her performance is sabotaged by her character's motivations: she starts out the victim of her bigot father's disdain, she proves to be supportive to her ex-husband, then becomes a vindictive bitch that wants his head on a plate.<br /><br />The colours of the movie have a washed-up quality like it was made in the early 70's and Huston's direction is as uninteresting as everything else. There's promise behind the story and perhaps in the hands of a director hungry to be recognized it could've been morphed to something better but what's left looks like a film nobody was really interested in making.\"\n",
            "Label : 0 (neg)\n",
            "Review: b'The concept of the legal gray area in Love Crimes contributes to about 10% of the movie\\'s appeal; the other 90% can be attributed to it\\'s flagrant bad-ness. To say that Sean Young\\'s performance as a so-called district attorney is wooden is a gross understatement. With her bland suits and superfluous hair gel, Young does a decent job at convincing the audience of her devout hatred for men. Why else would she ask her only friend to pose as a prostitute just so she can arrest cops who try to pick up on them? This hatred is also the only reason why she relentlessly pursues a perverted photographer who gives women a consensual thrill and the driving force behind this crappy movie. Watching Young go from frigid to full-frontal nudity does little to raise interest, but the temper tantrum she throws standing next to a fire by a lake does. Watching her rant and rave about her self-loathing and sexual frustration makes Love Crimes worth the rental fee, but it\\'s all downhill to and from there. Despite her urge to bring Patrick Bergin\\'s character to justice, her policing skills completely escape her in the throes of her own tired lust and passion. Patrick Bergin does a decent enough job as a slimy sociopath; if it worked in Sleeping With the Enemy it sure as hell can work in this. But I can\\'t help but wonder if the noticeable lack of energy Young brings to the film conflicts with his sliminess. I\\'m guessing it does and the result is a \"thriller\" with thrills that are thoroughly bad and yet comedic.'\n",
            "Label : 0 (neg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6ywSWUI8h-G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec07b1d5-48ef-49df-e41c-51c8deaa4012"
      },
      "source": [
        "#\n",
        "# Exercise 12.3 - Use the skip() method together with the take() method\n",
        "# to examine batch of reviews in the range of 6 to 10.\n",
        "#\n",
        "for text_batch, label_batch in train_ds.skip(5).take(1):\n",
        "  for i in range(5): # Then we can look at some of the instances\n",
        "    print(f'Review: {text_batch.numpy()[i]}')\n",
        "    label = label_batch.numpy()[i]\n",
        "    print(f'Label : {label} ({class_names[label]})')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review: b'There\\'s no denying the first Azumi film was a commercial product; it was an adaptation of a popular manga and had cast of young, attractive actors and certainly wasn\\'t lacking in the budget department. Yet it more than entertained for what it was, and I can\\'t deny I enjoyed it immensely.<br /><br />\"Azumi 2\" lacks just about everything that made the original so wonderful. The first thing that should set alarm bells ringing is the absence of the superb Ryuhei Kitamura at the helm. With him, he seemed to take not only his own visual flair and kinetics, but the originals style, beauty and most importantly, its heart. While the first had a simple \"hitlist\" plot, this one has a corkscrew mess of a story, with too many dull characters stabbing each other in the back so many times the potential for any sympathy or pathos is obliterated. Gone is the effective interplay between the lead characters; Azumi and her cohorts are often reduced to a bunch of stroppy teenagers arguing in a forest. Characterisation is non existent; if anyone watching actually cares who lives and who dies, I\\'ll be shocked. The same applies to the villains here. The final battle - in fact all the battles - are completely devoid of any sort of tension. The fact that they are poorly choreographed and abysmally directed - not to mention few and far between - is made a sideline by their own sheer pointlessness. The villains themselves try far too hard to be campy, and even if they were all combined, they don\\'t come within a country mile of the Pete Burnsian antics of Jo Odagiri in the original.<br /><br />####Major Spoiler at end of paragraph!##### <br /><br />Aya Ueto tries her best it has to be said, and she also managed to keep her hair in good condition between the films. Azumi is now a fully fledged assassin, meaning she can wave her sword around in slow motion; unfortunately, now the character is instilled with a sort of Man With No Name style mysteriousness, Ueto\\'s model looks become even more inappropriate. I know this is supposed to be the point, but this combined with the ineffectiveness of everyone else in the film, the stupidity of the plot and the general ineptness of the film in general means it is downright impossible to get behind her character this time around. The less said about Chiaki \"Remember me from Kill Bill\" Kuriyama\\'s performance the better; it suffices to say her \"turn\" from good to evil is about as subtle as napalm.<br /><br />Overall, this was just a colossal disappointment. Any merits is does have were done ten times better in the first film. A lazy, unsatisfying - and generally downright boring - mess.'\n",
            "Label : 0 (neg)\n",
            "Review: b\"- I had planned to write something explaining what I didn't like about this movie, but this is going to be more difficult than I thought. Honestly, I can't remember much about it. I watched it just three days ago and it's made almost no impression on me. That's usually the sign of a real stinker. About the only thing I remember was being incredibly bored by most of it. The novelty of having a Humphrey Bogart look-a-like as the detective wore off real quick. It would be different if he could act, but he's a one-note entertainer. The kill scenes were amateurishly handled and there was no suspense leading up to them. If you can't spot the killer five minutes into the movie, you need to see more Euro horror. The casting is a dead giveaway to the killer's identity.\"\n",
            "Label : 0 (neg)\n",
            "Review: b'Skippy from \"Family Ties\" plays Eddie, a wussy \\'metal\\' nerd who gets picked on. When his favorite wussy \\'metal\\' singer, Sammi Curr, dies, he throws a hissy fit tearing down all the posters on his bedroom wall. But when he later gets an unreleased record that holds the spirit of his dead \\'metal\\' idol. He first gets sucked into ideas of revenge, but then he doesn\\'t want to take it as far as Sammi does. Which isn\\'t really that far as his main victims only seem to go to the hospital. This movie is utterly laughable and has about as much to do with real metal as say, \"Rock Star\". OK, maybe a tad more than that piece of junk, but you get my point. And how ANYone can root for a guy played by Skippy from \"Family Ties\" I haven\\'t a clue. The cameo by Gene Simmons is OK, and Ozzy Osbourne reaches coherency, I applaud him for that, but otherwise skip this one.<br /><br />My Grade: D <br /><br />Eye Candy:Elise Richards gets topless, an a topless extra at a pool party'\n",
            "Label : 0 (neg)\n",
            "Review: b'Let\\'s start this review out on a positive note -- I am very glad they didn\\'t decide to wimp out with Tony being shot and do a retrospective season like some people were rumoring. Actually, creator and writer of this episode David Chase did quite the opposite. We don\\'t actually know if Tony will live or die. He\\'s in a coma and his chances of recovering are very slim to none. This episode seemed to move very slow, and the coma induced dream Tony was in involving mistaken identity and robed Asian monks slapping the sh*t out of him was absolutely, flat-out weird. After 45-minutes I got a little sick of everyone grieving, but that shouldn\\' t be a reason to slam this episode. It was a weird and unpredictable episode, but it was still well-written and intense. Edie Falco gave an astounding career-defining performance in this episode as the conflicted wife having to face with her husband\\'s could-be demise. I also found it interesting AJ dropped out of school and swore a vendetta against Junior, which AJ most likely won\\'t have the balls to pull off. Silvio is now acting-boss which opens numerous doors to problems in later episodes. There were a lot of great quips in this episode, also, and I think Vito \\'Pole-Smoker\\' Spadafore may meet his demise if he keeps being a greedy S.O.B.<br /><br />This wasn\\'t a great episode and disappointed only because even though Tony kills people, we as an audience adore him and feel he is our hero of the show. This was a necessary episode for the series, even though it was a little snore inducing towards the conclusion. Kudos to Edie Falco\\'s performance, and David Chase and the writers for creating this wholly original and unpredictable plot twist. This is the only season of \\'The Sopranos\\' where I haven\\'t a f*cking clue where it is going to go. I can\\'t wait for next week\\'s episode. My Rating: 7.5/10 <br /><br />Best Line of the Episode: (Paulie to AJ): \"Let\\'s go, Van Helsing!\"'\n",
            "Label : 1 (pos)\n",
            "Review: b'There\\'s a lot of good that can be said for this cartoon; the backgrounds are rich, lushly colored and full of nicely done art deco details. The animation is up to the usual studio standards of the time, which are unquestionably higher than those of the present day. However, I find it tedious for a number of reasons.<br /><br />The Music: It\\'s definitely not up to Scott Bradley\\'s usual standards. Although it\\'s probably supposed to be evocative of a \"Great Gatsby\" setting, it ends up being dreary, sleepy, repetitious AND monotonous (repetitious and monotonous are not the same, as Beethoven\\'s 5th Symphony attests). Since most people (including me) tend to close their eyes when they yawn, there\\'s a lot of the visual part of the cartoon that will be missed by the average viewer.<br /><br />The Storyline: I\\'m not giving away any secrets that aren\\'t already in the plot summary - country good, city bad. This is a common theme in films, both animated and live, from this era. It\\'s a misplaced nostalgia for a nonexistent rural idyll, which, in the present day, is reflected in a similar nostalgia for \"values\" that never were.'\n",
            "Label : 0 (neg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dX8FtlpGJRE6"
      },
      "source": [
        "## Loading models from TensorFlow Hub\n",
        "\n",
        "Here you can choose which BERT model you will load from TensorFlow Hub and fine-tune. There are multiple BERT models available.\n",
        "\n",
        "  - [BERT-Base](https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3), [Uncased](https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3) and [seven more models](https://tfhub.dev/google/collections/bert/1) with trained weights released by the original BERT authors.\n",
        "  - [Small BERTs](https://tfhub.dev/google/collections/bert/1) have the same general architecture but fewer and/or smaller Transformer blocks, which lets you explore tradeoffs between speed, size and quality.\n",
        "  - [ALBERT](https://tfhub.dev/google/collections/albert/1): four different sizes of \"A Lite BERT\" that reduces model size (but not computation time) by sharing parameters between layers.\n",
        "  - [BERT Experts](https://tfhub.dev/google/collections/experts/bert/1): eight models that all have the BERT-base architecture but offer a choice between different pre-training domains, to align more closely with the target task.\n",
        "  - [Electra](https://tfhub.dev/google/collections/electra/1) has the same architecture as BERT (in three different sizes), but gets pre-trained as a discriminator in a set-up that resembles a Generative Adversarial Network (GAN).\n",
        "  - BERT with Talking-Heads Attention and Gated GELU [[base](https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1), [large](https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_large/1)] has two improvements to the core of the Transformer architecture.\n",
        "\n",
        "The model documentation on TensorFlow Hub has more details and references to the\n",
        "research literature. Follow the links above, or click on the [`tfhub.dev`](http://tfhub.dev) URL\n",
        "printed after the next cell execution.\n",
        "\n",
        "The suggestion is to start with a Small BERT (with fewer parameters) because this will be faster to fine-tune. A small model  with higher accuracy would be ALBERT. If you want even better accuracy, choose one of the classic BERT sizes or their recent refinements like Electra, Talking Heads, or a BERT Expert.\n",
        "\n",
        "Aside from the models available below, there are [multiple versions](https://tfhub.dev/google/collections/transformer_encoders_text/1) of the models that are larger and can yield even better accuracy, but they are too big to be fine-tuned in a Colab VM. \n",
        "\n",
        "You'll see in the code below that switching the tfhub.dev URL is enough to try any of these models, because all the differences between them are encapsulated in the SavedModels from TF Hub.\n",
        "\n",
        "You can read the original BERT model hyperparameters from the filenames below. For example, L=4 hidden layers, a hidden vector size of H=512, and A=8 attention heads for a dictionary of lowercased English words would be bert_en_uncased_L-4_H-512_A-8. Roughly speaking, models with larger internal components will take much longer to fine-tune but will also exhibit much greater context sensitivity.\n",
        "\n",
        "Note the use of Jupyter forms in this code box - some of these features are unique to Colab. You can use the dropdown arrow at the far right to select among the options. These are controlled by @param."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8_ctG55-uTX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e66b432-76b3-4c14-8c8b-294d145f090b"
      },
      "source": [
        "#@title Choose a BERT model to fine-tune\n",
        "\n",
        "bert_model_name = 'small_bert/bert_en_uncased_L-6_H-768_A-12'  #@param [\"bert_en_uncased_L-12_H-768_A-12\", \"bert_en_cased_L-12_H-768_A-12\", \"bert_multi_cased_L-12_H-768_A-12\", \"small_bert/bert_en_uncased_L-2_H-128_A-2\", \"small_bert/bert_en_uncased_L-2_H-256_A-4\", \"small_bert/bert_en_uncased_L-2_H-512_A-8\", \"small_bert/bert_en_uncased_L-2_H-768_A-12\", \"small_bert/bert_en_uncased_L-4_H-128_A-2\", \"small_bert/bert_en_uncased_L-4_H-256_A-4\", \"small_bert/bert_en_uncased_L-4_H-512_A-8\", \"small_bert/bert_en_uncased_L-4_H-768_A-12\", \"small_bert/bert_en_uncased_L-6_H-128_A-2\", \"small_bert/bert_en_uncased_L-6_H-256_A-4\", \"small_bert/bert_en_uncased_L-6_H-512_A-8\", \"small_bert/bert_en_uncased_L-6_H-768_A-12\", \"small_bert/bert_en_uncased_L-8_H-128_A-2\", \"small_bert/bert_en_uncased_L-8_H-256_A-4\", \"small_bert/bert_en_uncased_L-8_H-512_A-8\", \"small_bert/bert_en_uncased_L-8_H-768_A-12\", \"small_bert/bert_en_uncased_L-10_H-128_A-2\", \"small_bert/bert_en_uncased_L-10_H-256_A-4\", \"small_bert/bert_en_uncased_L-10_H-512_A-8\", \"small_bert/bert_en_uncased_L-10_H-768_A-12\", \"small_bert/bert_en_uncased_L-12_H-128_A-2\", \"small_bert/bert_en_uncased_L-12_H-256_A-4\", \"small_bert/bert_en_uncased_L-12_H-512_A-8\", \"small_bert/bert_en_uncased_L-12_H-768_A-12\", \"albert_en_base\", \"electra_small\", \"electra_base\", \"experts_pubmed\", \"experts_wiki_books\", \"talking-heads_base\"]\n",
        "\n",
        "map_name_to_handle = {\n",
        "    'bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n",
        "    'bert_en_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n",
        "    'bert_multi_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n",
        "    'albert_en_base':\n",
        "        'https://tfhub.dev/tensorflow/albert_en_base/2',\n",
        "    'electra_small':\n",
        "        'https://tfhub.dev/google/electra_small/2',\n",
        "    'electra_base':\n",
        "        'https://tfhub.dev/google/electra_base/2',\n",
        "    'experts_pubmed':\n",
        "        'https://tfhub.dev/google/experts/bert/pubmed/2',\n",
        "    'experts_wiki_books':\n",
        "        'https://tfhub.dev/google/experts/bert/wiki_books/2',\n",
        "    'talking-heads_base':\n",
        "        'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n",
        "}\n",
        "\n",
        "map_model_to_preprocess = {\n",
        "    'bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'bert_en_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'bert_multi_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3',\n",
        "    'albert_en_base':\n",
        "        'https://tfhub.dev/tensorflow/albert_en_preprocess/3',\n",
        "    'electra_small':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'electra_base':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'experts_pubmed':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'experts_wiki_books':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'talking-heads_base':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "}\n",
        "\n",
        "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
        "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
        "\n",
        "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
        "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1\n",
            "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEyCF3B49mV_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b51ec13-6e04-4e23-a031-d66e232471fb"
      },
      "source": [
        "#\n",
        "# Exercise 12.4 - Create a small Jupyter form here that controls batch size.\n",
        "# Have the batch_size default to 32 as it was set in an earlier code block.\n",
        "# Hint: This notebook provides an easy overview and tutorial of forms in\n",
        "# Colab notebooks: https://colab.research.google.com/notebooks/forms.ipynb\n",
        "#\n",
        "number_slider = 32 #@param {type:\"slider\", min:10, max:128, step:1}\n",
        "print(number_slider)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WrcxxTRDdHi"
      },
      "source": [
        "## The preprocessing model\n",
        "\n",
        "Text inputs need to be transformed to numeric token ids and arranged in several Tensors before being input to BERT. TensorFlow Hub provides a matching preprocessing model for each of the BERT models discussed above, which implements this transformation using TF ops from the TF.text library. Having tensorflow manage these processes without regular Python code can enable great speed improvements in preprocessing large datasets.\n",
        "\n",
        "The preprocessing model MUST be the one referenced by the documentation of the BERT model, which you can read at the URL printed above. For BERT models from the drop-down above, the preprocessing model is selected automatically.\n",
        "\n",
        "Note: You will load the preprocessing model into a [hub.KerasLayer](https://www.tensorflow.org/hub/api_docs/python/hub/KerasLayer) to compose your fine-tuned model. This is the preferred API to load a TF2-style SavedModel from TF Hub into a Keras model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SQi-jWd_jzq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "860b1d6f-eda4-4e26-a386-0647bafd760f"
      },
      "source": [
        "# Wraps a SavedModel (or a legacy TF1 Hub format) as a Keras Layer\n",
        "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)\n",
        "\n",
        "type(bert_preprocess_model)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow_hub.keras_layer.KerasLayer"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4naBiEE_cZX"
      },
      "source": [
        "Let's try the preprocessing model on a piece of text and see the output:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9-zCzJpnuwS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc766629-19a8-4afe-cf18-a2f05b70526d"
      },
      "source": [
        "text_test = ['This is a truly awful, terrible, stinky movie!']\n",
        "text_preprocessed = bert_preprocess_model(text_test)\n",
        "\n",
        "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
        "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
        "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}') # Just show the first 12 IDs; we don't need to review all 128 of them\n",
        "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}') # Just show the first 12 masks; note that once we get into the pads, they are all masked off\n",
        "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}') # See below about multi-element input"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys       : ['input_mask', 'input_type_ids', 'input_word_ids']\n",
            "Shape      : (1, 128)\n",
            "Word Ids   : [  101  2023  2003  1037  5621  9643  1010  6659  1010 27136  2100  3185]\n",
            "Input Mask : [1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "Type Ids   : [0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kshj2KhnX5S3"
      },
      "source": [
        "Note how the word ID output shows a start token (101) and an end token (102), as well as pad tokens on the end. All BERT models use these markers to set the context for the words in a sentence. Note that BERT also uses a SEP character for multi-element input (as in more than one sentence in a single input sequence). One of the innovations of BERT is that it generates  embeddings that are context-sensitive through self-attention. To accomplish that trick we need the start and end markers to help establish the context for each word in the sequence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bl8-Z32M-Csz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0acbc916-2aba-4f40-bf76-2acf6c3d84cc"
      },
      "source": [
        "#\n",
        "# Exercise 12.5 - Make a change to one word in text_test and rerun the code\n",
        "# in the block just above. Copy the code to this block so you can compare \n",
        "# the outputs. Make sure to save the output of bert_preprocess_model(text_test)\n",
        "# to a different variable, so you have two preprocessor outputs for later.\n",
        "#\n",
        "text_test2 = ['This is a truly beautiful, terrible, stinky movie!']\n",
        "text_preprocessed2 = bert_preprocess_model(text_test)\n",
        "\n",
        "print(f'Keys       : {list(text_preprocessed2.keys())}')\n",
        "print(f'Shape      : {text_preprocessed2[\"input_word_ids\"].shape}')\n",
        "print(f'Word Ids   : {text_preprocessed2[\"input_word_ids\"][0, :12]}') # Just show the first 12 IDs; we don't need to review all 128 of them\n",
        "print(f'Input Mask : {text_preprocessed2[\"input_mask\"][0, :12]}') # Just show the first 12 masks; note that once we get into the pads, they are all masked off\n",
        "print(f'Type Ids   : {text_preprocessed2[\"input_type_ids\"][0, :12]}') # See below about multi-element input"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys       : ['input_mask', 'input_type_ids', 'input_word_ids']\n",
            "Shape      : (1, 128)\n",
            "Word Ids   : [  101  2023  2003  1037  5621  9643  1010  6659  1010 27136  2100  3185]\n",
            "Input Mask : [1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "Type Ids   : [0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqL7ihkN_862"
      },
      "source": [
        "As you can see, now you have the 3 outputs from the preprocessing that a BERT model would use (`input_words_id`, `input_mask` and `input_type_ids`).\n",
        "\n",
        "Some other important points:\n",
        "- The input is truncated to 128 tokens. The number of tokens can be customized, and you can see more details on the [Solve GLUE tasks using BERT on a TPU colab](https://www.tensorflow.org/text/tutorials/bert_glue).\n",
        "- The `input_type_ids` only have one value (0) because this is a single sentence input. For a multiple sentence input, it would have one number for each input.\n",
        "\n",
        "Since this text preprocessor is a TensorFlow model, It can be included in your model directly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKnLPSEmtp9i"
      },
      "source": [
        "## Using the BERT model\n",
        "\n",
        "Before putting BERT into your own model, let's take a look at its outputs. You will load it from TF Hub and see the returned values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXxYpK8ixL34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e975f215-c493-462a-fa24-799d75c42282"
      },
      "source": [
        "# Again with the wrapper: Wraps a SavedModel (or a legacy TF1 Hub format) as a Keras Layer\n",
        "bert_model = hub.KerasLayer(tfhub_handle_encoder)\n",
        "\n",
        "type(bert_model)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow_hub.keras_layer.KerasLayer"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OoF9mebuSZc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c547031-6edb-4209-fb27-722e57d78822"
      },
      "source": [
        "bert_results = bert_model(text_preprocessed)\n",
        "\n",
        "print(f'Loaded BERT: {tfhub_handle_encoder}')\n",
        "print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
        "print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\n",
        "print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
        "print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded BERT: https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1\n",
            "Pooled Outputs Shape:(1, 768)\n",
            "Pooled Outputs Values:[ 0.16053838 -0.27219185  0.438637    0.3036405  -0.09600565 -0.34465447\n",
            "  0.50792944 -0.58160806  0.07469921  0.3828426  -0.9632549  -0.8083539 ]\n",
            "Sequence Outputs Shape:(1, 128, 768)\n",
            "Sequence Outputs Values:[[ 0.07618193 -0.31737947 -0.4014785  ... -0.4593331   0.07710469\n",
            "   0.82023823]\n",
            " [ 0.327652    0.13737716 -0.5779009  ... -0.41215688  0.15135515\n",
            "   0.31142122]\n",
            " [-0.43388352 -0.25980157 -0.49037224 ...  0.40389237 -0.5288578\n",
            "   0.6716922 ]\n",
            " ...\n",
            " [ 0.38968724 -0.16754736 -0.65737295 ... -0.2817206   0.20104298\n",
            "   0.5089858 ]\n",
            " [ 0.34887335 -0.36809838 -0.6959432  ...  0.12742592 -0.03341261\n",
            "   0.42347735]\n",
            " [ 0.08028224  0.3274457  -0.40305227 ... -0.26666847  0.2974277\n",
            "   0.46419546]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sm61jDrezAll"
      },
      "source": [
        "The BERT models return a map with 3 important keys: `pooled_output`, `sequence_output`, `encoder_outputs`:\n",
        "\n",
        "- `pooled_output` represents each input sequence as a whole. The shape is `[batch_size, H]`. In this case H is the vector dimensionality of the hidden vectors. You can think of each one of these vectors as an embedding for the entire movie review.\n",
        "- `sequence_output` represents each input token in the context. The shape is `[batch_size, seq_length, H]`. You can think of this as an embedding for every token in the movie review.\n",
        "- `encoder_outputs` are the intermediate activations of the `L` Transformer blocks. `outputs[\"encoder_outputs\"][i]` is a Tensor of shape `[batch_size, seq_length, 1024]` with the outputs of the i-th Transformer block, for `0 <= i < L`. The last value of the list is equal to `sequence_output`.\n",
        "\n",
        "For the fine-tuning we will be using the `pooled_output` array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1GuCIcj-tO_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e7c282d-4fda-474f-bf5c-81a7547b7a95"
      },
      "source": [
        "#\n",
        "# Exercise 12.6 - Run your second preprocessed sentence through the bert_model\n",
        "# as shown above. \n",
        "#\n",
        "bert_results2 = bert_model(text_preprocessed2)\n",
        "\n",
        "print(f'Loaded BERT: {tfhub_handle_encoder}')\n",
        "print(f'Pooled Outputs Shape:{bert_results2[\"pooled_output\"].shape}')\n",
        "print(f'Pooled Outputs Values:{bert_results2[\"pooled_output\"][0, :12]}')\n",
        "print(f'Sequence Outputs Shape:{bert_results2[\"sequence_output\"].shape}')\n",
        "print(f'Sequence Outputs Values:{bert_results2[\"sequence_output\"][0, :12]}')"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded BERT: https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1\n",
            "Pooled Outputs Shape:(1, 768)\n",
            "Pooled Outputs Values:[ 0.16053838 -0.27219185  0.438637    0.3036405  -0.09600565 -0.34465447\n",
            "  0.50792944 -0.58160806  0.07469921  0.3828426  -0.9632549  -0.8083539 ]\n",
            "Sequence Outputs Shape:(1, 128, 768)\n",
            "Sequence Outputs Values:[[ 0.07618193 -0.31737947 -0.4014785  ... -0.4593331   0.07710469\n",
            "   0.82023823]\n",
            " [ 0.327652    0.13737716 -0.5779009  ... -0.41215688  0.15135515\n",
            "   0.31142122]\n",
            " [-0.43388352 -0.25980157 -0.49037224 ...  0.40389237 -0.5288578\n",
            "   0.6716922 ]\n",
            " ...\n",
            " [ 0.38968724 -0.16754736 -0.65737295 ... -0.2817206   0.20104298\n",
            "   0.5089858 ]\n",
            " [ 0.34887335 -0.36809838 -0.6959432  ...  0.12742592 -0.03341261\n",
            "   0.42347735]\n",
            " [ 0.08028224  0.3274457  -0.40305227 ... -0.26666847  0.2974277\n",
            "   0.46419546]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Fz-AT_t-5FI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "outputId": "d1bf1bdc-9db1-44aa-a5bb-9432e734069a"
      },
      "source": [
        "#\n",
        "# Advanced/Optional Exercise 12.7 - Use a graphic (such as a scatterplot) or \n",
        "# statistic (such as a correlation) to compare the\n",
        "# the pooled outputs from the two similar test sentences.\n",
        "#\n",
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(bert_results[\"pooled_output\"], bert_results2[\"pooled_output\"])"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f81802723d0>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDNKfAXbDnJH"
      },
      "source": [
        "## Define your model\n",
        "\n",
        "You will create an extremely simple model to fine-tune, with the preprocessing model, the selected BERT model, and one Dense node preceded by a Dropout layer. The Dropout layer is to control overfitting. The single Dense node is what will predict our two-class output.\n",
        "\n",
        "Note: for more information about the base model's input and output, follow the model's URL to review documentation. Because we used the preprocessing model that was paired with our BERT model, we don't need to mess with the preprocessing details.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aksj743St9ga"
      },
      "source": [
        "# Model building call: We are using the functional interface here.\n",
        "def build_classifier_model(dropout_ratio):\n",
        "  #Take input ans store as a tensor layer of input\n",
        "  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "  #Create preprocessing layer \n",
        "  preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
        "  #Create encoder inputs from preprocessing layer\n",
        "  encoder_inputs = preprocessing_layer(text_input)\n",
        "  #Define the coder with trainable parameters = True to fine tune the model\n",
        "  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder') # Here's the BERT model, with trainable=True so that we can fine tune\n",
        "  #Create output from encoder using encoder inputs\n",
        "  outputs = encoder(encoder_inputs)\n",
        "  #Create output of the pooled out\n",
        "  net = outputs['pooled_output']\n",
        "  #Add a dropout layer to prevent overfitting\n",
        "  net = tf.keras.layers.Dropout(dropout_ratio)(net) # Help to prevent overfitting\n",
        "  \n",
        "  # End with the ability to do binary classification: But why is activation=None?\n",
        "  #The final classification model in BERT is a dense layer, with no activation function\n",
        "  #Because this output of unnormalised logits is then passed to the softmax function \n",
        "  #to obtain class probabilities\n",
        "  net = tf.keras.layers.Dense(1, activation=None, name='classifier')(net) \n",
        "  return tf.keras.Model(text_input, net)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#building a classification model using BERT attention weights\n",
        "classifier_model = build_classifier_model(dropout_ratio=0.1)\n",
        "#We see the type of classifier model as keras engine functional type\n",
        "type(classifier_model)"
      ],
      "metadata": {
        "id": "kMRslVeCRQvv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55085dd4-89aa-49d0-e857-e43efdd00688"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "keras.engine.functional.Functional"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xreyopjf_Yrg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "597ee2ff-fb3c-4947-9aa5-d1426ac6ed07"
      },
      "source": [
        "#\n",
        "# Exercise 12.8 - Add comments to the build_classifier_model(), documenting \n",
        "# each layer of the model. Then run a model.summary() to look at the model\n",
        "# configuration.\n",
        "#\n",
        "classifier_model.summary()\n"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text (InputLayer)              [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " preprocessing (KerasLayer)     {'input_type_ids':   0           ['text[0][0]']                   \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_mask': (Non                                               \n",
            "                                e, 128)}                                                          \n",
            "                                                                                                  \n",
            " BERT_encoder (KerasLayer)      {'pooled_output': (  66955009    ['preprocessing[0][0]',          \n",
            "                                None, 768),                       'preprocessing[0][1]',          \n",
            "                                 'sequence_output':               'preprocessing[0][2]']          \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 'encoder_outputs':                                               \n",
            "                                 [(None, 128, 768),                                               \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768)],                                               \n",
            "                                 'default': (None,                                                \n",
            "                                768)}                                                             \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 768)          0           ['BERT_encoder[0][7]']           \n",
            "                                                                                                  \n",
            " classifier (Dense)             (None, 1)            769         ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 66,955,778\n",
            "Trainable params: 66,955,777\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zs4yhFraBuGQ"
      },
      "source": [
        "Let's check that the model runs with the output of the preprocessing model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGMF8AZcB2Zy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "601babbd-a79f-4d29-9ce5-b492824088bd"
      },
      "source": [
        "# Process one instance into the not-yet-fine-tuned model\n",
        "bert_raw_result = classifier_model(tf.constant(text_test))\n",
        "print(tf.sigmoid(bert_raw_result))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[0.86313164]], shape=(1, 1), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Checkpoint! Report the Sigmoid Results of Processing Test Text\n",
        "\n",
        "The code block just above produced a tensor containing just one value which was the result of using a sigmoid transformation on the output of the \"not yet fine tuned\" model. Write your name on the white board with the value next to it. You can round to three digits of precision.\n",
        "\n",
        "\n",
        "\n",
        "#Discuss: Discuss the fine tuning process with your partner\n",
        "\n",
        "Make sure you understand what has happened so far. We have initialized a model that accepts a token sequence as input, sends that into a BERT layer, and sends the pooling output of the BERT layer into a single dense node. You should be able to answer these questions:\n",
        "\n",
        "* How many weights does the BERT layer have? Is this a lot?\n",
        "* How were the weights in the BERT model initialized? Or are they simply random?\n",
        "* The dense node should have 129 trainable parameters. Where did this number come from? \n",
        "* Which parameters in the model will be affected by the fine tuning process?"
      ],
      "metadata": {
        "id": "-HuZwei8DvXB"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSK0pbl6_pgh"
      },
      "source": [
        "#\n",
        "# Exercise 12.9 - Add a comment explaining why the output of the previous block\n",
        "# is a single float value. What does that have to do with the problem we are\n",
        "# using the model to address? The sigmoid() transformation does what to the \n",
        "# raw output of the Dense node?\n",
        "#\n",
        "# Hint: You might want to try a sentence with completely opposite polarity,\n",
        "# Like this: tf.sigmoid(classifier_model(tf.constant([\"Best movie ever!\"])))\n",
        "#\n",
        "\n",
        "#The output is the final probability from the softmax function\n",
        "#This gives the probability that the text is positive or negative in polarity\n",
        "#Using sigmoid function, we can approximate the probability for 0 or 1 to classify\n",
        "#Running an opposit polarity, we get a very low softmax value."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTUzNV2JE2G3"
      },
      "source": [
        "The output is not going to be very informative, of course, because the model has not been fine-tuned yet. Keep in mind, however, that the pre-trained BERT model does have a fair bit of intelligence, as it has been trained on a large amount of text (just not for any particular task.\n",
        "\n",
        "Let's take a look at the model's structure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EmzyHZXKIpm"
      },
      "source": [
        "tf.keras.utils.plot_model(classifier_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbUWoZMwc302"
      },
      "source": [
        "## Model training\n",
        "\n",
        "You now have all the pieces to train a model, including the preprocessing module, BERT encoder, data, and classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpJ3xcwDT56v"
      },
      "source": [
        "### Loss function\n",
        "\n",
        "Since this is a binary classification problem and the model outputs a probability (a single-unit layer), the `losses.BinaryCrossentropy` loss function is the most appropriate choice.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWPOZE-L3AgE"
      },
      "source": [
        "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "metrics = tf.metrics.BinaryAccuracy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77psrpfzbxtp"
      },
      "source": [
        "### Optimizer\n",
        "\n",
        "For fine-tuning, let's use the same optimizer that BERT was originally trained with: the \"Adaptive Moments\" (Adam). This optimizer minimizes the prediction loss and does regularization by weight decay (not using moments), which is also known as [AdamW](https://arxiv.org/abs/1711.05101).\n",
        "\n",
        "For the learning rate (`init_lr`), we use the same schedule as BERT pre-training: linear decay of a notional initial learning rate, prefixed with a linear warm-up phase over the first 10% of training steps (`num_warmup_steps`). In line with the BERT paper, the initial learning rate is smaller for fine-tuning (best of 5e-5, 3e-5, 2e-5)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9eP2y9dbw32"
      },
      "source": [
        "epochs = 3 # Five might be a little better but three seems to suffice\n",
        "# The training model keeps improving after three epochs, but the validation\n",
        "# only increments by a very small amount.\n",
        "\n",
        "steps_per_epoch = tf.data.experimental.cardinality(train_ds).numpy()\n",
        "num_train_steps = steps_per_epoch * epochs\n",
        "num_warmup_steps = int(0.1*num_train_steps)\n",
        "\n",
        "init_lr = 3e-5\n",
        "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
        "                                          num_train_steps=num_train_steps,\n",
        "                                          num_warmup_steps=num_warmup_steps,\n",
        "                                          optimizer_type='adamw')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqlarlpC_v0g"
      },
      "source": [
        "### Loading the BERT model and training\n",
        "\n",
        "Using the `classifier_model` you created earlier, you can compile the model with the loss, metric and optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7GPDhR98jsD"
      },
      "source": [
        "classifier_model.compile(optimizer=optimizer,\n",
        "                         loss=loss,\n",
        "                         metrics=metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ngcuk7BNAUn6"
      },
      "source": [
        "#\n",
        "# Exercise 12.9 - What is the value of num_warmup_steps? Do a search for\n",
        "# \"Learning Rate Warmup\" and add a comment describing what num_warmup_steps\n",
        "# is doing. \n",
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpBuV5j2cS_b"
      },
      "source": [
        "Note: training time will vary depending on the complexity of the BERT model you have selected."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtfDFAnN_Neu"
      },
      "source": [
        "print(f'Training model with {tfhub_handle_encoder}')\n",
        "history = classifier_model.fit(x=train_ds,\n",
        "                               validation_data=val_ds,\n",
        "                               epochs=epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure you examine the progress of validation loss and validation accuracy. By this point in the course, you should have substantial expertise in making sense of these values. How do you know if the progress of your validation loss is good or not-so-good?"
      ],
      "metadata": {
        "id": "jpS4M29_UHex"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBthMlTSV8kn"
      },
      "source": [
        "### Evaluate the model\n",
        "\n",
        "Let's see how the model performs on the holdout data set (test_ds). The model has not seen the contents of this dataset before. Two values will be returned. Loss (a number which represents the error, lower values are better), and accuracy. You should compare the loss and accuracy with the values that concluded the training process above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slqB-urBV9sP"
      },
      "source": [
        "loss, accuracy = classifier_model.evaluate(test_ds)\n",
        "\n",
        "print(f'Loss: {loss}')\n",
        "print(f'Accuracy: {accuracy}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uttWpgmSfzq9"
      },
      "source": [
        "### Plot the accuracy and loss over time\n",
        "\n",
        "Based on the `History` object returned by `model.fit()`. You can plot the training and validation loss for comparison, as well as the training and validation accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiythcODf0xo"
      },
      "source": [
        "history_dict = history.history\n",
        "print(history_dict.keys())\n",
        "\n",
        "acc = history_dict['binary_accuracy']\n",
        "val_acc = history_dict['val_binary_accuracy']\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "fig = plt.figure(figsize=(10, 6))\n",
        "fig.tight_layout()\n",
        "\n",
        "plt.subplot(2, 1, 1)\n",
        "# \"bo\" is for \"blue dot\"\n",
        "plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "# b is for \"solid blue line\"\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "# plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(epochs, acc, 'r', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzJZCo-cf-Jf"
      },
      "source": [
        "In this plot, the red lines represent the training loss and accuracy, and the blue lines are the validation loss and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dH8-nCKXAsLl"
      },
      "source": [
        "#\n",
        "# Exercise 12.10 - Make note of the shape and final values of the Loss and \n",
        "# accuracy functions so that you can compare later with a different BERT model.\n",
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShcvqJAgVera"
      },
      "source": [
        "# This will save your model so that it can be reloaded later\n",
        "if save_model == True:\n",
        "  dataset_name = 'imdb'\n",
        "  saved_model_path = './{}_bert'.format(dataset_name.replace('/', '_'))\n",
        "\n",
        "  classifier_model.save(saved_model_path, include_optimizer=False)\n",
        "  save_model = False # Only do this once, so that there is one model on disk to reload"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PrmgfRvA3NR"
      },
      "source": [
        "#\n",
        "# Exercise 12.11 - Return to the Jupyter form earlier in this notebook and\n",
        "# choose a different BERT model to fine tune. Keep it small so that you have time\n",
        "# to train it today in class! Compare your results with what you found on the first\n",
        "# model. Have you achieved any improvement?\n",
        "#\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rtn7jewb6dg4"
      },
      "source": [
        "## Reload for model comparison.\n",
        "\n",
        "You should have one model stored to disk and if you tested a second model, the first model will not be in memory. It is important to make performance comparisons between the two models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iikSynz7QEPj"
      },
      "source": [
        "# Exercise 12.12 - \n",
        "# Optionally zip the imdb_bert directory so that it can be downloaded to your local\n",
        "# machine. This would make it possible to restore the model.\n",
        "# !zip -r imdb_bert.zip imdb_bert # Uncomment this to save zip file\n",
        "# This zips down to about a few MB, depending upon the size of the BERT model.\n",
        "\n",
        "# If you later upload the zip file to the file area for this VM, you can unzip \n",
        "# the imdb_bert.zip file into the corresponding directory of model data:\n",
        "# !unzip imdb_bert.zip\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbI25bS1vD7s"
      },
      "source": [
        "Let's reload the model, so you can try it side by side with the model that is still in memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUEWVskZjEF0"
      },
      "source": [
        "reloaded_model = tf.saved_model.load(saved_model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyTappHTvNCz"
      },
      "source": [
        "Here you can test your models on any sentences you want, just add to the examples variable below. Note that if you are running this code but have only trained one BERT model, the scores will naturally be identical."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBWzH6exlCPS"
      },
      "source": [
        "def print_my_examples(inputs, results):\n",
        "  result_for_printing = \\\n",
        "    [f'input: {inputs[i]:<30} : score: {results[i][0]:.6f}'\n",
        "                         for i in range(len(inputs))]\n",
        "  print(*result_for_printing, sep='\\n')\n",
        "  print()\n",
        "\n",
        "\n",
        "examples = [\n",
        "    'this is such an amazing movie!',  \n",
        "    'The movie was great!',\n",
        "    'The movie was meh.',\n",
        "    'The movie was okish.',\n",
        "    'The movie was terrible...'\n",
        "]\n",
        "\n",
        "reloaded_results = tf.sigmoid(reloaded_model(tf.constant(examples)))\n",
        "original_results = tf.sigmoid(classifier_model(tf.constant(examples)))\n",
        "\n",
        "print('Results from the saved model:')\n",
        "print_my_examples(examples, reloaded_results)\n",
        "print('Results from the model in memory:')\n",
        "print_my_examples(examples, original_results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Exercise 12.13 - Comment on the scores produced by the two models. Which\n",
        "# model seems more accurate to you? Why would this be true? \n"
      ],
      "metadata": {
        "id": "mDvqbE5CYYux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yv8I8HaoBYV7"
      },
      "source": [
        "#\n",
        "# Exercise 12.14 - Write two more test sentences that attempt to achieve a \n",
        "# maximum and minimum output score, using both the in-memory model and \n",
        "# the reloaded model.\n",
        "#\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}