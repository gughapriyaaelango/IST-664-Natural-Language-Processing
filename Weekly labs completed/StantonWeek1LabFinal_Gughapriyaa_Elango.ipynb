{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiy-ZEZZlLlh"
      },
      "source": [
        "**IST664 - NLP Lab Week 1**\n",
        "\n",
        "Edited by Jeff Stanton for IST664/CIS668. Students may freely excerpt this code for use in homework and projects with appropriate attribution. \n",
        "\n",
        "During the lab, you should run the code one block at a time and make sure you know what each line of code accomplished. Add commments to explain the code to your future self. Complete as many exercises as you can during the lab period. When you submit the lab, make sure to provide a note in Blackboard with your submission that tells the last exercise you completed.\n",
        "\n",
        "Before getting started on this lab, make sure you have reviewed the introductory Python notebook (unless you are already experienced with Python). In this first section, we will use the Python “import” statement to load the NLTK package. This contains lots of text examples and unique capabilities for basic syntactic analysis of text. Whenever you see a code block containing only a comment (#) follow the instructions to add your own code.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tVAmC7V6Xf9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "820b5c1c-c1eb-4243-b2c8-94e7d33bcd8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data] Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/genesis.zip.\n",
            "[nltk_data] Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n",
            "[nltk_data] Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data] Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/webtext.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Introductory Examples for the NLTK Book ***\n",
            "Loading text1, ..., text9 and sent1, ..., sent9\n",
            "Type the name of the text or sentence to view it.\n",
            "Type: 'texts()' or 'sents()' to list the materials.\n",
            "text1: Moby Dick by Herman Melville 1851\n",
            "text2: Sense and Sensibility by Jane Austen 1811\n",
            "text3: The Book of Genesis\n",
            "text4: Inaugural Address Corpus\n",
            "text5: Chat Corpus\n",
            "text6: Monty Python and the Holy Grail\n",
            "text7: Wall Street Journal\n",
            "text8: Personals Corpus\n",
            "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
          ]
        }
      ],
      "source": [
        "# IST664 - NLP Lab Week 1\n",
        "# This notebook has small examples that are meant to be run step by step.\n",
        "\n",
        "import nltk\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('genesis')\n",
        "nltk.download('inaugural')\n",
        "nltk.download('treebank')\n",
        "nltk.download('nps_chat')\n",
        "nltk.download('webtext')\n",
        "from nltk.book import * # This may throw errors, looking for other downloads\n",
        "# Just add them into the list of downloads above.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0lfwwdt-_OT"
      },
      "source": [
        "Among the loaded objects, NLTK includes 9 of the text examples available from the corpora package (only a very small number of the available texts!). It has used the variable names text1 through text9 for these examples, and already assigned them values. The variables sent1 through sent9 have also been set to be a list of tokens of the first sentence of each text. These are examples from the beginning of the NLTK book. Normally we have to load and process texts ourselves, rather than getting them in prepackaged form."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qQPQXmBJX2cJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65ea267e-e240-4c28-e885-ce965ba6f7bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Text: Moby Dick by Herman Melville 1851>\n"
          ]
        }
      ],
      "source": [
        "print(text1) # Shows the title"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DKIvq6_3m0hu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9dcda78-65fb-4097-ec85-a999796f1f35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Text: Sense and Sensibility by Jane Austen 1811>\n"
          ]
        }
      ],
      "source": [
        "# Now you try it by repeating that last command, but using the imported\n",
        "# data object text2. Describe what text2 contains.\n",
        "print(text2)\n",
        "#\n",
        "# Exercise 1.1: Your description of text2: \n",
        "#text2 contains the text of book - \"Sense and Sensibility\" by author Jane Austen in 1811"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "imavAwY23fWZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cd83d00-2303-4dab-f791-c965aea31709"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nltk.text.Text"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "type(text1) # The type() command reveals the data type of an object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ao58rDlq42y9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4815099-f2f6-428a-faca-e650c39bc671"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['_CONTEXT_RE',\n",
              " '_COPY_TOKENS',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getitem__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__len__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_context',\n",
              " '_train_default_ngram_lm',\n",
              " 'collocation_list',\n",
              " 'collocations',\n",
              " 'common_contexts',\n",
              " 'concordance',\n",
              " 'concordance_list',\n",
              " 'count',\n",
              " 'dispersion_plot',\n",
              " 'findall',\n",
              " 'generate',\n",
              " 'index',\n",
              " 'name',\n",
              " 'plot',\n",
              " 'readability',\n",
              " 'similar',\n",
              " 'tokens',\n",
              " 'vocab']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "dir(text1) # These are the attributes of the object\n",
        "# Check out how the end of the list shows all of the methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "O0zrQaMi5eFj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af1c53d7-c62e-4183-852f-b4ef07ceae1b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Text.concordance of <Text: Moby Dick by Herman Melville 1851>>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Given the list above, we can find out more things about each attribute\n",
        "getattr(text1, \"concordance\")\n",
        "\n",
        "# <bound method Text.concordance of <Text: Moby Dick by Herman Melville 1851>>\n",
        "# A bound method is a function that is an attribute of a class and can be\n",
        "# called using an expression like : text1.concordance()\n",
        "# See the next section for more information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DyHGRJa0klp"
      },
      "outputs": [],
      "source": [
        "# You can also find lots of details about an object by calling help()\n",
        "help(text1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "QLW9IcHT35BJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4c58745-d13e-4801-a143-0650aac09fbc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__add__',\n",
              " '__class__',\n",
              " '__contains__',\n",
              " '__delattr__',\n",
              " '__delitem__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getitem__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__iadd__',\n",
              " '__imul__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__iter__',\n",
              " '__le__',\n",
              " '__len__',\n",
              " '__lt__',\n",
              " '__mul__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__reversed__',\n",
              " '__rmul__',\n",
              " '__setattr__',\n",
              " '__setitem__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " 'append',\n",
              " 'clear',\n",
              " 'copy',\n",
              " 'count',\n",
              " 'extend',\n",
              " 'index',\n",
              " 'insert',\n",
              " 'pop',\n",
              " 'remove',\n",
              " 'reverse',\n",
              " 'sort']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "type(sent1) # What type is sent1\n",
        "#sent1 is a list\n",
        "# Add a line of code that displays the attributes of sent1\n",
        "dir(sent1)\n",
        "#dir() displays attributes\n",
        "# Exercise 1.2: Attributes of sent1 \n",
        "#'append','clear','copy','count','extend','index','insert','pop','remove','reverse','sort'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "QRJ1VIUOX5T2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "298d8c24-c907-4f17-c93f-20bbb84618f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Call', 'me', 'Ishmael', '.']\n"
          ]
        }
      ],
      "source": [
        "print(sent1) # In Python lists are surrounded by [ and ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "a0I4yxQM69a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4a76417-b944-47c8-d0ea-58ffa3e75648"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['.', 'Call', 'Ishmael', 'me']\n"
          ]
        }
      ],
      "source": [
        "sent1.sort() # This reorders the list alphabetically\n",
        "print(sent1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "WcJW-2DF8Bz0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c2046f3-95ca-4c17-9c88-decfaa77ccc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Call', 'Ishmael', 'me']\n"
          ]
        }
      ],
      "source": [
        "sent1.remove('.') # We can delete items by name\n",
        "print(sent1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "YWow54JR8VqF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "740837ce-8a33-466a-cb63-5679655b3874"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Call', 'Ishmael', 'me', '.']\n"
          ]
        }
      ],
      "source": [
        "sent1.append('.') # And we can add an item onto the end of the list\n",
        "print(sent1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "7tNkiaFYYOXR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f4ead56-3a60-4feb-9a2e-caadd925531e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Call Ishmael me .\n"
          ]
        }
      ],
      "source": [
        "# The join method can be applied to a list\n",
        "sent1text = ' '.join(sent1) # You can glue elements of the list back together\n",
        "print(sent1text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "zrVJGccsvIEW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f70462e-9d2f-4cd2-b548-16882a1c3661"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'family', 'of', 'Dashwood', 'had', 'long', 'been', 'settled', 'in', 'Sussex', '.']\n",
            "The family of Dashwood had long been settled in Sussex .\n"
          ]
        }
      ],
      "source": [
        "# Join sent2 back together with spaces in between and then\n",
        "# print it (two lines of code).\n",
        "print(sent2)\n",
        "\n",
        "# Exercise 1.3: Re-join sent2 tokens\n",
        "sent2text=' '.join(sent2)\n",
        "print(sent2text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uj5hUFAkmHYw"
      },
      "source": [
        "**Searching**\n",
        "\n",
        "The text data structure from nltk has a number of bound methods. A flexible way of searching uses the findall() method. Another function is “similar” which finds all the words that are used in the same context as the one given, where the context is the word before and the word after. We can also examine the contexts that are shared by two or more words, such as “monstrous” and “very” by using common_contexts. We have to enclose these words by square brackets as well as parentheses, and separate them with a comma. The output of common_contexts is a pair of words that surrounds both of the target words provided. For example if the target is very and the function returns a_pretty, the fragment in question would be \"a very pretty\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "WaAdHmOVFWQ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08a6cc50-7d53-49ed-caaa-6e9a3f5bc172"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "morning; morning; morning; morning; morning; morning; morning;\n",
            "morning; morning; morning; morning; morning; morning; morning;\n",
            "morning; morning; morning; morning; morning; morning; morning;\n",
            "morning; morning; morning; morning; morning; morning; morning;\n",
            "morning; morning; morning; morning; morning; morning; morning;\n",
            "morning; morning; morning; morning; morning; morning; morning;\n",
            "morning; morning; morning; morning; morning; morning; morning;\n",
            "morning; morning; morning; morning; morning; morning; morning;\n",
            "morning; morning; morning; morning; morning; morning; morning;\n",
            "morning; morning; morning; morning; morning\n"
          ]
        }
      ],
      "source": [
        "# A flexible capability is provided by findall(), which can use a \n",
        "# \"regular expression\" to find instances. Single tokens must be surrounded\n",
        "# by angle brackets < >\n",
        "text1.findall('<morning>')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "-7gbz4FDKOyM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b179520b-14c8-4733-e1e1-3c1192f80b67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Morning to ye; Morning to ye; Morning to ye; Morning to ye; Morning to\n",
            "ye\n"
          ]
        }
      ],
      "source": [
        "# Note that these token specifications are case sensitive\n",
        "text1.findall('<Morning><to><ye>')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "nasu93P_KtZx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4eb44542-9105-479b-8038-09219f3ae099"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Morning to ye , shipmates; Morning to ye , shipmates; Morning to ye ,\n",
            "shipmates; Morning to ye .\" Once; Morning to ye ! morning\n"
          ]
        }
      ],
      "source": [
        "# We can also include two wildcard tokens to find out what comes next\n",
        "text1.findall('<Morning><to><ye><.*><.*>')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "29_anrs4RJlJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae7f3da6-3336-4fea-db53-0c320e407247"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sea time whale ship man water voyage same moment world while hand word\n",
            "case lord day boat land days other\n"
          ]
        }
      ],
      "source": [
        "text1.similar('morning') # These words are used in the same context as morning "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "PMI__hpCRJlK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dfe0230-2475-4992-e442-d66dfa49390d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "day house time room world place matter cottage evening point country\n",
            "door and rest thing moment latter subject better letter\n"
          ]
        }
      ],
      "source": [
        "text2.similar('morning') # And here's the same thing for the second book"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "EJXhAOLHRJlK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea45f70f-a412-444b-def0-cf3c1aa506b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the_when the_and that_at\n"
          ]
        }
      ],
      "source": [
        "# Show the common contexts for two different words\n",
        "# The use of the square brackets makes a list from the two words\n",
        "text1.common_contexts([\"morning\", \"evening\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "1vsmysnKoifn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d737fd1-352c-4b8b-ecd5-cd0c530ba88c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the_was this_i the_of the_marianne the_for the_before\n"
          ]
        }
      ],
      "source": [
        "# Now you try it by repeating the common_contexts command, but using the\n",
        "# data object text2. Use the terms morning and evening.\n",
        "\n",
        "#\n",
        "# 1.4: Include your explanation of the output:\n",
        "text2.common_contexts([\"morning\",\"evening\"])\n",
        "#morning and evening occurs in contexts like -\n",
        "#the morning/evening was...\n",
        "#this morning/evening i...\n",
        "#the morning/evening of...\n",
        "#the morning/evening marianne...\n",
        "#the morning/evening for...\n",
        "#the morning/evening before..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7DHn6RGn6QM"
      },
      "source": [
        "**Basic Corpus Linguistics: Word Counting**\n",
        "\n",
        "A natural question to ask in the analysis of a text is: how many words are there in the text? While it is straightforward for human beings to answer the question, it is not so easy for computers. As a starting point, we can use Python function len to first count the total number of words and punctuation symbols that appear."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "GpNt_O7WRJlK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d35e616-29d5-4b43-d58a-0594d10ed239"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "260819"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# Counting the total number of tokens\n",
        "len(text1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4znga5B2oHJG"
      },
      "source": [
        "How to interpret this number? This number shows how many words and punctuation symbols, or \"tokens\" there are in the complete list. A token is the technical name for a sequence of characters which is treated as a group by the software. Each text from the books was separated into a list of tokens, and this is one of the first NLP processing steps.\n",
        "\n",
        "Now this is the total number of tokens, and we might also want to find out how many distinct words there are, not counting repetitions. The Python “set” function removes the repetitions, and we can apply the “sorted” function to that, returning the resulted sorted list of tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "RnBCvkekRJlL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d02e996a-ef71-4c4a-f6fc-bc9538e33b29"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['!', '!\"', '!\"--', \"!'\", '!\\'\"', '!)', '!)\"', '!*', '!--', '!--\"']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "sorted(set(text1))[:10] # Review the first 10 of an alphabetized set of tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "oB37sEsnmvOM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "UddrbN6HMsr5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3138a754-9ee1-4f29-97a3-d0e64a39f5c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Alone',\n",
              " 'Alps',\n",
              " 'Already',\n",
              " 'Also',\n",
              " 'Am',\n",
              " 'Ambergriese',\n",
              " 'Ambergris',\n",
              " 'Amelia',\n",
              " 'America',\n",
              " 'American']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "# Let's look at a few more, after we've gotten through the punctuation, numbers\n",
        "# and other stuff that appears early in the sort.\n",
        "sorted(set(text1))[400:410]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "2x5lhq3lRJlL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c78fc4a-f5d9-440c-d034-5746808cbaf7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19317"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "# The set() function creates an unordered collection\n",
        "# of elements where each element is unique. We can take advantage of this\n",
        "# to count the number of unique tokens in the book.\n",
        "len(sorted(set(text1))) # Total number of tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "NN8U9PBNRJlM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88e56981-8b43-4c73-ca35-917cd56b335f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.052607363727335814"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "# Among tokens that are actual words, \"the\" is often one of the most common in \n",
        "# modern English. \n",
        "text1.count('the')/len(text1) # As a proportion of all tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "8NK-bNsaRJlN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7ccb691-6424-4dfa-e890-45a7f641d622"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.023096476867099407"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "text1.count('and')/len(text1) # \"And\" is also a very common word in English "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84TjUkB81z4i"
      },
      "source": [
        "This next code block contains our first use of a list comprehension in Python. This is like a for loop in any other programming language with the difference that it yields a list object that can be used for other purposes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "i5uiKi17BZ46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d1f3e18-755a-4480-b291-cc8857ac398f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n"
          ]
        }
      ],
      "source": [
        "# A list comprehension is a cool kind of for loop in Python\n",
        "my_numbers = [number for number in range(10,20)]\n",
        "print(my_numbers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "cUWH3TrB2YdJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e35fd4f-350f-4cea-8fb3-ed43c8b636d0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "type(my_numbers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "AWLssPwCRJlN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0572b184-7c1e-42e3-ddb8-6a27a9a1e212"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "106"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "# This uses a list comprehension to cycle through all of the words in text1.\n",
        "# We apply a test to each token to see how many characters it contains. We only\n",
        "# include it in the list if it has 15 or more characters.\n",
        "long_words = [w for w in text1 if len(w) >= 15] \n",
        "len(long_words) # Count how many tokens are 15 letters or more"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "t07jd3sqRJlN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa3fcf83-6cba-4062-bcf5-bc1f76cc1d79"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['CIRCUMNAVIGATION',\n",
              " 'perpendicularly',\n",
              " 'unceremoniously',\n",
              " 'uncomfortableness',\n",
              " 'sympathetically',\n",
              " 'Ehrenbreitstein',\n",
              " 'multitudinously',\n",
              " 'phrenologically',\n",
              " 'cannibalistically',\n",
              " 'comfortableness']"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "# Let's see them:\n",
        "long_words[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "collapsed": true,
        "id": "ozgMccJtRJlN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "238f352f-74e2-40c5-c81c-99d16372875f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22605"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "# For text2, calculate the following quantities by copying lines of code\n",
        "# from the blocks up above:\n",
        "\n",
        "# Exercise 1.5: The size of the token set versus total tokens (expressed as a proportion)\n",
        "len(set(text2))/len(text2) #0.0482\n",
        "# Exercise 1.6: The occurrences of the word 'the' as a percentage of all tokens\n",
        "text2.count('the')/len(text2) # 0.02727\n",
        "# Exercise 1.7: The occurrences of the word 'morning' as a percentage of all tokens\n",
        "text2.count('morning')/len(text2) #0.00061\n",
        "# Exercise 1.8: How many tokens are 7 letters or more\n",
        "seven_more=[w for w in text2 if len(w)>=7]\n",
        "len(seven_more)\n",
        "#22605 number of tokens that are 7 letters or more"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWFnzN9ilxiT"
      },
      "source": [
        "#Checkpoint! - Write Your Name and the Number of Tokens on the Whiteboard\n",
        "\n",
        "For this lab checkpoint, write your name and the number of tokens with 7 letters or more on the whiteboard. If your answer is different from the other answers on the board, check your code for errors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "aR23u1bNO3sY"
      },
      "outputs": [],
      "source": [
        "# Here we are creating a custom function to integrate what we learned. \n",
        "def day_word_analysis(input_text):\n",
        "  \"\"\"\n",
        "  Find and print context for common time of day words.\n",
        "  Print an analysis of the occurrence of these words.\n",
        "  \"\"\"\n",
        "  m_count = input_text.count('morning')\n",
        "  a_count = input_text.count('afternoon')\n",
        "\n",
        "  print('Percentage of time of day words:', \n",
        "        100*(m_count + a_count)/len(input_text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "MV_aDcy5QTlE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "392ae095-44fc-4b13-de4d-f2c1355647f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage of time of day words: 0.029905796740268154\n"
          ]
        }
      ],
      "source": [
        "day_word_analysis(text1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "rCo_613sQpFq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca0001c9-2faa-469c-ee1d-a7fce3fef660"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage of time of day words: 0.036807134449560804\n",
            "Percentage of time of day words: 0.0995931513815901\n"
          ]
        }
      ],
      "source": [
        "# Now add 'evening' to day_word_analysis() and retest it.\n",
        "# Test with text1 and text2. \n",
        "def day_word_analysis(input_text):\n",
        "  \"\"\"\n",
        "  Find and print context for common time of day words.\n",
        "  Print an analysis of the occurrence of these words.\n",
        "  \"\"\"\n",
        "  m_count = input_text.count('morning')\n",
        "  a_count = input_text.count('afternoon')\n",
        "  e_count = input_text.count('evening')\n",
        "\n",
        "  print('Percentage of time of day words:', \n",
        "        100*(m_count + a_count + e_count)/len(input_text))\n",
        "\n",
        "# Exercise 1.9: What do the results show?\n",
        "day_word_analysis(text1) #0.0368\n",
        "day_word_analysis(text2) #0.0995"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8Dj5UYvF9YC"
      },
      "source": [
        "Here's a piece of code from Natural Language Processing in Action that demonstrates the use of the Counter() function from the collections package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "jnJp80P2GMQ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2ab8ea5-421c-4205-9477-7c87370c7e00"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'valuable': 1,\n",
              "         'or': 1,\n",
              "         'entertaining': 1,\n",
              "         ',': 7,\n",
              "         'as': 1,\n",
              "         'affording': 1,\n",
              "         'a': 2,\n",
              "         'glancing': 1,\n",
              "         'bird': 1,\n",
              "         \"'\": 1,\n",
              "         's': 1,\n",
              "         'eye': 1,\n",
              "         'view': 1,\n",
              "         'of': 3,\n",
              "         'what': 1,\n",
              "         'has': 1,\n",
              "         'been': 1,\n",
              "         'promiscuously': 1,\n",
              "         'said': 1,\n",
              "         'thought': 1,\n",
              "         'fancied': 1,\n",
              "         'and': 2,\n",
              "         'sung': 1,\n",
              "         'Leviathan': 1,\n",
              "         'by': 1,\n",
              "         'many': 1,\n",
              "         'nations': 1,\n",
              "         'generations': 1,\n",
              "         'including': 1,\n",
              "         'our': 1,\n",
              "         'own': 1,\n",
              "         '.': 1,\n",
              "         'So': 1,\n",
              "         'fare': 1,\n",
              "         'thee': 1,\n",
              "         'well': 1,\n",
              "         'poor': 1,\n",
              "         'devil': 1,\n",
              "         'Sub': 1,\n",
              "         '-': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "moby_excerpt = text1[400:450] # Just analyze 50 of the words\n",
        "\n",
        "Counter(moby_excerpt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "kAG5MUTdGtdm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92bfc764-2355-4770-9a29-8dc2ac725131"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'and': 2,\n",
              "         'housekeeper': 1,\n",
              "         'in': 2,\n",
              "         'his': 5,\n",
              "         'sister': 1,\n",
              "         '.': 2,\n",
              "         'But': 1,\n",
              "         'her': 2,\n",
              "         'death': 1,\n",
              "         ',': 4,\n",
              "         'which': 1,\n",
              "         'happened': 1,\n",
              "         'ten': 1,\n",
              "         'years': 1,\n",
              "         'before': 1,\n",
              "         'own': 1,\n",
              "         'produced': 1,\n",
              "         'a': 1,\n",
              "         'great': 1,\n",
              "         'alteration': 1,\n",
              "         'home': 1,\n",
              "         ';': 1,\n",
              "         'for': 1,\n",
              "         'to': 1,\n",
              "         'supply': 1,\n",
              "         'loss': 1,\n",
              "         'he': 1,\n",
              "         'invited': 1,\n",
              "         'received': 1,\n",
              "         'into': 1,\n",
              "         'house': 1,\n",
              "         'the': 2,\n",
              "         'family': 1,\n",
              "         'of': 1,\n",
              "         'nephew': 1,\n",
              "         'Mr': 1,\n",
              "         'Henry': 1,\n",
              "         'Dashwood': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "# What's the most common token as revealed by Counter()? What's the most common\n",
        "# token that is NOT punctuation?\n",
        "#Most common token - comma -',' occuring 7 times\n",
        "#Most common token that is not a punctuation - \"of\" occuring 3 times\n",
        "# Exercise 1.10: Run Counter() on 50 tokens from text2. Compare the results to\n",
        "# what you see above.\n",
        "\n",
        "sense_excerpt = text2[100:150] \n",
        "\n",
        "Counter(sense_excerpt)\n",
        "\n",
        "#Most common token - \"his\" occurs 5 times\n",
        "#Most common token that is punctuation is comma occuring 4 times"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alg5dggPHJnq"
      },
      "source": [
        "You have probably have reached this point before the end of the class period. Download a copy of this notebook with all of your exercises completed and the outputs of each code block retained. Then upload that file (which will have the .ipynb extension) to the appropriate drop box on Blackboard.\n",
        "\n",
        "In the notes area for your submission, write a note indicating how many of the exercises you completed.\n",
        "\n",
        "If there is additional time left in the class period, solve this problem:\n",
        "Write and test a function that receives two token lists. The function should use Counter() to enumerate the unique tokens in each token list (between the specified start and end). Then the function should print the token counts for each text, but ONLY for tokens that exist in both input texts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "9LHpv65l3ZFn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a15f3e17-48eb-47c2-e662-19f03dd82648"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4669\n",
            "[('influence', 1), ('ruins', 1), ('crimsoned', 1), ('Saturday', 1), ('sort', 1)]\n"
          ]
        }
      ],
      "source": [
        "# Many programmers break a problem down and solve a smaller and easier problem\n",
        "# before tackling a larger one. \n",
        "\n",
        "# One way to address this challenge is to create simple lists of unique tokens \n",
        "# for each text and then use a list comprehension to create a list of tokens\n",
        "# from one text that also exist in the other.\n",
        "\n",
        "#\n",
        "# Exercise 1.11: Develop and test a function to address the challenge.\n",
        "def two_counters(input1):\n",
        "  c=Counter(input1) #prints the counts\n",
        "  #I want to print the five most common words - referred from stackoverflow\n",
        "  print(c.most_common(5)) \n",
        "\n",
        "text1_unique = set(text1) #get unique tokens of text1\n",
        "text2_unique = set(text2) #get unique tokens of text2\n",
        "#Get unique tokens that exist in both text1 and text2\n",
        "both_unique = set(text1_unique).intersection(text2_unique) #Referred this solution from stackoverflow\n",
        "print(len(both_unique)) #4669 common unique words in both texts\n",
        "both_unique=list(both_unique)\n",
        "two_counters(both_unique)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}