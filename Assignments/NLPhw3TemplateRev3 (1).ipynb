{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#IST664/CIS668 - Homework 3 (assigned in Week 7)#\n",
        "\n",
        "Note to students: You may freely use code from the labs for this class without the need for attributions. Also note that this HW template has cell tags that are used by the grading program. Please retain these cell tags. Feel free to add new code blocks as needed: these do not need tags.\n",
        "\n",
        "Originality assertion: All of the text and comments in this file are my original work (except for template items written by the instructor). All of the code in this file is my work, except where I give credit to another source. By adding my name below, I affirm this originality assertion.\n",
        "\n",
        "*** My name: _________ ***\n",
        "\n",
        "Sometimes, it can be beneficial to discuss the challenges in the homework with another student. This is fine as long as you DO NOT SHARE CODE with the other person. If you consulted with anyone about this homework, list their names here:\n",
        "\n",
        "*** My collaborators: _________ ***\n"
      ],
      "metadata": {
        "id": "UBy_JaSAGpux"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 1: Read Sentence Pairs from Github**\n",
        "\n",
        "It is a weird acronym, but the \"Sentences Involving Compositional Knowledge\" (SICK) dataset includes a large number of sentence pairs with various levels of similarity. I've stored a copy in my GitHub account and you should be able to download it directly to your virtual machine and into a Pandas dataframe. Here's a link to a web page with more information about the data:\n",
        "https://marcobaroni.org/composes/sick.html \n",
        "\n",
        "When you review the data, you will notice a field where the options are ENTAILMENT, CONTRADICTION, or NEUTRAL. Textual entailment is when one sentence logically follows based on the meaning of another sentence. You can read more about textual entailment here: https://en.wikipedia.org/wiki/Textual_entailment"
      ],
      "metadata": {
        "id": "OBdgCgdcRNrq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "sick_data = pd.read_csv(\"https://raw.githubusercontent.com/jmstanto/ist664/main/SICK_train.txt\" , sep='\\t', on_bad_lines='skip', index_col=None) \n",
        "\n",
        "# HW3T1A\n",
        "# Add code to display the first few rows of data\n",
        "#\n",
        "\n"
      ],
      "metadata": {
        "id": "wtW_IYsqRMGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HW3T1B\n",
        "# Add code that shows the number of variables and the number of rows in the dataset.\n",
        "# Add some comments describing what each of the columns contains. \n",
        "#\n"
      ],
      "metadata": {
        "id": "R3YsUGm0R8Gr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2: Add a Similarity Score to Each Row**\n",
        "\n",
        "Use a pre-trained sentence embedding model to generate a similarity score for each sentence pair. To get started, here's some code from Lab 7:"
      ],
      "metadata": {
        "id": "mMBf3r-qTE_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# HW3T2A\n",
        "# The first thing we will need is the library for loading sentence transformers\n",
        "# This generates a lot of output, but should run pretty fast.\n",
        "!pip install sentence-transformers"
      ],
      "metadata": {
        "id": "Xg9FEECDTZqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HW3T2B\n",
        "# Now load a pre-trained sentence transformer. There are hundreds to choose from.\n",
        "# This downloads a lot of data to your virtual machine and takes half a minute or so.\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Here's a sentence transformer model that encodes a d=384 vector. See:\n",
        "# https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\n",
        "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
      ],
      "metadata": {
        "id": "e-pEfIZHTrhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HW3T2C\n",
        "# Here's an example of how we can put the sentence transformer to use \n",
        "# by encoding the two sentences from the first row and computing a \n",
        "# cosine similarity between them.\n",
        "from sentence_transformers.util import cos_sim\n",
        "\n",
        "show_row = 2\n",
        "\n",
        "print(sick_data[\"sentence_A\"][show_row])\n",
        "print(sick_data[\"sentence_B\"][show_row])\n",
        "print(sick_data[\"entailment_judgment\"][show_row])\n",
        "a = model.encode([sick_data[\"sentence_A\"][show_row]])\n",
        "b = model.encode([sick_data[\"sentence_B\"][show_row]])\n",
        "\n",
        "cos_sim(a, b).tolist()[0][0] # The notation on the end extracts a scalar from the tensor object"
      ],
      "metadata": {
        "id": "5CGy2Ou4UcfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HW3T2D\n",
        "# Add code to produce a similarity score for each sentence pair and insert the\n",
        "# list into the Pandas dataframe as a new column. You can use the \"insert\" method\n",
        "# on a Pandas df to add a column. Choose a sensible label for your new variable as\n",
        "# you will need it later for the regression analysis.\n",
        "#\n",
        "# Note that if you process the whole dataset, it will take a couple of minutes\n",
        "# to encode all 4500 of the sentences. You can subset the data down to 1000\n",
        "# or 1500 rows if you prefer to shorten the run time.\n",
        "#\n",
        "\n"
      ],
      "metadata": {
        "id": "dczow-X7Vrtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HW3T2E\n",
        "# Review a few rows of the modified Pandas df with the new column\n",
        "#\n"
      ],
      "metadata": {
        "id": "PxFfFJyn1iv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HW3T2F\n",
        "# Run and interpret a simple correlation between your new similarity score\n",
        "# and the original relatedness_score column. The corr() method from Pandas\n",
        "# (which is a method for columns) can do this. \n",
        "#\n"
      ],
      "metadata": {
        "id": "vS_NDhiyXNXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add your interpretation of the correlation by replacing this text. Would you consider this value to be small? Large? Is it what you expected? Why?"
      ],
      "metadata": {
        "id": "QESAX9U0kSli"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 3: Create Dummy Codes for Entailment**\n",
        "\n",
        "In this task after this one, you will produce a regression analysis that predicts the original relatedness_score from your newly added similarity measure along with two dummy codes created from the entailment_judgment.\n",
        "\n",
        "With linear regression we can use as predictors any combination of metric variables and binary codes. With a label like entailment_judgment, with three or more categories, we need to create dummy codes to represent the categories. To avoid collinearity, there should always be one less dummy code than the number of categories."
      ],
      "metadata": {
        "id": "4IH5vlX_a-pD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# HW3T3A\n",
        "# Show the three types of entailment_judgment using set().\n"
      ],
      "metadata": {
        "id": "c4CaB6u7arRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HW3T3B\n",
        "contra = [ int(ej == \"CONTRADICTION\") for ej in sick_data[\"entailment_judgment\"]]\n",
        "entail = [ int(ej == \"ENTAILMENT\") for ej in sick_data[\"entailment_judgment\"]]"
      ],
      "metadata": {
        "id": "dxxHH8szmUd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HW3T3C\n",
        "# Insert the two new dummy codes into your pandas df\n",
        "#\n"
      ],
      "metadata": {
        "id": "-Dk7JbvL2nM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HW3T3D\n",
        "# Review the newly modified df\n",
        "#\n"
      ],
      "metadata": {
        "id": "MGbBKyuX2s5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 4: See if the root verbs match**\n",
        "\n",
        "In HW2 you conducted some information extraction from sentences including locating the root verb. If the root verbs match on two sentences, that may indicate something about how related the sentences are. For this task you will create a list of dummy codes that indicate whether the two sentences in each pair use the same root verb."
      ],
      "metadata": {
        "id": "S48eJkJxpkEb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# HW3T4A\n",
        "import spacy # SpaCy will help us find roots\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "FWsjMchar74m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HW3T4B\n",
        "# Here's some demo code that shows how to fetch the roots\n",
        "show_row = 5\n",
        "\n",
        "print(sick_data[\"sentence_A\"][show_row])\n",
        "print(sick_data[\"sentence_B\"][show_row])\n",
        "\n",
        "doc1 = nlp(sick_data[\"sentence_A\"][show_row])\n",
        "doc2 = nlp(sick_data[\"sentence_B\"][show_row])\n",
        "\n",
        "list(doc1.sents)[0].root, list(doc2.sents)[0].root"
      ],
      "metadata": {
        "id": "3AV5MVb9qCB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HW3T4C\n",
        "# Here's a test that compares the two strings\n",
        "list(doc1.sents)[0].root.text == list(doc2.sents)[0].root.text"
      ],
      "metadata": {
        "id": "72lExZHWr6BG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HW3T4D\n",
        "# Write a loop that will perform the test on each pair of sentences and save the result in a list\n",
        "#\n"
      ],
      "metadata": {
        "id": "62VFUsvOs2nz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HW3T4E\n",
        "# Insert the new dummy code into your pandas df.\n",
        "# Use the column name, \"root_match\", as shown in the example\n",
        "#\n"
      ],
      "metadata": {
        "id": "nJ7iinsds1Av"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HW3T4F\n",
        "# Display the pandas df\n",
        "#\n"
      ],
      "metadata": {
        "id": "Si7-RlWfs-nA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 5: Run Regression Analysis to Predict relatedness_score**\n",
        "\n",
        "Next, your job is to conduct a regression analysis where you predict relatedness_score from your newly added similarity measure along with two dummy codes created from the entailment_judgment. The sklearn library has a linear regression model, but statsmodels.api produces nicer output."
      ],
      "metadata": {
        "id": "OMr4W8zJ24Xz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# HW3T5A\n",
        "# The sm.OLS() method does regression and once you have fitted the model\n",
        "# the summary() method produces nice output with all the values needed to \n",
        "# interpret regression results.\n",
        "#\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "\n",
        "# You can specify your regression model using a formula language, like this:\n",
        "# results = smf.ols('relatedness_score ~ similarity + dummy_entail + dummy_contra + root_match', data=sick_data).fit()\n",
        "# Of course, you may need to adjust the X-variable names depending upon the\n",
        "# labels you used when you inserted them into the database. \n"
      ],
      "metadata": {
        "id": "-JZaSUIKlEck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HW3T5B\n",
        "# Use the summary() method on your results object to show the regression output."
      ],
      "metadata": {
        "id": "LFuSoytKpKm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "HW3T5C\n",
        "\n",
        "Replace this text with an explanation of the regression output. Make sure to report on the values of the coefficients for the predictors (and the intercept). Also report and interpret the R-squared value. Is this a good predictive model? "
      ],
      "metadata": {
        "id": "UruFHFFbJp23"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 6: Find the sentence with the largest error of prediction and the smallest error of prediction.**\n",
        "\n"
      ],
      "metadata": {
        "id": "smRnWo7MaVJi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# HW3T6A\n",
        "# Use the predict() method on the results object to produce predicted scores \n",
        "# for each row in your data frame. For the regression equation to work, you must\n",
        "# supply all three of the X variables for each case. Pandas makes it \n",
        "# easy to create a Pandas subset of columns, like this:\n",
        "#\n",
        "# predictors = sick_data[['similarity', 'dummy_entail', 'dummy_contra', 'root_match']]\n"
      ],
      "metadata": {
        "id": "U7qrcP1o5KUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HW3T6B\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#\n",
        "# Show a histogram of predicted values from the previous block. Comment on\n",
        "# why the range of the predicted values does or does not make sense.\n",
        "#"
      ],
      "metadata": {
        "id": "B_FuDtwBtj_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HW3T6C\n",
        "# Compute a squared error value for each row of your data frame. This is easy:\n",
        "# subtract the predicted value from the actual value (i.e., relatedness_score) \n",
        "# and square the result. You can use a for loop or a list comprehension. \n",
        "\n",
        "# Hint 1:\n",
        "# Python's built-in zip() function allows you to bundle two vectors of data\n",
        "# together into a list of tuples.\n",
        "# Hint 2: \n",
        "# When extracting data from a Pandas column, sometimes you must use the \n",
        "# tolist() method to get the data into a structure that can be used for\n",
        "# functions like zip().\n",
        "\n"
      ],
      "metadata": {
        "id": "U2N-Jz0vsqxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HW3T6D\n",
        "import numpy as np\n",
        "# Use np.argmin() to find the index of the row in the Pandas dataset with the \n",
        "# smallest squared error of prediction\n"
      ],
      "metadata": {
        "id": "-2DmbfpMsjxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HW3T6E\n",
        "# Use np.argmax() to find the index of the row with the largest squared error\n"
      ],
      "metadata": {
        "id": "lWSjeVsorq0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HW3T6F\n",
        "# Display the Pandas data from the row with the worst prediction. Note that\n",
        "# the iloc() method allows you to select a particular row.\n"
      ],
      "metadata": {
        "id": "MChHQZgLu3kM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HW3T6G\n",
        "# Display the Pandas data from the row with the worst prediction\n"
      ],
      "metadata": {
        "id": "SWU2L5HSuPxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "HW3T6H\n",
        "\n",
        "Replace this text with an explanation of why the argmin() case was \"easy\" to predict and the argmax() case was \"hard\" to predict. This explanation should consider the semantic content of the sentences in reference to the relatedness_score developed by the experts."
      ],
      "metadata": {
        "id": "_o4xtTfTLzxu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 7: Write your own two contradictory sentences and predict the relatedness score**"
      ],
      "metadata": {
        "id": "_T7IM6KotZtC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# HW3T7A\n",
        "# Replace these empty strings with your own sentences\n",
        "test_sentenceA = \"\"\n",
        "test_sentenceB = \"\""
      ],
      "metadata": {
        "id": "h9i05sD8ty1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HW3T7B\n",
        "# Encode the sentences into vectors as was demonstrated for task 2.\n"
      ],
      "metadata": {
        "id": "2PhkNAfYMmqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HW3T7C\n",
        "# Compute the cosine similarity between the two vectors."
      ],
      "metadata": {
        "id": "8ZG5U91nUyXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HW3T7D\n",
        "# You may have used the formula interface for fitting your regression model\n",
        "# with smf.ols(). If that's true, the easiest way to get a prediction for a\n",
        "# novel case is to build a one-row Pandas dataframe and enter the X variables\n",
        "# you need to make the prediction. The next two lines of commented code\n",
        "# provide an exmaple of this technique: \n",
        "# temp_df = pd.DataFrame(columns=['similarity', 'dummy_entail', 'dummy_contra', 'root_match'])\n",
        "# temp_df.loc[0] = [0.80, 0, 0] # You can include whatever X data you want in place of these three values\n",
        "#\n"
      ],
      "metadata": {
        "id": "qmjeZaY0Nca1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HW3T7E\n",
        "# Use the predict() method on your regression output object to make one \n",
        "# prediction of relatedness_score using the one-row Pandas dataframe from\n",
        "# the previous step.\n",
        "#\n"
      ],
      "metadata": {
        "id": "wC1e-tJYNGPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "HW3T7F\n",
        "\n",
        "Replace this text with an interpretation of the output score from the prediction based on your two sentences."
      ],
      "metadata": {
        "id": "ozWJAQh5P0c6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "HWCC\n",
        "\n",
        "Don't forget to write a concluding comment describing your findings. Provide an overview of your findings from the tasks you accomplished above. How well were you able to predict the relatedness score from the other variables? Did entailment or contradiction work as predictors and what does each coefficient say about our ability to predict relatedness scores? Would it be helpful to know something about entailment if we are trying to understand paraphrases? Why do we care about entailment in the context of an application such as chat?"
      ],
      "metadata": {
        "id": "dy7gSNmRzsOa"
      }
    }
  ]
}