{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##IST664/CIS668 - Homework 1 (assigned in Week 2)\n",
        "\n",
        "Student name:\n",
        "\n",
        "Originality assertion: By adding my name above, I assert that all of the text and comments in this file are my original work (except for template items written by the instructor). All of the code in this file is my work, except where I give credit to another source.\n",
        "\n",
        "Note: You may freely use code from Labs 1 and 2, as well as any in class exercise notebooks for this class without the need for attributions. \n",
        "\n",
        "Also note: DO NOT under any circumstances borrow the code of another student. You should feel free to help each other with coaching and suggestions, but do not share code."
      ],
      "metadata": {
        "id": "UBy_JaSAGpux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In this code, we import the NLTK, download the Gutenberg texts, extract a \n",
        "# list of file identifiers from the downloaded material.\n",
        "\n",
        "import nltk # Bring in the NLP toolkit\n",
        "nltk.download('gutenberg') # Then import the Gutenberg library, which has books\n",
        "nltk.corpus.gutenberg.fileids()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q15645S3Gqfe",
        "outputId": "485b6867-b0f0-4eef-e7c2-d645b1d2dde9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['austen-emma.txt',\n",
              " 'austen-persuasion.txt',\n",
              " 'austen-sense.txt',\n",
              " 'bible-kjv.txt',\n",
              " 'blake-poems.txt',\n",
              " 'bryant-stories.txt',\n",
              " 'burgess-busterbrown.txt',\n",
              " 'carroll-alice.txt',\n",
              " 'chesterton-ball.txt',\n",
              " 'chesterton-brown.txt',\n",
              " 'chesterton-thursday.txt',\n",
              " 'edgeworth-parents.txt',\n",
              " 'melville-moby_dick.txt',\n",
              " 'milton-paradise.txt',\n",
              " 'shakespeare-caesar.txt',\n",
              " 'shakespeare-hamlet.txt',\n",
              " 'shakespeare-macbeth.txt',\n",
              " 'whitman-leaves.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a file index using the list above, except for 0 and 1, where the first\n",
        "# letters of the file name are closest to the first letters of your last name.\n",
        "\n",
        "my_file_id = 2 # Change to any value between 2 and 17\n",
        "\n",
        "my_file = nltk.corpus.gutenberg.fileids()[my_file_id] # Extract the file\n",
        "\n",
        "my_text = nltk.corpus.gutenberg.raw(my_file) # Here's the raw text"
      ],
      "metadata": {
        "id": "95mzb154GvLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 1\n",
        "\n",
        "Make sure that you have (at least) one block of code for each of the tasks.\n",
        "\n",
        "1.\tTokenize your book and print how many tokens it contains\n",
        "2.\tRemove stop words and punctuation; lowercase all remaining tokens; make sure to use this result in subsequent operations for Part 1.\n",
        "3.\tRecalculate and display the total number of remaining tokens (i.e., after removal of stop words and punctuation)\n",
        "4.\tFind all tokens with a length (in characters) greater than eight; print at least one example from this list and print the length of this list\n",
        "5.\tConduct a frequency analysis of the tokens and store it in an appropriate data structure; display the type of that data structure\n",
        "6.\tDisplay the 20 most frequently occurring tokens and how often they occur\n",
        "7.\tObtain a list of the unique set of tokens and print the length of this list\n",
        "8.\tDisplay a list of 10 hapaxes\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GVCzss8S8oel"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Begin tasks 1 - 8 here.\n",
        "#"
      ],
      "metadata": {
        "id": "ZXZdsiIXGn9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Part 2\n",
        "\n",
        "A Regular Expression (RegEx), is a sequence of characters that forms a search pattern. RegEx can be used to check if a string contains the specified search pattern. You can use the re package to test whether a regular expression matches a specific string in Python. All of the following exercises should be done using regex expressions.\n",
        "\n",
        "9.\tGo back to the “raw” text of your book and use a sentence tokenizer to divide the text into a list of sentences. Display the total number of sentences in the list. Perform the following parsing operations on a sample of sentences using RegEx patterns. For readability, I suggest that you do each of these items in a separate code block:\n",
        "10.\tDivide the sentence into separate tokens based on whitespace. \n",
        "11.\tDiscard all punctuation characters.\n",
        "12.\tRemove plural endings by discarding a trailing \"s\" on any token.\n",
        "13.\tRemove \"ed\" endings (i.e., the past tense on a verb such as \"framed\").\n",
        "\n",
        "It doesn't really matter how many sentences you process, just so long as you do enough to demonstrate that your Regex code works for items 10-13. Make sure that the output displayed in the notebook clearly demonstrates the success of your Regex code. Put in a concluding comment that discusses how well your Regex works, compared with a more full-featured stemmer (e.g., the Porter stemmer). \n"
      ],
      "metadata": {
        "id": "BSXoDJSzGspD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Begin tasks 9 - 13 here.\n",
        "#"
      ],
      "metadata": {
        "id": "kBUW4LNEGxC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change this text to your concluding comment."
      ],
      "metadata": {
        "id": "fKDplCIv4IGe"
      }
    }
  ]
}